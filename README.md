# Plano de Experimento ‚Äì Previs√£o de Custos de Infraestrutura Cloud

---

## 1. Identifica√ß√£o B√°sica

### 1.1 T√≠tulo do Experimento
**Previs√£o de Custos de Infraestrutura Cloud Utilizando Modelos Baseados em M√©tricas Reais: Uma Compara√ß√£o entre Algoritmos Simples e T√©cnicas de S√©ries Temporais**

### 1.2 ID / C√≥digo
`TCC-PRED-CUSTO-2024-001`

### 1.3 Vers√£o do Documento e Hist√≥rico de Revis√£o

| Vers√£o | Data | Autor | Descri√ß√£o das Altera√ß√µes |
|--------|------|-------|--------------------------|
| v1.0 | 02/12/2024 | Renato Matos Alves Penna | Vers√£o inicial - Se√ß√µes 1 a 4 |

### 1.4 Datas

- **Data de Cria√ß√£o:** 02/12/2024
- **√öltima Atualiza√ß√£o:** 02/12/2024

### 1.5 Autores

| Nome | √Årea | Contato |
|------|------|---------|
| Renato Matos Alves Penna | Computa√ß√£o / Engenharia de Software | renatomatosapbusiness@gmail.com |

### 1.6 Respons√°vel Principal (PI / Dono do Experimento)

**Orientador:** Danilo de Quadros Maia Filho  
**Respons√°vel pela Execu√ß√£o:** Renato Matos Alves Penna

### 1.7 Projeto / Produto / Iniciativa Relacionada

Este experimento est√° vinculado ao **Trabalho de Conclus√£o de Curso (TCC)** do curso de gradua√ß√£o, com foco em Engenharia de Software Experimental aplicada a Cloud Computing. O estudo visa contribuir tanto para o contexto acad√™mico quanto para aplica√ß√µes pr√°ticas em empresas e startups que buscam otimiza√ß√£o de custos em infraestrutura cloud.

---

## 2. Contexto e Problema

### 2.1 Descri√ß√£o do Problema / Oportunidade

A computa√ß√£o em nuvem tornou-se fundamental para organiza√ß√µes modernas, permitindo escalabilidade sob demanda e redu√ß√£o de custos de infraestrutura f√≠sica. Entretanto, a natureza din√¢mica e el√°stica dos recursos cloud apresenta um desafio cr√≠tico: **custos imprevis√≠veis e dif√≠ceis de estimar**.

#### Problema Central:
Organiza√ß√µes frequentemente enfrentam:
- **Gastos inesperados** devido a picos de uso n√£o antecipados
- **Dificuldade em prever or√ßamentos** mensais/trimestrais de infraestrutura
- **Falta de visibilidade** sobre quais m√©tricas de uso mais impactam os custos
- **Aus√™ncia de modelos preditivos** que auxiliem no planejamento financeiro

#### Oportunidade:
Criar modelos de previs√£o de custos baseados em m√©tricas reais de uso (CPU, mem√≥ria, armazenamento, requisi√ß√µes) pode:
- Permitir **planejamento financeiro mais preciso**
- Identificar **padr√µes de consumo** e oportunidades de otimiza√ß√£o
- Auxiliar **decis√µes t√©cnicas** com impacto financeiro quantific√°vel
- Prevenir **estouros de or√ßamento** atrav√©s de alertas antecipados

### 2.2 Contexto Organizacional e T√©cnico

#### Contexto Organizacional:
Este √© um **experimento acad√™mico** desenvolvido como Trabalho de Conclus√£o de Curso. Embora n√£o esteja vinculado a uma empresa espec√≠fica, o estudo foi projetado para ter **aplicabilidade pr√°tica** em contextos reais de:
- Startups e PMEs que utilizam infraestrutura cloud
- Times de DevOps respons√°veis por otimiza√ß√£o de custos
- Equipes de engenharia que precisam justificar decis√µes t√©cnicas financeiramente
- Departamentos financeiros que necessitam de previs√µes or√ßament√°rias confi√°veis

#### Contexto T√©cnico:
- **Ambiente:** Simula√ß√£o baseada em padr√µes real√≠sticos de workloads cloud
- **Tecnologias:** Python 3.10+, bibliotecas de an√°lise de dados (Pandas, NumPy), machine learning (Scikit-learn, Statsmodels, Prophet)
- **M√©tricas analisadas:** CPU, mem√≥ria RAM, armazenamento, volume de requisi√ß√µes/tr√°fego de rede
- **Modelos cloud:** Precifica√ß√£o baseada em provedores reais (AWS, Azure, GCP)
- **Processo:** Metodologia experimental controlada com an√°lise estat√≠stica rigorosa

### 2.3 Trabalhos e Evid√™ncias Pr√©vias (Internos e Externos)

#### Evid√™ncias Externas (Literatura):
**Nota:** Esta se√ß√£o ser√° expandida na fase de revis√£o bibliogr√°fica, mas alguns temas relevantes incluem:
- Estudos sobre **time series forecasting** aplicados a custos de TI
- Papers sobre **cloud cost optimization** e FinOps
- Pesquisas comparando **modelos de previs√£o** (ARIMA, exponential smoothing, machine learning)
- Trabalhos sobre **m√©tricas de infraestrutura** como preditores de custos

#### Evid√™ncias Internas:
Este √© o primeiro experimento formal sobre o tema no contexto do TCC. Observa√ß√µes preliminares indicam que:
- Modelos de s√©ries temporais podem capturar padr√µes sazonais de uso
- M√©tricas de CPU e requisi√ß√µes apresentam correla√ß√£o forte com custos
- A granularidade dos dados (di√°ria vs. hor√°ria) afeta a precis√£o das previs√µes

### 2.4 Referencial Te√≥rico e Emp√≠rico Essencial

#### Conceitos Fundamentais:

**1. Computa√ß√£o em Nuvem e Modelos de Precifica√ß√£o:**
- Recursos el√°sticos e precifica√ß√£o baseada em uso
- M√©tricas de consumo: CPU, mem√≥ria, armazenamento, rede
- Modelos pay-as-you-go dos principais provedores

**2. S√©ries Temporais:**
- Conceitos de tend√™ncia, sazonalidade e ru√≠do
- Estacionariedade e transforma√ß√µes necess√°rias
- Autocorrela√ß√£o e depend√™ncia temporal

**3. Modelos de Previs√£o:**
- **Modelos Simples:** M√©dia m√≥vel, regress√£o linear
- **Modelos Cl√°ssicos de S√©ries Temporais:** ARIMA, Exponential Smoothing
- **M√©tricas de Avalia√ß√£o:** MAE, RMSE, MAPE

**4. Engenharia de Software Experimental:**
- Desenho experimental e controle de vari√°veis
- Testes de hip√≥teses e an√°lise estat√≠stica
- Valida√ß√£o cruzada e generaliza√ß√£o de modelos

#### Base Emp√≠rica:
A literatura em FinOps e cloud cost management demonstra que:
- Previs√µes precisas reduzem desperd√≠cio em at√© 30%
- Modelos baseados em s√©ries temporais superam heur√≠sticas simples
- A combina√ß√£o de m√∫ltiplas m√©tricas melhora a acur√°cia preditiva

---

## 3. Objetivos e Quest√µes (Goal / Question / Metric)

### 3.1 Objetivo Geral (Goal Template)

**Analisar** modelos de previs√£o de custos cloud baseados em m√©tricas reais de uso  
**com o prop√≥sito de** comparar sua acur√°cia e identificar qual apresenta melhor desempenho  
**com respeito a** erro de previs√£o (MAE, RMSE, MAPE) e capacidade de generaliza√ß√£o  
**do ponto de vista de** engenheiros de software, times de DevOps e gestores financeiros  
**no contexto de** ambientes cloud com workloads simulados representando aplica√ß√µes reais.

### 3.2 Objetivos Espec√≠ficos

1. **O1 - Desenvolver modelos de previs√£o:** Construir e implementar pelo menos quatro modelos distintos de previs√£o de custos (regress√£o linear, m√©dia m√≥vel, ARIMA, exponential smoothing) utilizando m√©tricas reais de uso de infraestrutura.

2. **O2 - Avaliar acur√°cia dos modelos:** Medir e comparar a precis√£o de cada modelo utilizando m√©tricas padronizadas de erro (MAE, RMSE, MAPE) em diferentes janelas temporais.

3. **O3 - Identificar vari√°veis preditoras:** Analisar quais m√©tricas de infraestrutura (CPU, mem√≥ria, requisi√ß√µes, armazenamento) apresentam maior correla√ß√£o com os custos finais e maior poder preditivo.

4. **O4 - Validar generaliza√ß√£o:** Verificar se os modelos mant√™m precis√£o adequada em dados n√£o utilizados no treinamento (valida√ß√£o cruzada), garantindo capacidade de generaliza√ß√£o para per√≠odos futuros.

5. **O5 - Comparar estabilidade:** Avaliar a robustez dos modelos diante de diferentes padr√µes de uso (picos, sazonalidade, tend√™ncias) e determinar qual apresenta previs√µes mais est√°veis.

### 3.3 Quest√µes de Pesquisa / de Neg√≥cio

#### Relacionadas ao Objetivo O1 (Desenvolver modelos):
- **Q1.1:** Qual modelo de previs√£o apresenta o menor erro m√©dio absoluto (MAE)?
- **Q1.2:** Como os modelos se comportam em diferentes janelas de previs√£o (7, 14 e 30 dias)?
- **Q1.3:** Existe diferen√ßa estatisticamente significativa entre o desempenho dos modelos?

#### Relacionadas ao Objetivo O2 (Avaliar acur√°cia):
- **Q2.1:** Qual modelo apresenta menor erro quadr√°tico m√©dio (RMSE)?
- **Q2.2:** Qual modelo oferece o menor erro percentual (MAPE)?
- **Q2.3:** Os erros de previs√£o diminuem com janelas temporais maiores?

#### Relacionadas ao Objetivo O3 (Identificar vari√°veis):
- **Q3.1:** Quais m√©tricas de infraestrutura apresentam maior correla√ß√£o com os custos totais?
- **Q3.2:** Como varia√ß√µes no volume de requisi√ß√µes afetam o custo previsto?
- **Q3.3:** O consumo de CPU √© um preditor melhor que o uso de mem√≥ria para custos?

#### Relacionadas ao Objetivo O4 (Validar generaliza√ß√£o):
- **Q4.1:** Os modelos generalizam bem para per√≠odos n√£o vistos durante o treinamento?
- **Q4.2:** Qual √© o erro m√©dio de valida√ß√£o cruzada de cada modelo?
- **Q4.3:** Existe degrada√ß√£o significativa de performance entre treino e teste?

#### Relacionadas ao Objetivo O5 (Comparar estabilidade):
- **Q5.1:** Qual modelo apresenta menor vari√¢ncia nos erros de previs√£o?
- **Q5.2:** Algum modelo apresenta sinais de overfitting (diferen√ßa treino/teste > 10%)?
- **Q5.3:** Os modelos de s√©ries temporais s√£o mais est√°veis que modelos simples?

### 3.4 M√©tricas Associadas (GQM)

#### Tabela GQM Completa

| Objetivo | Quest√£o | M√©tricas Associadas |
|----------|---------|---------------------|
| **O1: Desenvolver modelos** | Q1.1: Qual modelo apresenta menor MAE? | M1 (MAE) |
| | Q1.2: Como se comportam em diferentes janelas? | M1 (MAE), M2 (RMSE) |
| | Q1.3: H√° diferen√ßa estat√≠stica entre modelos? | M1 (MAE), M11 (p-valor ANOVA) |
| **O2: Avaliar acur√°cia** | Q2.1: Qual modelo apresenta menor RMSE? | M2 (RMSE) |
| | Q2.2: Qual modelo oferece menor MAPE? | M3 (MAPE) |
| | Q2.3: Erros diminuem com janelas maiores? | M1 (MAE), M2 (RMSE) por janela |
| **O3: Identificar vari√°veis** | Q3.1: Quais m√©tricas t√™m maior correla√ß√£o? | M4 (Correla√ß√£o %), M7-M10 |
| | Q3.2: Como requisi√ß√µes afetam custo? | M5 (Custo/requisi√ß√£o), M10 (Requisi√ß√µes) |
| | Q3.3: CPU vs. Mem√≥ria como preditor? | M4 (Correla√ß√£o), M7 (CPU), M8 (Mem√≥ria) |
| **O4: Validar generaliza√ß√£o** | Q4.1: Modelos generalizam para novos per√≠odos? | M6 (Erro valida√ß√£o cruzada) |
| | Q4.2: Qual erro m√©dio de valida√ß√£o cruzada? | M6 (Erro valida√ß√£o cruzada) |
| | Q4.3: H√° degrada√ß√£o entre treino/teste? | M12 (Diferen√ßa treino/teste) |
| **O5: Comparar estabilidade** | Q5.1: Qual modelo tem menor vari√¢ncia? | M13 (Desvio padr√£o dos erros) |
| | Q5.2: Algum modelo apresenta overfitting? | M12 (Diferen√ßa treino/teste) |
| | Q5.3: S√©ries temporais s√£o mais est√°veis? | M13 (Desvio padr√£o), M12 (Diferen√ßa treino/teste) |

#### Tabela Detalhada de M√©tricas

| ID | M√©trica | Descri√ß√£o Completa | Unidade | Fonte dos Dados |
|----|---------|-------------------|---------|-----------------|
| **M1** | MAE (Mean Absolute Error) | Erro absoluto m√©dio entre valores reais e previstos | Valor monet√°rio (R$) | C√°lculo p√≥s-previs√£o |
| **M2** | RMSE (Root Mean Square Error) | Raiz quadrada do erro quadr√°tico m√©dio | Valor monet√°rio (R$) | C√°lculo p√≥s-previs√£o |
| **M3** | MAPE (Mean Absolute Percentage Error) | Erro percentual absoluto m√©dio | Percentual (%) | C√°lculo p√≥s-previs√£o |
| **M4** | Correla√ß√£o com Custo | Correla√ß√£o de Pearson entre m√©trica e custo final | Coeficiente (-1 a 1) | An√°lise estat√≠stica |
| **M5** | Custo por Requisi√ß√£o | Custo m√©dio por requisi√ß√£o processada | R$ por requisi√ß√£o | Dataset de custos |
| **M6** | Erro de Valida√ß√£o Cruzada | Erro m√©dio em k-fold cross-validation (k=5) | Percentual (%) | Valida√ß√£o cruzada |
| **M7** | Consumo M√©dio de CPU | Utiliza√ß√£o percentual m√©dia de CPU | Percentual (%) | M√©tricas simuladas |
| **M8** | Consumo M√©dio de Mem√≥ria | Uso m√©dio de mem√≥ria RAM | Megabytes (MB) | M√©tricas simuladas |
| **M9** | Volume de Armazenamento | Quantidade total de storage utilizado | Gigabytes (GB) | M√©tricas simuladas |
| **M10** | Quantidade de Requisi√ß√µes | Volume de requisi√ß√µes por per√≠odo | Requisi√ß√µes/segundo | M√©tricas simuladas |
| **M11** | P-valor (ANOVA/Kruskal-Wallis) | Signific√¢ncia estat√≠stica da diferen√ßa entre modelos | Valor p | Teste estat√≠stico |
| **M12** | Diferen√ßa Treino/Teste | Diferen√ßa percentual de erro entre treino e teste | Percentual (%) | Compara√ß√£o de erros |
| **M13** | Desvio Padr√£o dos Erros | Variabilidade dos erros de previs√£o | Valor monet√°rio (R$) | An√°lise estat√≠stica |

---

## 4. Escopo e Contexto do Experimento

### 4.1 Escopo Funcional / de Processo (Inclu√≠do e Exclu√≠do)

#### ‚úÖ Inclu√≠do no Escopo:

**M√©tricas de Infraestrutura:**
- Consumo de CPU (percentual de utiliza√ß√£o)
- Consumo de mem√≥ria RAM (em MB)
- Volume de armazenamento (em GB)
- Quantidade de requisi√ß√µes/tr√°fego de rede (req/s)

**Modelos de Previs√£o:**
- Regress√£o Linear
- M√©dia M√≥vel Simples
- ARIMA (AutoRegressive Integrated Moving Average)
- Exponential Smoothing (Suaviza√ß√£o Exponencial)

**Janelas Temporais de An√°lise:**
- Previs√µes baseadas em 7 dias
- Previs√µes baseadas em 14 dias
- Previs√µes baseadas em 30 dias

**M√©tricas de Avalia√ß√£o:**
- MAE, RMSE, MAPE
- Erro de valida√ß√£o cruzada (k=5)
- An√°lise de correla√ß√£o entre m√©tricas e custos
- Testes estat√≠sticos (ANOVA ou Kruskal-Wallis)

**An√°lises:**
- Compara√ß√£o estat√≠stica entre modelos
- Identifica√ß√£o de vari√°veis mais preditivas
- An√°lise de estabilidade e generaliza√ß√£o
- Detec√ß√£o de overfitting

#### ‚ùå Exclu√≠do do Escopo:

**Aspectos T√©cnicos:**
- Implementa√ß√£o em ambiente cloud real (ser√° simulado)
- Integra√ß√£o com APIs de provedores cloud
- Monitoramento em tempo real
- Sistemas de alertas autom√°ticos
- Deploy de modelos em produ√ß√£o

**M√©tricas Adicionais:**
- Custos de transfer√™ncia de dados entre regi√µes
- Custos de servi√ßos gerenciados (bancos de dados, cache)
- Custos de suporte t√©cnico ou SLAs
- M√©tricas de lat√™ncia ou disponibilidade

**Modelos Avan√ßados:**
- Redes neurais ou deep learning
- Modelos ensemble complexos
- Prophet (Facebook) ou t√©cnicas de boosting
- Modelos espec√≠ficos de provedores (AWS Forecast, etc.)

**Aspectos Organizacionais:**
- An√°lise de ROI ou business case
- Processos de governan√ßa financeira
- Pol√≠ticas de chargeback entre departamentos
- Compliance ou auditoria financeira

### 4.2 Contexto do Estudo (Tipo de Organiza√ß√£o, Projeto, Experi√™ncia)

#### Tipo de Organiza√ß√£o:
**Contexto Acad√™mico** - Trabalho de Conclus√£o de Curso  
Embora seja um estudo acad√™mico, foi projetado para ter **aplicabilidade pr√°tica** em:
- Startups de tecnologia
- Pequenas e m√©dias empresas (PMEs) com infraestrutura cloud
- Times de DevOps em organiza√ß√µes de qualquer porte

#### Tipo de Projeto:
- **Natureza:** Experimento controlado com an√°lise quantitativa
- **Dura√ß√£o:** 5 meses (planejamento e execu√ß√£o)
- **Complexidade:** M√©dia (4 modelos, 3 janelas temporais, m√∫ltiplas m√©tricas)

#### Perfil de Experi√™ncia:
- **Pesquisador:** Estudante de gradua√ß√£o com conhecimento intermedi√°rio em:
  - Engenharia de Software
  - An√°lise de dados e estat√≠stica
  - Cloud computing (conceitual)
  - Python e bibliotecas de machine learning

#### Criticidade:
- **Baixa criticidade operacional** (ambiente simulado)
- **Alta criticidade acad√™mica** (requisito de TCC)
- **Potencial impacto pr√°tico** m√©dio-alto para empresas que adotarem os resultados

### 4.3 Premissas

1. **Dados de Uso:**
   - √â poss√≠vel obter e processar dados reais de traces p√∫blicos de cloud computing
   - Os traces do Google Cluster Data 2019 s√£o representativos de workloads cloud reais
   - A granularidade dos dados (5 minutos para 1 hora ap√≥s agrega√ß√£o) √© suficiente para capturar padr√µes relevantes

2. **Per√≠odo Analisado:**
   - 30 dias de hist√≥rico do dataset s√£o suficientes para treinamento
   - O per√≠odo extra√≠do representa comportamento t√≠pico de sistemas cloud
   - N√£o h√° eventos extraordin√°rios no per√≠odo espec√≠fico selecionado que distor√ßam completamente os padr√µes

3. **C√°lculo de Custos:**
   - As tabelas de precifica√ß√£o dos provedores permanecem est√°veis durante o per√≠odo
   - √â poss√≠vel estimar custos baseando-se em tabelas p√∫blicas (AWS, Azure, GCP)
   - A convers√£o de m√©tricas de uso (CPU, mem√≥ria) em custo monet√°rio segue modelo linear simplificado

4. **Modelos de Previs√£o:**
   - Os modelos escolhidos s√£o representativos das abordagens mais comuns
   - As implementa√ß√µes das bibliotecas (Scikit-learn, Statsmodels) s√£o confi√°veis
   - Hiperpar√¢metros padr√£o s√£o adequados para uma primeira compara√ß√£o

5. **Recursos Computacionais:**
   - O hardware dispon√≠vel √© suficiente para processar o dataset e treinar os modelos em tempo h√°bil
   - Python 3.10+ e bibliotecas necess√°rias est√£o dispon√≠veis e funcionais
   - Dataset do Kaggle (sample) √© acess√≠vel e tem tamanho gerenci√°vel

6. **Conhecimento T√©cnico:**
   - O pesquisador possui conhecimento suficiente para implementar os modelos
   - H√° suporte do orientador para decis√µes metodol√≥gicas cr√≠ticas
   - Documenta√ß√£o do Google Cluster Data √© suficiente para interpretar os dados corretamente

### 4.4 Restri√ß√µes

1. **Temporais:**
   - Prazo de 5 meses para conclus√£o (incluindo documenta√ß√£o)
   - Necessidade de cumprir datas de entrega intermedi√°rias (entregas 1-4)

2. **Financeiras:**
   - Or√ßamento zero (uso de ferramentas gratuitas/open-source apenas)
   - Uso de datasets p√∫blicos gratuitos (Google Cluster Data via Kaggle ou BigQuery free tier)

3. **T√©cnicas:**
   - Limita√ß√£o a modelos implement√°veis com bibliotecas Python gratuitas
   - Depend√™ncia de dados de traces p√∫blicos (contexto espec√≠fico do Google)
   - Processamento local (sem clusters ou infraestrutura distribu√≠da)
   - Necessidade de agregar/processar dados brutos do trace

4. **Metodol√≥gicas:**
   - Desenho experimental com fator √∫nico (tipo de modelo)
   - Dataset fixo (per√≠odo espec√≠fico de maio 2019)
   - Foco em an√°lise quantitativa (sem entrevistas ou estudos de caso)

5. **Organizacionais:**
   - Projeto individual (sem equipe de desenvolvimento)
   - Depend√™ncia da disponibilidade do orientador para revis√µes

6. **Escopo:**
   - Limita√ß√£o a 4 modelos de previs√£o (quest√£o de viabilidade)
   - Apenas m√©tricas de CPU e mem√≥ria do dataset (storage/rede s√£o estimados ou ausentes)
   - Dataset espec√≠fico de um provedor (Google), n√£o multi-cloud

### 4.5 Limita√ß√µes Previstas

#### Limita√ß√µes de Validade Externa (Generaliza√ß√£o):

1. **Contexto Espec√≠fico do Dataset:**
   - Dados provenientes exclusivamente de clusters Google (n√£o AWS, Azure, outros)
   - Workloads espec√≠ficos do Google (podem n√£o representar todas as empresas)
   - Per√≠odo espec√≠fico (maio 2019) pode n√£o capturar sazonalidades anuais
   - Diferentes provedores cloud t√™m caracter√≠sticas diferentes

2. **Precifica√ß√£o Estimada:**
   - Custos calculados com tabelas p√∫blicas, n√£o refletem custos reais Google
   - N√£o considera descontos corporativos, reserved instances ou savings plans
   - Modelo de precifica√ß√£o simplificado (linear) pode n√£o capturar complexidades reais

3. **Escala e Complexidade:**
   - Dataset de larga escala pode ter caracter√≠sticas diferentes de PMEs
   - M√∫ltiplos servi√ßos e interdepend√™ncias do Google n√£o s√£o replic√°veis em empresas menores
   - Padr√µes de uso de um hyperscaler podem n√£o se aplicar a todos os contextos

#### Limita√ß√µes de Validade Interna:

1. **Vari√°veis de Confus√£o:**
   - Poss√≠vel correla√ß√£o esp√∫ria entre m√©tricas devido √† simula√ß√£o
   - Dificuldade em isolar completamente o efeito de cada vari√°vel

2. **Vieses de Implementa√ß√£o:**
   - Escolha de hiperpar√¢metros pode favorecer alguns modelos
   - Qualidade da implementa√ß√£o pode variar entre modelos

#### Limita√ß√µes de Validade de Constructo:

1. **Medi√ß√£o de Custos:**
   - Custos simulados podem n√£o refletir descontos, reserved instances ou savings plans
   - Varia√ß√µes de pre√ßo por regi√£o n√£o s√£o consideradas

2. **Complexidade Reduzida:**
   - M√©tricas de infraestrutura s√£o simplifica√ß√£o da realidade
   - Fatores humanos e organizacionais n√£o s√£o capturados

#### Limita√ß√µes Pr√°ticas:

1. **Recursos Limitados:**
   - Tempo e capacidade computacional limitam a complexidade dos modelos
   - Impossibilidade de testar todos os modelos e configura√ß√µes poss√≠veis

2. **Experi√™ncia:**
   - Primeira experi√™ncia formal com experimenta√ß√£o controlada
   - Curva de aprendizado pode afetar qualidade inicial

**Estrat√©gias de Mitiga√ß√£o:** Estas limita√ß√µes ser√£o reconhecidas explicitamente nos resultados e discuss√£o do trabalho, com recomenda√ß√µes claras sobre contextos onde os resultados s√£o mais ou menos aplic√°veis.

---

## 5. Stakeholders e Impacto Esperado

### 5.1 Stakeholders Principais

| Stakeholder | Papel | Interesse no Experimento |
|-------------|-------|--------------------------|
| **Empresas e Startups** | Tomadores de decis√£o financeira | Modelos que ajudem a prever e controlar custos cloud |
| **Times DevOps** | Operadores de infraestrutura | Ferramentas para planejamento de escalabilidade e otimiza√ß√£o de recursos |
| **Desenvolvedores** | Criadores de aplica√ß√µes | Entendimento do impacto financeiro de decis√µes t√©cnicas (arquitetura, padr√µes de uso) |
| **Times Financeiros** | Gestores de or√ßamento | Previs√µes mais confi√°veis para planejamento or√ßament√°rio |
| **Gestores de TI** | Lideran√ßa t√©cnica | Dados para justificar investimentos e decis√µes estrat√©gicas |
| **Orientador Acad√™mico** | Supervisor do TCC | Qualidade metodol√≥gica e rigor cient√≠fico do experimento |
| **Comunidade Acad√™mica** | Pesquisadores | Contribui√ß√£o para √°rea de Engenharia de Software Experimental e FinOps |

### 5.2 Interesses e Expectativas dos Stakeholders

#### Empresas e Startups:
- **Expectativa:** Identificar modelo de previs√£o aplic√°vel na pr√°tica
- **Interesse:** Reduzir gastos inesperados em at√© 15-30%
- **Utilidade:** Implementar alertas preditivos de estouro de or√ßamento
- **Benef√≠cio:** ROI positivo atrav√©s de melhor planejamento financeiro

#### Times DevOps:
- **Expectativa:** Compreender quais m√©tricas monitorar prioritariamente
- **Interesse:** Correla√ß√£o clara entre m√©tricas t√©cnicas e impacto financeiro
- **Utilidade:** Dados para dimensionar infraestrutura preventivamente
- **Benef√≠cio:** Redu√ß√£o de incidentes relacionados a recursos (out of memory, throttling)

#### Desenvolvedores:
- **Expectativa:** Entender como decis√µes de c√≥digo/arquitetura afetam custos
- **Interesse:** Modelos que relacionem padr√µes de uso com custos espec√≠ficos
- **Utilidade:** Guidelines para desenvolvimento cost-aware
- **Benef√≠cio:** C√≥digo mais eficiente e econ√¥mico

#### Times Financeiros:
- **Expectativa:** Previs√µes confi√°veis para or√ßamentos trimestrais/anuais
- **Interesse:** Erro de previs√£o < 20%
- **Utilidade:** Justificativas quantitativas para aloca√ß√£o de recursos
- **Benef√≠cio:** Redu√ß√£o de ajustes or√ßament√°rios emergenciais

#### Gestores de TI:
- **Expectativa:** Evid√™ncias para tomada de decis√£o estrat√©gica
- **Interesse:** Compara√ß√£o objetiva entre diferentes abordagens preditivas
- **Utilidade:** Business case para investimento em ferramentas de FinOps
- **Benef√≠cio:** Melhor governan√ßa de custos cloud

#### Orientador e Comunidade Acad√™mica:
- **Expectativa:** Experimento metodologicamente rigoroso
- **Interesse:** Contribui√ß√£o cient√≠fica para √°rea de Engenharia de Software Experimental
- **Utilidade:** Refer√™ncia para futuros trabalhos em FinOps e previs√£o de custos
- **Benef√≠cio:** Avan√ßo do conhecimento na interse√ß√£o de ES e cloud computing

### 5.3 Impactos Potenciais no Processo / Produto

#### Durante a Execu√ß√£o do Experimento:

**Impactos Positivos:**
- **Aprendizado:** Ganho de conhecimento em t√©cnicas de s√©ries temporais e an√°lise preditiva
- **Metodologia:** Experi√™ncia pr√°tica com experimenta√ß√£o controlada
- **Documenta√ß√£o:** Cria√ß√£o de material de refer√™ncia sobre previs√£o de custos cloud

**Impactos Neutros:**
- **Tempo:** Dedica√ß√£o de ~5 meses ao experimento (esperado para TCC)
- **Recursos:** Uso de recursos computacionais locais (sem custo adicional)

**Impactos Negativos (Mitigados):**
- **Risco m√≠nimo:** Por ser simula√ß√£o, n√£o h√° risco de impactar sistemas em produ√ß√£o
- **Escopo limitado:** Foco em dados sint√©ticos pode gerar expectativas n√£o atendidas

#### P√≥s-Experimento:

**Impacto Acad√™mico:**
- Contribui√ß√£o para corpus de conhecimento em FinOps
- Poss√≠vel publica√ß√£o em workshops ou confer√™ncias de ES
- Refer√™ncia para trabalhos futuros sobre cloud cost optimization

**Impacto Pr√°tico:**
- Empresas podem implementar modelos testados
- Redu√ß√£o de desperd√≠cio financeiro em infraestrutura cloud
- Melhoria em processos de planejamento e governan√ßa

**Impacto no Produto/Processo:**
- **Curto prazo:** N√£o h√° produto direto, mas documenta√ß√£o e c√≥digo reutiliz√°veis
- **M√©dio prazo:** Potencial de evolu√ß√£o para ferramenta de previs√£o
- **Longo prazo:** Base para sistema de FinOps completo (alertas, dashboards, recomenda√ß√µes)

---

## 6. Riscos de Alto N√≠vel, Premissas e Crit√©rios de Sucesso

### 6.1 Riscos de Alto N√≠vel (Neg√≥cio, T√©cnicos, etc.)

#### Riscos de Neg√≥cio:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Resultados n√£o aplic√°veis na pr√°tica** | M√©dia | Alto | Usar dataset real (Google Cluster Data); validar com literatura |
| **Baixo interesse de stakeholders** | Baixa | M√©dio | Demonstrar aplicabilidade atrav√©s de casos de uso concretos |
| **Expectativas n√£o atendidas** | M√©dia | M√©dio | Comunicar claramente escopo e limita√ß√µes desde o in√≠cio |

#### Riscos T√©cnicos:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Dados reais com problemas de qualidade** | M√©dia | Alto | Pr√©-valida√ß√£o rigorosa; tratamento de outliers e valores faltantes |
| **Modelos com baixo poder preditivo** | M√©dia | Alto | Testar m√∫ltiplos modelos; ajustar hiperpar√¢metros se necess√°rio |
| **Problemas de implementa√ß√£o** | Baixa | M√©dio | Usar bibliotecas consolidadas (Scikit-learn, Statsmodels) |
| **Hardware insuficiente para processar dataset** | M√©dia | M√©dio | Usar sample do Kaggle (gerenci√°vel) ao inv√©s do dataset completo |
| **Bugs ou erros de c√≥digo** | M√©dia | M√©dio | Testes unit√°rios; revis√£o de c√≥digo; valida√ß√£o de resultados |

#### Riscos de Dados:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Dataset indispon√≠vel ou alterado** | Baixa | Alto | Fazer download e backup local; usar m√∫ltiplas fontes (Kaggle + BigQuery) |
| **Inconsist√™ncia no per√≠odo analisado** | Baixa | M√©dio | Valida√ß√£o de qualidade dos dados extra√≠dos; an√°lise explorat√≥ria |
| **Falta de variabilidade nos dados** | Baixa | M√©dio | Google Cluster Data tem alta variabilidade natural de workloads reais |

#### Riscos Metodol√≥gicos:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Vi√©s na compara√ß√£o de modelos** | M√©dia | Alto | Usar mesma m√©trica de avalia√ß√£o e mesmo dataset para todos |
| **Overfitting n√£o detectado** | M√©dia | Alto | Valida√ß√£o cruzada rigorosa; an√°lise de diferen√ßa treino/teste |
| **Falta de signific√¢ncia estat√≠stica** | M√©dia | Alto | Garantir tamanho de amostra adequado (30 execu√ß√µes por modelo) |

#### Riscos de Cronograma:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Atrasos na implementa√ß√£o** | M√©dia | Alto | Buffer de tempo no cronograma; entregas incrementais |
| **Complexidade subestimada** | M√©dia | M√©dio | Revis√£o peri√≥dica do progresso com orientador |
| **Problemas pessoais/sa√∫de** | Baixa | Alto | Adiantar entregas quando poss√≠vel; comunica√ß√£o transparente |

#### Riscos Externos:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Mudan√ßas em precifica√ß√£o de provedores** | Baixa | Baixo | Usar tabelas de pre√ßo fixas do momento inicial |
| **Indisponibilidade do orientador** | Baixa | M√©dio | Agendar reuni√µes com anteced√™ncia; documentar decis√µes |

### 6.2 Crit√©rios de Sucesso Globais (Go / No-Go)

#### Crit√©rios M√≠nimos de Sucesso (Must-Have):

‚úÖ **Crit√©rio 1: Modelos Funcionais**
- **Meta:** Implementar com sucesso pelo menos 3 dos 4 modelos propostos
- **Medida:** C√≥digo execut√°vel que gera previs√µes
- **Limiar:** 100% dos modelos rodando sem erros cr√≠ticos

‚úÖ **Crit√©rio 2: Avalia√ß√£o de Acur√°cia**
- **Meta:** Calcular MAE, RMSE e MAPE para todos os modelos
- **Medida:** M√©tricas de erro computadas e documentadas
- **Limiar:** Todas as m√©tricas calculadas para todos os modelos

‚úÖ **Crit√©rio 3: Compara√ß√£o Estat√≠stica**
- **Meta:** Realizar teste estat√≠stico comparando desempenho dos modelos
- **Medida:** ANOVA ou Kruskal-Wallis com p-valor calculado
- **Limiar:** Teste realizado com interpreta√ß√£o clara dos resultados

‚úÖ **Crit√©rio 4: Identifica√ß√£o de Melhor Modelo**
- **Meta:** Determinar qual modelo apresenta menor erro
- **Medida:** Ranking dos modelos por MAE
- **Limiar:** Conclus√£o clara sobre qual modelo √© superior

#### Crit√©rios Desej√°veis de Sucesso (Should-Have):

üéØ **Crit√©rio 5: Erro Aceit√°vel**
- **Meta:** Atingir erro m√©dio < 20% em ao menos um modelo
- **Medida:** MAPE do melhor modelo
- **Limiar:** MAPE < 20% (desej√°vel); < 30% (aceit√°vel)

üéØ **Crit√©rio 6: Identifica√ß√£o de Vari√°veis Preditoras**
- **Meta:** Determinar quais m√©tricas mais influenciam o custo
- **Medida:** Correla√ß√£o entre m√©tricas (CPU, mem√≥ria, etc.) e custo
- **Limiar:** Identificar pelo menos 2 m√©tricas com correla√ß√£o > 0.6

üéØ **Crit√©rio 7: Generaliza√ß√£o**
- **Meta:** Validar que modelos generalizam para dados n√£o vistos
- **Medida:** Diferen√ßa entre erro de treino e teste
- **Limiar:** Diferen√ßa < 15% (sem overfitting severo)

üéØ **Crit√©rio 8: Signific√¢ncia Estat√≠stica**
- **Meta:** Provar diferen√ßa significativa entre modelos
- **Medida:** p-valor do teste estat√≠stico
- **Limiar:** p < 0.05 (diferen√ßa significativa)

#### Crit√©rios Extras de Sucesso (Nice-to-Have):

‚≠ê **Crit√©rio 9: An√°lise de Estabilidade**
- **Meta:** Avaliar robustez dos modelos em diferentes cen√°rios
- **Medida:** Vari√¢ncia dos erros
- **Limiar:** Modelo mais est√°vel identificado

‚≠ê **Crit√©rio 10: Documenta√ß√£o Completa**
- **Meta:** Documentar todo o processo experimental
- **Medida:** Se√ß√µes do plano experimental preenchidas
- **Limiar:** 100% das se√ß√µes 1-12 completas

#### Crit√©rios de Qualidade Cient√≠fica:

üìä **Crit√©rio 11: Rigor Metodol√≥gico**
- Desenho experimental apropriado
- Vari√°veis de controle identificadas e mantidas constantes
- An√°lise estat√≠stica correta

üìä **Crit√©rio 12: Reprodutibilidade**
- C√≥digo documentado e versionado
- Instru√ß√µes claras para replica√ß√£o
- Dados sint√©ticos ger√°veis novamente

### 6.3 Crit√©rios de Parada Antecipada (Pr√©-Execu√ß√£o)

O experimento deve ser **adiado ou cancelado** se qualquer uma das seguintes condi√ß√µes ocorrer antes do in√≠cio da execu√ß√£o:

‚ùå **Parada Tipo 1 - Recursos Insuficientes:**
- Hardware dispon√≠vel n√£o consegue processar os modelos em tempo h√°bil
- Bibliotecas necess√°rias n√£o funcionam no ambiente dispon√≠vel
- **A√ß√£o:** Reduzir escopo (menos modelos ou janelas menores) ou buscar recursos alternativos

‚ùå **Parada Tipo 2 - Inviabilidade Metodol√≥gica:**
- Impossibilidade de gerar dados sint√©ticos real√≠sticos
- Modelos escolhidos s√£o inadequados para o problema ap√≥s revis√£o mais profunda
- **A√ß√£o:** Revisar desenho experimental com orientador

‚ùå **Parada Tipo 3 - Mudan√ßa de Escopo:**
- Orientador solicita mudan√ßa radical no tema do TCC
- Prazos acad√™micos s√£o alterados drasticamente
- **A√ß√£o:** Renegociar escopo ou prazos

‚ùå **Parada Tipo 4 - Problemas Pessoais:**
- Problemas de sa√∫de graves do pesquisador
- Impossibilidade de dedicar tempo m√≠nimo necess√°rio
- **A√ß√£o:** Solicitar extens√£o de prazo ou trancamento

‚ùå **Parada Tipo 5 - Riscos Identificados como Cr√≠ticos:**
- Ap√≥s revis√£o, identifica√ß√£o de risco n√£o mitig√°vel com alto impacto
- Feedback do orientador indicando inviabilidade fundamental
- **A√ß√£o:** Replanejamento completo ou mudan√ßa de tema

**Processo de Decis√£o:**
1. Identifica√ß√£o do problema que motiva a parada
2. Discuss√£o com orientador
3. Explora√ß√£o de alternativas de mitiga√ß√£o
4. Decis√£o formal (continuar, adiar ou cancelar)
5. Documenta√ß√£o da decis√£o

---

## 7. Modelo Conceitual e Hip√≥teses

### 7.1 Modelo Conceitual do Experimento

#### Modelo Conceitual Geral

O modelo conceitual deste experimento baseia-se na premissa de que **custos de infraestrutura cloud s√£o fun√ß√£o direta de m√©tricas de uso** e que **modelos matem√°ticos podem capturar padr√µes hist√≥ricos para prever custos futuros**.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MODELO CONCEITUAL                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        M√âTRICAS DE USO                    MODELO DE              CUSTO
       (Independentes)                     PREVIS√ÉO              PREVISTO
                                          (Tratamento)          (Dependente)
                                                
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                      
    ‚îÇ  CPU (%)        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                 
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ                                 
                           ‚îÇ                                 
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Mem√≥ria (MB)   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ Regress√£o    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ  Custo   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ         ‚îÇ Linear       ‚îÇ       ‚îÇ (R$)     ‚îÇ
                           ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ                ‚îÇ                     ‚îÇ
    ‚îÇ Storage (GB)    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                ‚îÇ                     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
                           ‚îÇ         ‚îÇ M√©dia M√≥vel  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
    ‚îÇ Requisi√ß√µes     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ                     ‚îÇ
    ‚îÇ (req/s)         ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ ARIMA        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
                                            ‚îÇ                     ‚îÇ
         Padr√µes                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
         Hist√≥ricos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ Exponential  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         (s√©ries temporais)          ‚îÇ Smoothing    ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                            
                                            ‚îÇ
                                            ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ   AVALIA√á√ÉO  ‚îÇ
                                     ‚îÇ MAE, RMSE,   ‚îÇ
                                     ‚îÇ    MAPE      ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                            ‚îÇ
                                            ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ  COMPARA√á√ÉO  ‚îÇ
                                     ‚îÇ ESTAT√çSTICA  ‚îÇ
                                     ‚îÇ (ANOVA/K-W)  ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Rela√ß√µes Causais Assumidas:

1. **M√©tricas ‚Üí Custo:**
   - Maior uso de CPU ‚Üí Maior custo de compute
   - Mais requisi√ß√µes ‚Üí Maior custo de rede e compute
   - Mais armazenamento ‚Üí Maior custo de storage
   - Mais mem√≥ria ‚Üí Maior custo de inst√¢ncias maiores

2. **Hist√≥rico ‚Üí Previs√£o:**
   - Padr√µes passados de uso permitem prever padr√µes futuros
   - Tend√™ncias e sazonalidade se repetem ao longo do tempo
   - Correla√ß√µes entre m√©tricas s√£o est√°veis

3. **Modelo ‚Üí Precis√£o:**
   - Diferentes modelos capturam diferentes aspectos dos dados
   - Modelos mais complexos (ARIMA) podem capturar padr√µes n√£o-lineares
   - Modelos simples (m√©dia m√≥vel) podem ser mais robustos a ru√≠do

#### Vari√°vel Moderadora:
- **Janela Temporal:** O tamanho da janela de observa√ß√£o (7, 14 ou 30 dias) pode moderar a rela√ß√£o entre modelo e precis√£o

#### Pressuposto Central:
**"O tipo de modelo de previs√£o utilizado influencia significativamente o erro de previs√£o de custos cloud, sendo poss√≠vel identificar um modelo superior para o contexto estudado."**

### 7.2 Hip√≥teses Formais (H0, H1)

#### Hip√≥tese Principal:

**H0 (Hip√≥tese Nula):**
> N√£o existe diferen√ßa estatisticamente significativa na precis√£o (medida por MAE, RMSE ou MAPE) entre os modelos de previs√£o analisados (Regress√£o Linear, M√©dia M√≥vel, ARIMA e Exponential Smoothing).

**Formalmente:** Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ = Œº‚ÇÑ

Onde:
- Œº‚ÇÅ = erro m√©dio da Regress√£o Linear
- Œº‚ÇÇ = erro m√©dio da M√©dia M√≥vel
- Œº‚ÇÉ = erro m√©dio do ARIMA
- Œº‚ÇÑ = erro m√©dio do Exponential Smoothing

**H1 (Hip√≥tese Alternativa):**
> Existe diferen√ßa estatisticamente significativa na precis√£o entre pelo menos dois dos modelos de previs√£o analisados.

**Formalmente:** ‚àÉ i,j ‚àà {1,2,3,4} tal que Œº·µ¢ ‚â† Œº‚±º

---

#### Hip√≥teses Espec√≠ficas (Sub-Hip√≥teses):

**H1.1 - Regress√£o Linear vs. S√©ries Temporais:**
- **H1.1.0 (Nula):** A regress√£o linear apresenta erro m√©dio igual aos modelos de s√©ries temporais (ARIMA e Exponential Smoothing)
- **H1.1.1 (Alternativa):** A regress√£o linear apresenta erro m√©dio diferente dos modelos de s√©ries temporais
- **Dire√ß√£o esperada:** Modelos de s√©ries temporais tendem a ter menor erro (capturam depend√™ncia temporal)

**H1.2 - ARIMA vs. Modelos Simples:**
- **H1.2.0 (Nula):** ARIMA apresenta erro m√©dio igual aos modelos simples (Regress√£o Linear e M√©dia M√≥vel)
- **H1.2.1 (Alternativa):** ARIMA apresenta erro m√©dio menor que modelos simples
- **Dire√ß√£o esperada:** ARIMA < (Regress√£o Linear, M√©dia M√≥vel)
- **Justificativa:** ARIMA captura autocorrela√ß√£o, tend√™ncia e sazonalidade

**H1.3 - Exponential Smoothing em Dados com Tend√™ncia:**
- **H1.3.0 (Nula):** Exponential Smoothing n√£o gera previs√µes mais est√°veis que outros modelos em dados com tend√™ncia
- **H1.3.1 (Alternativa):** Exponential Smoothing gera previs√µes mais est√°veis (menor vari√¢ncia de erro) em dados com tend√™ncia
- **Dire√ß√£o esperada:** œÉ¬≤(Exp.Smoothing) < œÉ¬≤(outros modelos)
- **Justificativa:** Suaviza√ß√£o exponencial d√° peso maior a observa√ß√µes recentes, reduzindo impacto de ru√≠do

**H1.4 - Efeito da Janela Temporal:**
- **H1.4.0 (Nula):** O tamanho da janela temporal (7, 14 ou 30 dias) n√£o afeta significativamente o erro de previs√£o
- **H1.4.1 (Alternativa):** Janelas temporais maiores resultam em menor erro de previs√£o
- **Dire√ß√£o esperada:** Erro(30 dias) < Erro(14 dias) < Erro(7 dias)
- **Justificativa:** Mais dados hist√≥ricos permitem melhor captura de padr√µes

**H1.5 - Correla√ß√£o M√©trica-Custo:**
- **H1.5.0 (Nula):** N√£o h√° diferen√ßa significativa na correla√ß√£o de diferentes m√©tricas (CPU, mem√≥ria, requisi√ß√µes, storage) com o custo final
- **H1.5.1 (Alternativa):** CPU e requisi√ß√µes apresentam correla√ß√£o significativamente maior com custo do que mem√≥ria e storage
- **Dire√ß√£o esperada:** Corr(CPU, Custo) > Corr(Mem√≥ria, Custo)

### 7.3 N√≠vel de Signific√¢ncia e Considera√ß√µes de Poder

#### N√≠vel de Signific√¢ncia:
**Œ± = 0.05 (5%)**

- Padr√£o amplamente aceito em ci√™ncias experimentais
- Representa 5% de chance de rejeitar H0 quando ela √© verdadeira (Erro Tipo I)
- Ser√° usado em todos os testes estat√≠sticos (ANOVA, Kruskal-Wallis, testes t)

**Interpreta√ß√£o:**
- Se p-valor < 0.05 ‚Üí Rejeitar H0 (diferen√ßa √© estatisticamente significativa)
- Se p-valor ‚â• 0.05 ‚Üí N√£o rejeitar H0 (n√£o h√° evid√™ncia suficiente de diferen√ßa)

#### Poder Estat√≠stico:

**Poder Desejado:** 1 - Œ≤ = 0.80 (80%)

- Representa 80% de chance de detectar uma diferen√ßa real quando ela existe
- Œ≤ = 0.20 (20% de chance de Erro Tipo II - n√£o detectar diferen√ßa que existe)

**C√°lculo de Tamanho de Amostra:**
Para alcan√ßar poder de 80% com Œ± = 0.05:
- **Repeti√ß√µes por modelo:** n = 30 execu√ß√µes
- **Total de observa√ß√µes:** 30 √ó 4 modelos = 120 observa√ß√µes
- **Justificativa:** Teorema do Limite Central garante distribui√ß√£o normal com n ‚â• 30

**Tamanho de Efeito Detect√°vel:**
Com n = 30 por grupo, √© poss√≠vel detectar:
- Diferen√ßa de efeito m√©dio (d de Cohen ‚âà 0.5)
- Diferen√ßa de ~15-20% no erro m√©dio entre modelos

**Considera√ß√µes:**

1. **Repetibilidade:**
   - Cada modelo ser√° executado 30 vezes com inicializa√ß√µes aleat√≥rias diferentes
   - Reduz impacto de variabilidade aleat√≥ria
   - Permite c√°lculo confi√°vel de intervalos de confian√ßa

2. **M√∫ltiplas Compara√ß√µes:**
   - Com 4 modelos, h√° 6 compara√ß√µes par-a-par poss√≠veis
   - Considerar corre√ß√£o de Bonferroni se necess√°rio: Œ±_ajustado = 0.05/6 = 0.0083
   - Usar post-hoc tests (Tukey HSD) ap√≥s ANOVA se H0 for rejeitada

3. **Valida√ß√£o Cruzada:**
   - K-fold com k = 5 aumenta o poder estat√≠stico
   - Cada modelo √© avaliado em 5 parti√ß√µes diferentes dos dados
   - Total efetivo de avalia√ß√µes: 30 execu√ß√µes √ó 5 folds = 150 avalia√ß√µes por modelo

4. **Sensibilidade:**
   - Se diferen√ßas forem sutis (< 10% de erro), poder pode ser insuficiente
   - Nesse caso, aumentar n para 50 ou considerar Œ± = 0.10 mais liberal

**Limita√ß√£o:**
Por usar dados sint√©ticos, o poder estat√≠stico √© suficiente para detectar diferen√ßas entre modelos, mas a validade externa (generaliza√ß√£o para dados reais) requer valida√ß√£o futura.

---

## 8. Vari√°veis, Fatores, Tratamentos e Objetos de Estudo

### 8.1 Objetos de Estudo

Os **objetos de estudo** s√£o as s√©ries temporais de m√©tricas de uso de infraestrutura cloud e os custos associados.

**Descri√ß√£o Detalhada:**

1. **S√©ries Temporais de M√©tricas:**
   - **CPU:** Percentual de utiliza√ß√£o ao longo do tempo
   - **Mem√≥ria:** Consumo em MB ao longo do tempo
   - **Armazenamento:** Volume em GB ao longo do tempo
   - **Requisi√ß√µes:** Taxa de requisi√ß√µes por segundo ao longo do tempo

2. **S√©rie Temporal de Custos:**
   - Custo calculado para cada per√≠odo de tempo (hora)
   - Baseado em tabelas de precifica√ß√£o de provedores cloud
   - Agrega√ß√£o das m√©tricas com pesos espec√≠ficos

**Caracter√≠sticas dos Objetos:**
- **Granularidade:** Hor√°ria (1 registro por hora)
- **Dura√ß√£o:** 30 dias (720 registros)
- **Tipo:** Dados sint√©ticos real√≠sticos
- **Formato:** S√©ries temporais univariadas e multivariadas

### 8.2 Sujeitos / Participantes (Vis√£o Geral)

**Importante:** Este experimento **n√£o envolve sujeitos humanos**. Os "sujeitos" s√£o as **execu√ß√µes dos modelos** sobre os dados.

**Caracteriza√ß√£o:**
- **Tipo:** Execu√ß√µes algor√≠tmicas (modelos de previs√£o)
- **Quantidade:** 30 execu√ß√µes √ó 4 modelos = 120 execu√ß√µes totais
- **Aleatoriza√ß√£o:** Cada execu√ß√£o usa seed aleat√≥ria diferente para:
  - Divis√£o treino/teste
  - Inicializa√ß√£o de par√¢metros (quando aplic√°vel)
  - Sele√ß√£o de folds na valida√ß√£o cruzada

**Equivalente a "Participantes" em Experimentos Tradicionais:**
- Cada execu√ß√£o de um modelo pode ser vista como um "participante"
- Diferentes execu√ß√µes capturam variabilidade natural do processo
- Permite an√°lise estat√≠stica robusta (m√©dia, desvio padr√£o, intervalos de confian√ßa)

### 8.3 Vari√°veis Independentes (Fatores) e seus N√≠veis

#### Fator Principal:

**F1: MODELO DE PREVIS√ÉO**

| N√≠vel | Descri√ß√£o | Sigla | Caracter√≠sticas |
|-------|-----------|-------|-----------------|
| **N√≠vel 1** | Regress√£o Linear | RL | Modelo simples, assume rela√ß√£o linear entre m√©tricas e custo |
| **N√≠vel 2** | M√©dia M√≥vel Simples | MM | M√©dia dos √∫ltimos N per√≠odos, sem considerar tend√™ncia |
| **N√≠vel 3** | ARIMA | ARIMA | Modelo de s√©ries temporais, captura autocorrela√ß√£o e tend√™ncia |
| **N√≠vel 4** | Exponential Smoothing | ES | Suaviza√ß√£o exponencial, d√° peso maior a observa√ß√µes recentes |

**Natureza do Fator:**
- **Tipo:** Categ√≥rico nominal
- **N√≠veis:** 4
- **Manipula√ß√£o:** Controlada experimentalmente (escolha do pesquisador)

#### Fator Secund√°rio (Explorat√≥rio):

**F2: JANELA TEMPORAL**

| N√≠vel | Descri√ß√£o | Uso |
|-------|-----------|-----|
| **N√≠vel 1** | 7 dias | Janela curta, previs√µes de curto prazo |
| **N√≠vel 2** | 14 dias | Janela m√©dia |
| **N√≠vel 3** | 30 dias | Janela longa, captura padr√µes de longo prazo |

**Natureza do Fator:**
- **Tipo:** Categ√≥rico ordinal
- **N√≠veis:** 3
- **Manipula√ß√£o:** An√°lise secund√°ria (n√£o √© foco principal, mas ser√° explorado)

### 8.4 Tratamentos (Condi√ß√µes Experimentais)

Os **tratamentos** correspondem aos 4 modelos de previs√£o que ser√£o aplicados:

#### Tratamento T1: Regress√£o Linear (RL)

**Descri√ß√£o:**
Modelo que assume rela√ß√£o linear entre m√©tricas de uso (X) e custo (Y):

Y = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑CPU + Œ≤‚ÇÇ¬∑Mem√≥ria + Œ≤‚ÇÉ¬∑Storage + Œ≤‚ÇÑ¬∑Requisi√ß√µes + Œµ

**Caracter√≠sticas:**
- **Complexidade:** Baixa
- **Vantagens:** Simples, interpret√°vel, r√°pido
- **Desvantagens:** N√£o captura depend√™ncia temporal, assume linearidade
- **Implementa√ß√£o:** `sklearn.linear_model.LinearRegression`
- **Hiperpar√¢metros:** Nenhum (usa defaults)

#### Tratamento T2: M√©dia M√≥vel Simples (MM)

**Descri√ß√£o:**
Previs√£o baseada na m√©dia dos √∫ltimos N per√≠odos:

≈∂‚Çú‚Çä‚ÇÅ = (Y‚Çú + Y‚Çú‚Çã‚ÇÅ + ... + Y‚Çú‚Çã‚Çô‚Çä‚ÇÅ) / N

**Caracter√≠sticas:**
- **Complexidade:** Muito baixa
- **Vantagens:** Extremamente simples, n√£o requer treinamento
- **Desvantagens:** N√£o captura tend√™ncias, lag em mudan√ßas bruscas
- **Implementa√ß√£o:** Numpy / Pandas
- **Hiperpar√¢metros:** N = 7 per√≠odos (janela de 7 horas)

#### Tratamento T3: ARIMA

**Descri√ß√£o:**
Modelo AutoRegressive Integrated Moving Average - captura autocorrela√ß√£o, tend√™ncia e m√©dia m√≥vel:

ARIMA(p, d, q):
- p = ordem autoregressiva
- d = ordem de diferencia√ß√£o (estacionariedade)
- q = ordem de m√©dia m√≥vel

**Caracter√≠sticas:**
- **Complexidade:** Alta
- **Vantagens:** Captura depend√™ncia temporal, tend√™ncias, sazonalidade
- **Desvantagens:** Requer estacionariedade, pode ser lento, dif√≠cil de interpretar
- **Implementa√ß√£o:** `statsmodels.tsa.arima.model.ARIMA`
- **Hiperpar√¢metros:** Auto-determinados via grid search ou AIC/BIC
  - Candidatos: ARIMA(1,1,1), ARIMA(2,1,2), ARIMA(1,1,0)

#### Tratamento T4: Exponential Smoothing (ES)

**Descri√ß√£o:**
Suaviza√ß√£o exponencial - d√° peso exponencialmente decrescente a observa√ß√µes mais antigas:

≈∂‚Çú‚Çä‚ÇÅ = Œ±¬∑Y‚Çú + (1-Œ±)¬∑≈∂‚Çú

Onde Œ± √© o par√¢metro de suaviza√ß√£o (0 < Œ± < 1)

**Caracter√≠sticas:**
- **Complexidade:** M√©dia
- **Vantagens:** Reage rapidamente a mudan√ßas, suaviza ru√≠do, simples de entender
- **Desvantagens:** N√£o captura sazonalidade complexa (vers√£o simples)
- **Implementa√ß√£o:** `statsmodels.tsa.holtwinters.ExponentialSmoothing`
- **Hiperpar√¢metros:** Œ± (suaviza√ß√£o), tend√™ncia (add/mul), sazonalidade (none/add/mul)
  - Usar Holt-Winters se necess√°rio capturar tend√™ncia + sazonalidade

### 8.5 Vari√°veis Dependentes (Respostas)

As **vari√°veis dependentes** s√£o as m√©tricas que medem a qualidade da previs√£o:

| ID | Vari√°vel | Descri√ß√£o | F√≥rmula | Unidade | Interpreta√ß√£o |
|----|----------|-----------|---------|---------|---------------|
| **VD1** | MAE | Mean Absolute Error | `Œ£|y·µ¢ - ≈∑·µ¢| / n` | R$ | Menor √© melhor; mesma escala do custo |
| **VD2** | RMSE | Root Mean Squared Error | `‚àö(Œ£(y·µ¢ - ≈∑·µ¢)¬≤ / n)` | R$ | Menor √© melhor; penaliza erros grandes |
| **VD3** | MAPE | Mean Absolute Percentage Error | `Œ£|(y·µ¢ - ≈∑·µ¢)/y·µ¢| / n √ó 100` | % | Menor √© melhor; erro relativo |
| **VD4** | Erro Valida√ß√£o | Erro em valida√ß√£o cruzada | M√©dia dos erros em k-folds | % | Mede generaliza√ß√£o |
| **VD5** | Vari√¢ncia Erro | Variabilidade do erro | `Var(erros)` | R$¬≤ | Menor √© melhor; mede estabilidade |
| **VD6** | R¬≤ | Coeficiente de Determina√ß√£o | `1 - (RSS/TSS)` | Adimensional | Maior √© melhor (0 a 1) |

**Vari√°vel Prim√°ria (Outcome Principal):**
- **MAE** ser√° usada como m√©trica prim√°ria para compara√ß√£o
- Raz√£o: Interpret√°vel, mesma escala do custo, robusta a outliers

**Vari√°veis Secund√°rias:**
- RMSE, MAPE: Complementam a an√°lise
- Erro Valida√ß√£o: Verifica generaliza√ß√£o
- Vari√¢ncia Erro: Avalia estabilidade

### 8.6 Vari√°veis de Controle / Bloqueio

Vari√°veis que **n√£o s√£o objeto de estudo** mas que podem afetar os resultados e, portanto, devem ser **mantidas constantes**:

| Vari√°vel de Controle | Como ser√° Controlada | Justificativa |
|----------------------|----------------------|---------------|
| **Dataset de Entrada** | Todos os modelos usar√£o exatamente os mesmos dados sint√©ticos | Garantir comparabilidade |
| **Per√≠odo de An√°lise** | Mesmos 30 dias para todos os modelos | Eliminar varia√ß√£o temporal |
| **Divis√£o Treino/Teste** | Mesma divis√£o 70%-30% para todos (com mesmo seed em cada execu√ß√£o) | Equidade na avalia√ß√£o |
| **M√©tricas de Entrada** | Mesmas 4 m√©tricas (CPU, mem√≥ria, storage, requisi√ß√µes) | Isonomia de informa√ß√£o |
| **Granularidade Temporal** | Granularidade hor√°ria para todos | Consist√™ncia temporal |
| **Ambiente Computacional** | Mesma m√°quina, mesmo Python, mesmas bibliotecas | Eliminar varia√ß√£o de hardware/software |
| **Pr√©-processamento** | Mesma normaliza√ß√£o/padroniza√ß√£o para todos os modelos | Igualdade de condi√ß√µes |
| **M√©trica de Avalia√ß√£o** | Mesmos c√°lculos de MAE, RMSE, MAPE para todos | Comparabilidade direta |
| **Ordem de Execu√ß√£o** | Ordem randomizada das execu√ß√µes | Evitar vi√©s temporal |
| **Tabela de Pre√ßos** | Mesma tabela de pre√ßos fixa | Eliminar mudan√ßas externas |

**Bloqueio:**
N√£o h√° necessidade de bloqueio formal pois:
- N√£o h√° sujeitos humanos (que poderiam ter caracter√≠sticas individuais)
- Todas as execu√ß√µes usam o mesmo ambiente computacional
- Aleatoriza√ß√£o da ordem de execu√ß√£o √© suficiente

### 8.7 Poss√≠veis Vari√°veis de Confus√£o Conhecidas

Vari√°veis que **podem distorcer os resultados** se n√£o forem adequadamente tratadas:

#### Confus√£o 1: Qualidade da Implementa√ß√£o

**Descri√ß√£o:** Modelos mais complexos podem ter implementa√ß√£o com mais bugs ou menos otimizada

**Mitiga√ß√£o:**
- Usar bibliotecas consolidadas (Scikit-learn, Statsmodels)
- Testar implementa√ß√µes com datasets conhecidos
- Validar resultados intermedi√°rios

**Monitoramento:**
- Revisar c√≥digo com orientador
- Comparar com exemplos da documenta√ß√£o oficial

---

#### Confus√£o 2: Hiperpar√¢metros N√£o-√ìtimos

**Descri√ß√£o:** Alguns modelos podem n√£o ter hiperpar√¢metros otimizados, favorecendo outros

**Mitiga√ß√£o:**
- Usar valores padr√£o das bibliotecas como baseline
- Para ARIMA, fazer grid search simples de par√¢metros (p,d,q)
- Documentar escolha de hiperpar√¢metros

**Monitoramento:**
- Se resultados forem inesperados, revisar hiperpar√¢metros
- An√°lise de sensibilidade (opcional)

---

#### Confus√£o 3: Overfitting Despercebido

**Descri√ß√£o:** Modelo pode ter bom desempenho no treino mas p√©ssimo no teste

**Mitiga√ß√£o:**
- Valida√ß√£o cruzada k-fold (k=5)
- Monitorar diferen√ßa entre erro de treino e teste
- Usar m√©trica de generaliza√ß√£o expl√≠cita

**Monitoramento:**
- Calcular M12 (Diferen√ßa treino/teste)
- Flagging se diferen√ßa > 15%

---

#### Confus√£o 4: Dados Sint√©ticos N√£o-Real√≠sticos

**Descri√ß√£o:** Simula√ß√£o pode favorecer artificialmente um tipo de modelo

**Mitiga√ß√£o:**
- Basear simula√ß√£o em papers e documenta√ß√£o
- Incluir ru√≠do, tend√™ncia e sazonalidade
- Validar padr√µes com especialistas (orientador)

**Monitoramento:**
- An√°lise explorat√≥ria dos dados sint√©ticos
- Compara√ß√£o com benchmarks da literatura

---

#### Confus√£o 5: Vari√¢ncia Aleat√≥ria

**Descri√ß√£o:** Resultados podem variar significativamente entre execu√ß√µes devido a aleatoriedade

**Mitiga√ß√£o:**
- Executar cada modelo 30 vezes
- Usar seeds aleat√≥rias diferentes
- Reportar m√©dia e intervalo de confian√ßa

**Monitoramento:**
- Calcular desvio padr√£o dos erros
- Verificar se intervalos de confian√ßa se sobrep√µem

---

#### Confus√£o 6: Ordem de Execu√ß√£o

**Descri√ß√£o:** Modelos executados primeiro podem ter condi√ß√µes diferentes (cache, temperatura CPU)

**Mitiga√ß√£o:**
- Randomizar ordem de execu√ß√£o dos modelos
- Limpar cache entre execu√ß√µes
- Medir tempo de execu√ß√£o para detectar anomalias

**Monitoramento:**
- An√°lise de vari√¢ncia por ordem de execu√ß√£o
- Verificar se h√° padr√µes sistem√°ticos

---

### Resumo das Vari√°veis (Tabela Consolidada)

| Vari√°vel | Tipo | Descri√ß√£o | Valores/N√≠veis | Papel no Experimento |
|----------|------|-----------|----------------|----------------------|
| **Modelo de Previs√£o** | Independente (Fator) | Algoritmo usado para prever custos | RL, MM, ARIMA, ES | Tratamento principal |
| **Janela Temporal** | Independente (Fator Secund√°rio) | Per√≠odo de hist√≥rico usado | 7, 14, 30 dias | An√°lise explorat√≥ria |
| **MAE** | Dependente (Resposta) | Erro absoluto m√©dio | Cont√≠nuo (R$) | Outcome prim√°rio |
| **RMSE** | Dependente (Resposta) | Raiz do erro quadr√°tico m√©dio | Cont√≠nuo (R$) | Outcome secund√°rio |
| **MAPE** | Dependente (Resposta) | Erro percentual m√©dio | Cont√≠nuo (%) | Outcome secund√°rio |
| **Erro Valida√ß√£o** | Dependente (Resposta) | Erro em valida√ß√£o cruzada | Cont√≠nuo (%) | Medida de generaliza√ß√£o |
| **Vari√¢ncia Erro** | Dependente (Resposta) | Estabilidade das previs√µes | Cont√≠nuo (R$¬≤) | Medida de robustez |
| **CPU M√©dia** | Controle | Utiliza√ß√£o m√©dia de CPU | Cont√≠nuo (%) | Mantida constante |
| **Mem√≥ria M√©dia** | Controle | Consumo m√©dio de RAM | Cont√≠nuo (MB) | Mantida constante |
| **Storage** | Controle | Volume de armazenamento | Cont√≠nuo (GB) | Mantida constante |
| **Requisi√ß√µes** | Controle | Taxa de requisi√ß√µes | Cont√≠nuo (req/s) | Mantida constante |
| **Dataset** | Controle | Dados usados para treino/teste | Mesmo para todos | Mantida constante |
| **Divis√£o Treino/Teste** | Controle | Propor√ß√£o 70%-30% | Fixa | Mantida constante |
| **Qualidade Implementa√ß√£o** | Confus√£o | Bugs ou otimiza√ß√£o de c√≥digo | Vari√°vel | Mitigada por bibliotecas |
| **Hiperpar√¢metros** | Confus√£o | Configura√ß√£o dos modelos | Vari√°vel | Documentada e justificada |

---
## 9. Desenho Experimental

### 9.1 Tipo de Desenho (Completamente Randomizado, Blocos, Fatorial, etc.)

**Tipo de Desenho:** **Completamente Aleatorizado (Completely Randomized Design - CRD)** com repeti√ß√µes

#### Justificativa:

1. **Adequa√ß√£o ao Problema:**
   - H√° apenas um fator principal (tipo de modelo de previs√£o)
   - N√£o h√° necessidade de blocos (ambiente homog√™neo, dados sint√©ticos)
   - Todos os modelos s√£o aplicados aos mesmos dados, garantindo equidade

2. **Vantagens para Este Contexto:**
   - **Simplicidade:** F√°cil de implementar e analisar
   - **Flexibilidade:** Permite diferentes n√∫meros de repeti√ß√µes por tratamento se necess√°rio
   - **Poder Estat√≠stico:** Com 30 repeti√ß√µes, fornece poder adequado para detectar diferen√ßas

3. **Caracter√≠sticas do Desenho:**
   - **Aleatoriza√ß√£o completa:** Ordem de execu√ß√£o dos modelos √© randomizada
   - **Repeti√ß√µes:** 30 execu√ß√µes independentes de cada modelo
   - **Controle rigoroso:** Todas as vari√°veis de controle mantidas constantes
   - **Valida√ß√£o cruzada:** k-fold (k=5) adiciona robustez

#### Estrutura do Experimento:

```
Tratamentos:    T1 (RL)  |  T2 (MM)  |  T3 (ARIMA)  |  T4 (ES)
                   ‚Üì           ‚Üì            ‚Üì            ‚Üì
Repeti√ß√µes:     n=30        n=30         n=30         n=30
                   ‚Üì           ‚Üì            ‚Üì            ‚Üì
Medidas:        MAE         MAE          MAE          MAE
                RMSE        RMSE         RMSE         RMSE
                MAPE        MAPE         MAPE         MAPE
                   ‚Üì           ‚Üì            ‚Üì            ‚Üì
An√°lise:    ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ANOVA ou Kruskal-Wallis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí
                   ‚Üì
           Compara√ß√µes Post-Hoc (Tukey HSD)
```

#### Alternativa N√£o Selecionada:

**Desenho Fatorial (2 fatores):**
- Poderia incluir "Janela Temporal" (7, 14, 30 dias) como segundo fator
- Resultaria em 4 √ó 3 = 12 combina√ß√µes de tratamentos
- **N√£o selecionado porque:** Aumentaria complexidade sem adicionar valor proporcional ao objetivo principal
- **Tratamento:** Janela temporal ser√° analisada de forma explorat√≥ria, n√£o inferencial

### 9.2 Randomiza√ß√£o e Aloca√ß√£o

#### Estrat√©gia de Randomiza√ß√£o:

**O que ser√° randomizado:**

1. **Ordem de Execu√ß√£o dos Modelos:**
   - As 120 execu√ß√µes (30 √ó 4 modelos) ter√£o ordem completamente aleat√≥ria
   - Evita vi√©s de ordem temporal (aquecimento de CPU, cache, etc.)
   
2. **Seeds para Divis√£o Treino/Teste:**
   - Cada uma das 30 repeti√ß√µes usar√° um seed aleat√≥rio diferente
   - Garante que cada execu√ß√£o tenha divis√£o treino/teste ligeiramente diferente
   - Seeds ser√£o pr√©-gerados e documentados para reprodutibilidade

3. **Inicializa√ß√£o de Par√¢metros (quando aplic√°vel):**
   - ARIMA: diferentes pontos de partida para otimiza√ß√£o
   - Exponential Smoothing: diferentes inicializa√ß√µes
   - Valida√ß√£o cruzada: ordem dos folds randomizada

#### Procedimento de Randomiza√ß√£o:

```python
# Pseudoc√≥digo do processo de randomiza√ß√£o

import numpy as np
import random

# 1. Gerar seeds para 30 repeti√ß√µes
np.random.seed(42)  # seed mestre para reprodutibilidade
seeds = np.random.randint(1, 10000, size=30)

# 2. Criar lista de todas as execu√ß√µes
execucoes = []
for modelo in ['RL', 'MM', 'ARIMA', 'ES']:
    for i, seed in enumerate(seeds):
        execucoes.append({
            'modelo': modelo,
            'repeticao': i + 1,
            'seed': seed
        })

# 3. Randomizar ordem de execu√ß√£o
random.seed(42)
random.shuffle(execucoes)

# 4. Executar na ordem randomizada
for exec in execucoes:
    executar_modelo(exec['modelo'], exec['seed'])
```

#### Documenta√ß√£o da Randomiza√ß√£o:

- **Seeds utilizados:** Salvos em arquivo CSV para reprodutibilidade total
- **Ordem de execu√ß√£o:** Registrada em log com timestamp
- **Verifica√ß√£o:** Ap√≥s experimento, confirmar que randomiza√ß√£o foi mantida

#### Controle de Confundidores:

**Fatores controlados (N√ÉO randomizados):**
- Dataset de entrada (mesmo para todos)
- Propor√ß√£o treino/teste (70%-30% fixa)
- M√©tricas de avalia√ß√£o (mesmas para todos)
- Ambiente computacional (mesma m√°quina)

### 9.3 Balanceamento e Contrabalan√ßo

#### Balanceamento:

**Balanceamento Completo Garantido:**

1. **N√∫mero de Repeti√ß√µes:**
   - Todos os 4 modelos: exatamente 30 execu√ß√µes cada
   - Total: 120 execu√ß√µes balanceadas (30-30-30-30)
   - Sem desbalanceamento planejado ou acidental

2. **Dados de Entrada:**
   - Todos os modelos recebem exatamente os mesmos dados
   - Mesmas 720 observa√ß√µes (30 dias √ó 24 horas)
   - Mesmas 4 m√©tricas de entrada (CPU, mem√≥ria, storage, requisi√ß√µes)

3. **Condi√ß√µes de Avalia√ß√£o:**
   - Mesma divis√£o treino/teste em cada repeti√ß√£o
   - Mesmas m√©tricas de avalia√ß√£o (MAE, RMSE, MAPE)
   - Mesmo procedimento de valida√ß√£o cruzada

#### Contrabalan√ßo (Counterbalancing):

**Contrabalan√ßo de Ordem:**

Embora n√£o haja "efeitos de aprendizagem" como em experimentos com humanos, o contrabalan√ßo de ordem mitiga efeitos de execu√ß√£o sequencial:

1. **Efeitos Mitigados:**
   - Aquecimento de hardware (CPU, cache)
   - Varia√ß√µes de carga do sistema operacional
   - Degrada√ß√£o de performance ao longo do tempo

2. **Estrat√©gia:**
   - Ordem de execu√ß√£o completamente randomizada (ver se√ß√£o 9.2)
   - Cada modelo aparece aproximadamente igual n√∫mero de vezes em cada posi√ß√£o
   - Verifica√ß√£o post-hoc: an√°lise de vari√¢ncia por ordem de execu√ß√£o

3. **Procedimento de Limpeza:**
   - Clear de mem√≥ria entre execu√ß√µes
   - Restart do kernel Python a cada 30 execu√ß√µes (opcional)
   - Monitoramento de temperatura e uso de CPU

#### Verifica√ß√£o de Balanceamento:

**Checklist Pr√©-Execu√ß√£o:**
- [ ] Confirmar n=30 para cada modelo
- [ ] Verificar que dataset √© id√™ntico para todos
- [ ] Validar que ordem est√° randomizada
- [ ] Confirmar que seeds s√£o √∫nicos e documentados

**Checklist P√≥s-Execu√ß√£o:**
- [ ] Verificar que todas as 120 execu√ß√µes foram conclu√≠das
- [ ] Confirmar aus√™ncia de outliers devido a erros de execu√ß√£o
- [ ] Analisar se ordem de execu√ß√£o introduziu vi√©s sistem√°tico

### 9.4 N√∫mero de Grupos e Sess√µes

#### N√∫mero de Grupos:

**4 Grupos (Tratamentos):**
1. Grupo 1: Regress√£o Linear (RL) - n=30
2. Grupo 2: M√©dia M√≥vel (MM) - n=30
3. Grupo 3: ARIMA - n=30
4. Grupo 4: Exponential Smoothing (ES) - n=30

**Total de Unidades Experimentais:** 120 execu√ß√µes

#### N√∫mero de Sess√µes:

**Defini√ß√£o de "Sess√£o":**
Uma sess√£o corresponde a uma execu√ß√£o completa de um modelo, incluindo:
- Carregamento dos dados
- Divis√£o treino/teste
- Treinamento do modelo
- Gera√ß√£o de previs√µes
- C√°lculo de m√©tricas de erro
- Valida√ß√£o cruzada

**Estrutura de Sess√µes:**

1. **Por Repeti√ß√£o:**
   - Cada repeti√ß√£o (1 a 30) = 1 sess√£o por modelo
   - Total: 30 sess√µes √ó 4 modelos = 120 sess√µes

2. **Por Valida√ß√£o Cruzada:**
   - Cada sess√£o inclui k=5 folds
   - Portanto: 120 sess√µes √ó 5 folds = 600 avalia√ß√µes de fold
   - Isso aumenta robustez sem aumentar n√∫mero de sess√µes principais

3. **Janelas Temporais (An√°lise Explorat√≥ria):**
   - Opcionalmente, repetir experimento com janelas de 7, 14 e 30 dias
   - Se realizado: 120 sess√µes √ó 3 janelas = 360 sess√µes totais
   - **Decis√£o:** Priorizar janela de 30 dias (an√°lise principal); outras janelas se tempo permitir

#### Dura√ß√£o Estimada:

**Por Sess√£o:**
- Regress√£o Linear: ~5 segundos
- M√©dia M√≥vel: ~2 segundos
- ARIMA: ~30-60 segundos (mais lento)
- Exponential Smoothing: ~10 segundos

**Total Estimado:**
- RL: 30 √ó 5s = 150s = 2.5 min
- MM: 30 √ó 2s = 60s = 1 min
- ARIMA: 30 √ó 45s = 1350s = 22.5 min
- ES: 30 √ó 10s = 300s = 5 min

**Tempo Total:** ~31 minutos + overhead (carregamento, logging) ‚âà **45-60 minutos**

#### Justificativa do N√∫mero de Sess√µes:

**N = 30 por grupo:**
- Atende requisito do Teorema do Limite Central (n ‚â• 30)
- Fornece poder estat√≠stico de 80% para detectar diferen√ßas m√©dias (d ‚âà 0.5)
- Permite c√°lculo robusto de intervalos de confian√ßa
- √â padr√£o em estudos experimentais

**N√£o aumentar para n = 50:**
- Retornos marginais decrescentes em poder estat√≠stico
- Tempo de execu√ß√£o dobraria (especialmente ARIMA)
- N = 30 j√° √© suficiente para conclus√µes robustas

---

## 10. Popula√ß√£o, Sujeitos e Amostragem

### 10.1 Popula√ß√£o-Alvo

**Defini√ß√£o da Popula√ß√£o:**

A popula√ß√£o-alvo deste experimento s√£o **workloads (cargas de trabalho) reais de aplica√ß√µes cloud**, caracterizadas por:

#### Caracter√≠sticas da Popula√ß√£o:

1. **Tipo de Aplica√ß√£o:**
   - Jobs e tasks executados em clusters de produ√ß√£o
   - Servi√ßos de processamento distribu√≠do
   - Aplica√ß√µes com padr√µes de uso vari√°veis ao longo do tempo
   - Workloads heterog√™neos (batch, servi√ßos online, an√°lise de dados)

2. **Perfil de Uso:**
   - Consumo vari√°vel de CPU (workloads reais de produ√ß√£o)
   - Uso din√¢mico de mem√≥ria RAM
   - Padr√µes temporais naturais (sem simula√ß√£o)
   - Heterogeneidade de recursos e utiliza√ß√£o

3. **Contexto Organizacional:**
   - Clusters de produ√ß√£o de larga escala
   - Ambiente gerenciado por sistema de orquestra√ß√£o (Google Borg)
   - Dados representativos de infraestrutura cloud real
   - Workloads de m√∫ltiplos usu√°rios e aplica√ß√µes

4. **Padr√µes Temporais:**
   - Presen√ßa de tend√™ncias naturais
   - Sazonalidade real (di√°ria, semanal)
   - Picos de uso espont√¢neos
   - Variabilidade natural de cargas de trabalho

#### Escopo da Generaliza√ß√£o:

**Onde os resultados SE APLICAM:**
- Ambientes cloud com workloads similares aos traces analisados
- Clusters gerenciados por orquestradores (Kubernetes, Borg, etc.)
- Horizontes de previs√£o de curto-m√©dio prazo (dias/semanas)
- Infraestruturas com precifica√ß√£o baseada em uso de recursos

**Onde os resultados PODEM N√ÉO SE APLICAR:**
- Workloads completamente diferentes dos traces (ex: IoT edge computing)
- Contextos com padr√µes de uso extremamente irregulares
- Ambientes com descontos especiais ou reserved instances complexos
- Aplica√ß√µes com requisitos de recursos completamente est√°ticos

### 10.2 Crit√©rios de Inclus√£o de Sujeitos

**Importante:** Este experimento usa **dados reais de traces p√∫blicos de cloud computing**, portanto "sujeitos" s√£o s√©ries temporais extra√≠das de workloads reais.

#### Fontes de Dados Candidatas:

**Fonte Prim√°ria (Recomendada):**

**1. Google Cluster Data 2019 (ClusterData2019)**
- **Descri√ß√£o:** Traces de 8 clusters Google Borg durante maio de 2019
- **Tamanho:** 2.4 TiB comprimidos (vers√£o completa), samples menores dispon√≠veis no Kaggle
- **M√©tricas Dispon√≠veis:**
  - CPU usage (histogramas a cada 5 minutos)
  - Memory usage
  - Job e task events
  - Resource requests
  - Timestamps precisos
- **Acesso:** 
  - BigQuery: `https://github.com/google/cluster-data`
  - Kaggle (sample): `https://www.kaggle.com/datasets/derrickmwiti/google-2019-cluster-sample`
- **Licen√ßa:** CC-BY (uso acad√™mico permitido)
- **Vantagens:** Dados reais, amplamente usado academicamente, bem documentado

**Fontes Alternativas (Backup):**

**2. MIT Supercloud Dataset**
- **Descri√ß√£o:** Logs de sistema HPC com GPU
- **M√©tricas:** CPU, GPU, mem√≥ria, file system
- **Granularidade:** 60 segundos (CPU/GPU)
- **Acesso:** `https://arxiv.org/abs/2108.02037`

**3. Azure Public Dataset**
- **Descri√ß√£o:** Workloads de infer√™ncia LLM
- **Acesso:** `https://github.com/Azure/AzurePublicDataset`

**4. IEEE DataPort - Cloud Performance Metrics**
- **Descri√ß√£o:** ~8,000 pontos de m√©tricas de sistema stateless
- **M√©tricas:** CPU, mem√≥ria, rede, TPS, response time
- **Granularidade:** 5 segundos
- **Acesso:** Requer IEEE DataPort subscription (gratuito para membros IEEE)

#### Crit√©rios de Inclus√£o para S√©ries Temporais Extra√≠das:

1. **Completude Temporal:**
   - Per√≠odo cont√≠nuo de pelo menos 30 dias
   - Granularidade m√°xima: 5 minutos (para compatibilidade com modelos)
   - Sem lacunas temporais significativas (< 5% de dados faltantes aceit√°vel)

2. **M√©tricas Necess√°rias:**
   - **Obrigat√≥rias:** CPU usage, Memory usage
   - **Desej√°veis:** Storage, Network I/O, Request count
   - **Para c√°lculo de custo:** Qualquer combina√ß√£o de CPU + Memory permite estimativa de custo

3. **Representatividade:**
   - Jobs/tasks de diferentes usu√°rios (n√£o apenas um usu√°rio)
   - Workloads heterog√™neos (n√£o apenas um tipo de aplica√ß√£o)
   - Presen√ßa de variabilidade natural (n√£o workloads artificialmente constantes)

4. **Qualidade dos Dados:**
   - Dados num√©ricos v√°lidos (n√£o corrompidos)
   - Timestamps consistentes e ordenados
   - Valores dentro de ranges plaus√≠veis (CPU: 0-100%, Memory > 0)

5. **Volume de Dados:**
   - M√≠nimo: 30 dias √ó 24h √ó 12 (para granularidade de 5 min) = ~8,640 observa√ß√µes por m√©trica
   - Ideal: 60-90 dias para maior robustez

#### Estrat√©gia de Sele√ß√£o do Dataset:

**Op√ß√£o Preferencial: Google Cluster Data 2019 (Sample via Kaggle)**

**Justificativa:**
1. **Realismo:** Dados reais de produ√ß√£o Google
2. **Qualidade:** Bem documentado e validado
3. **Acessibilidade:** Sample no Kaggle √© facilmente baix√°vel (sem necessidade de BigQuery)
4. **Uso Acad√™mico:** Centenas de papers usaram esses dados
5. **M√©tricas:** CPU e mem√≥ria dispon√≠veis com timestamps
6. **Tamanho Gerenci√°vel:** Sample de ~100MB vs. 2.4TiB da vers√£o completa

**Extra√ß√£o Espec√≠fica:**
- Selecionar subset de jobs/tasks com pelo menos 30 dias de dados
- Agregar m√©tricas por per√≠odo (ex: 1 hora) para reduzir granularidade
- Extrair 30-90 dias cont√≠nuos de um ou mais clusters

### 10.3 Crit√©rios de Exclus√£o de Sujeitos

#### S√©ries Temporais Exclu√≠das:

1. **Dados Incompletos ou Corrompidos:**
   - S√©ries com > 5% de valores faltantes
   - Timestamps inconsistentes ou desordenados
   - Valores corrompidos (NaN, Inf, valores negativos para CPU/mem√≥ria)

2. **Dados N√£o-Representativos:**
   - Jobs/tasks com dura√ß√£o < 24 horas (muito curtos)
   - Workloads completamente est√°ticos (vari√¢ncia ~0)
   - Outliers extremos sem explica√ß√£o (CPU > 100%, mem√≥ria negativa)

3. **Dados de Baixa Qualidade:**
   - Granularidade inconsistente (timestamps irregulares)
   - Lacunas temporais longas (> 1 hora sem dados)
   - Jobs marcados como "failed" ou "killed" (dependendo da an√°lise)

4. **Dados Fora do Escopo:**
   - Workloads muito espec√≠ficos que n√£o representam uso t√≠pico
   - Jobs de teste/debug (identific√°veis por padr√µes)
   - Dados de warmup ou shutdown de sistemas

#### Procedimento de Exclus√£o:

**Pr√©-Valida√ß√£o (antes do experimento):**

```python
import pandas as pd
import numpy as np

# 1. Carregar dados do Google Cluster (sample Kaggle ou BigQuery)
df = pd.read_csv('google_cluster_sample.csv')

# 2. Verificar valores faltantes
missing_pct = df.isna().sum() / len(df) * 100
print(f"% de dados faltantes por coluna:\n{missing_pct}")
assert missing_pct.max() < 5, "Mais de 5% de dados faltantes!"

# 3. Validar ranges
assert (df['cpu_usage'] >= 0).all() and (df['cpu_usage'] <= 1).all(), "CPU fora do range!"
assert (df['memory_usage'] >= 0).all(), "Mem√≥ria negativa detectada!"

# 4. Detectar s√©ries constantes
variancia = df.groupby('job_id')[['cpu_usage', 'memory_usage']].std()
jobs_validos = variancia[(variancia > 0.01).all(axis=1)].index
df = df[df['job_id'].isin(jobs_validos)]

# 5. Remover outliers extremos (z-score > 5)
from scipy import stats
z_scores = np.abs(stats.zscore(df[['cpu_usage', 'memory_usage']]))
df = df[(z_scores < 5).all(axis=1)]

# 6. Verificar completude temporal
df['timestamp'] = pd.to_datetime(df['timestamp'])
df = df.sort_values('timestamp')
gap_max = df['timestamp'].diff().max()
assert gap_max < pd.Timedelta('1 hour'), f"Lacuna temporal detectada: {gap_max}"

print(f"Dataset final: {len(df)} observa√ß√µes v√°lidas")
```

**Decis√£o de Exclus√£o:**
- Se s√©rie falhar em qualquer crit√©rio cr√≠tico ‚Üí **excluir**
- Documentar raz√£o da exclus√£o no log do experimento
- Manter registro de quantas s√©ries foram exclu√≠das e por qu√™

### 10.4 Tamanho da Amostra Planejado (por Grupo)

#### Tamanho da Amostra:

**N = 30 execu√ß√µes por modelo**

- **Total de Unidades Experimentais:** 120 (30 √ó 4 modelos)
- **Total de Avalia√ß√µes (com k-fold):** 600 (120 √ó 5 folds)

#### Justificativa Estat√≠stica:

**1. Teorema do Limite Central:**
- N ‚â• 30 garante distribui√ß√£o aproximadamente normal dos erros m√©dios
- Permite uso de testes param√©tricos (ANOVA) com seguran√ßa

**2. Poder Estat√≠stico:**
Para Œ± = 0.05 e poder = 0.80, com 4 grupos:
- N = 30 por grupo detecta tamanho de efeito d ‚âà 0.5 (m√©dio)
- Equivalente a diferen√ßa de ~15-20% no erro m√©dio entre modelos

**3. C√°lculo Formal (ANOVA One-Way):**

```
Par√¢metros:
- k = 4 grupos
- Œ± = 0.05
- Poder (1-Œ≤) = 0.80
- Efeito esperado: f = 0.25 (m√©dio)

F√≥rmula simplificada:
n ‚âà 2 √ó (Z_Œ±/2 + Z_Œ≤)¬≤ / (ES)¬≤
n ‚âà 2 √ó (1.96 + 0.84)¬≤ / (0.5)¬≤
n ‚âà 2 √ó 7.84 / 0.25
n ‚âà 31.36 ‚âà 30
```

**4. Valida√ß√£o Cruzada:**
- k-fold (k=5) multiplica efetivamente o poder
- Cada modelo √© avaliado 150 vezes (30 execu√ß√µes √ó 5 folds)
- Reduz impacto de variabilidade amostral

**5. Variabilidade com Dados Reais:**
- Com dados reais, cada execu√ß√£o usar√° diferentes seeds para:
  - Divis√£o treino/teste aleat√≥ria
  - Sele√ß√£o de diferentes subsets do dataset (se necess√°rio)
  - Inicializa√ß√£o de modelos
- Isso captura variabilidade natural dos dados

#### Tamanho M√≠nimo vs. M√°ximo:

**M√≠nimo Aceit√°vel:** N = 20
- Ainda fornece poder razo√°vel (~70%)
- √ötil se restri√ß√µes de processamento forem cr√≠ticas

**M√°ximo Vi√°vel:** N = 50
- Aumenta poder para ~90%
- Retornos marginais decrescentes
- Tempo de execu√ß√£o aumenta 67%

**Escolha:** N = 30 (balan√ßo √≥timo entre poder e viabilidade)

### 10.5 M√©todo de Sele√ß√£o / Recrutamento

**M√©todo:** **Amostragem de Traces P√∫blicos Reais de Cloud Computing**

Como n√£o h√° sujeitos humanos, o "recrutamento" consiste na **obten√ß√£o e extra√ß√£o de dados reais de datasets p√∫blicos**.

#### Processo de Obten√ß√£o dos Dados:

**Etapa 1: Download do Dataset**

**Op√ß√£o A: Kaggle (Recomendado para TCC)**
```bash
# Instalar Kaggle CLI
pip install kaggle

# Configurar credenciais (ap√≥s criar conta Kaggle)
# Baixar API token em https://www.kaggle.com/settings

# Fazer download do sample do Google Cluster 2019
kaggle datasets download -d derrickmwiti/google-2019-cluster-sample

# Descompactar
unzip google-2019-cluster-sample.zip
```

**Op√ß√£o B: BigQuery (Se necess√°rio dataset completo)**
```python
# Requer conta Google Cloud (possui free tier)
from google.cloud import bigquery

client = bigquery.Client()

query = """
SELECT 
    time,
    collection_id,
    average_usage_cpus,
    average_usage_memory
FROM `google.com:google-cluster-data.clusterdata_2019_a.task_usage`
WHERE time BETWEEN 600000000 AND 2592000000000  # ~30 dias
LIMIT 1000000
"""

df = client.query(query).to_dataframe()
df.to_csv('google_cluster_sample.csv', index=False)
```

**Etapa 2: Extra√ß√£o e Pr√©-processamento**

```python
import pandas as pd
import numpy as np

# Carregar dados
df = pd.read_csv('google_cluster_sample.csv')

# Converter timestamps (Google Cluster usa microsegundos desde epoch)
df['timestamp'] = pd.to_datetime(df['time'], unit='us')

# Renomear colunas para padronizar
df = df.rename(columns={
    'average_usage_cpus': 'cpu_usage',
    'average_usage_memory': 'memory_usage'
})

# Agregar por intervalo de tempo (ex: 1 hora) para reduzir granularidade
df = df.set_index('timestamp')
df_hourly = df.resample('1H').mean()

# Selecionar per√≠odo cont√≠nuo de 30 dias
start_date = df_hourly.index.min()
end_date = start_date + pd.Timedelta(days=30)
df_30d = df_hourly[(df_hourly.index >= start_date) & (df_hourly.index < end_date)]

print(f"Dataset final: {len(df_30d)} observa√ß√µes hor√°rias (~{len(df_30d)/24:.1f} dias)")
```

**Etapa 3: C√°lculo de Custos Estimados**

```python
# Calcular custo baseado em precifica√ß√£o t√≠pica de provedores
# Exemplo: AWS EC2 pricing simplificado

# Premissas de precifica√ß√£o (valores aproximados em R$/hora)
CPU_COST_PER_CORE_HOUR = 0.15  # R$ por core por hora
MEMORY_COST_PER_GB_HOUR = 0.02  # R$ por GB por hora

# Google Cluster normaliza CPU e mem√≥ria (0-1)
# Assumir inst√¢ncias com 4 cores e 16GB RAM (t√≠pico)
CORES = 4
RAM_GB = 16

df_30d['cpu_cost'] = df_30d['cpu_usage'] * CORES * CPU_COST_PER_CORE_HOUR
df_30d['memory_cost'] = df_30d['memory_usage'] * RAM_GB * MEMORY_COST_PER_GB_HOUR
df_30d['total_cost'] = df_30d['cpu_cost'] + df_30d['memory_cost']

# Salvar dataset final processado
df_30d.to_csv('dataset_cloud_preprocessado.csv')
```

**Etapa 4: Valida√ß√£o de Qualidade**
- Aplicar crit√©rios de inclus√£o (se√ß√£o 10.2)
- Aplicar crit√©rios de exclus√£o (se√ß√£o 10.3)
- An√°lise explorat√≥ria visual (plots de s√©ries temporais)
- Verificar estat√≠sticas descritivas

**Etapa 5: Documenta√ß√£o**
- Documentar fonte original dos dados (Google Cluster Data 2019)
- Registrar par√¢metros de extra√ß√£o e agrega√ß√£o
- Salvar metadata: per√≠odo exato, n√∫mero de jobs/tasks inclu√≠dos
- Garantir reprodutibilidade (c√≥digo + documenta√ß√£o)

#### Representatividade e Validade Externa:

**Vantagens de Usar Dados Reais:**

1. **Autenticidade:**
   - Padr√µes reais de uso de infraestrutura cloud
   - Variabilidade natural (n√£o artificialmente gerada)
   - Anomalias e eventos reais inclu√≠dos

2. **Credibilidade Cient√≠fica:**
   - Dataset amplamente usado em pesquisas (centenas de cita√ß√µes)
   - Dados validados pelo Google
   - Resultados compar√°veis com literatura existente

3. **Aplicabilidade Pr√°tica:**
   - Conclus√µes mais generaliz√°veis para ambientes reais
   - Maior confian√ßa de stakeholders (empresas, DevOps)
   - Valida√ß√£o externa mais forte

**Limita√ß√µes Reconhecidas:**

1. **Contexto Espec√≠fico:**
   - Dados de clusters Google Borg (n√£o todos os provedores)
   - Workloads espec√≠ficos de Google (n√£o universalmente representativos)
   - Per√≠odo espec√≠fico (maio 2019)

2. **Precifica√ß√£o Estimada:**
   - Custos calculados com base em tabelas p√∫blicas (n√£o custos reais Google)
   - N√£o considera descontos, reserved instances, ou pre√ßos negociados
   - Simplifica√ß√£o de modelo de precifica√ß√£o

3. **Pr√©-processamento:**
   - Agrega√ß√£o temporal (de 5 min para 1 hora) pode perder alguns padr√µes
   - Sele√ß√£o de subset pode n√£o capturar toda heterogeneidade

**Mitiga√ß√£o:**
- Documentar claramente limita√ß√µes no trabalho final
- Usar m√∫ltiplos subsets do dataset (variabilidade)
- Comparar resultados com literatura que usou mesmos dados

### 10.6 Treinamento e Prepara√ß√£o dos Sujeitos

**N√£o Aplic√°vel:** Este experimento n√£o envolve sujeitos humanos.

**Prepara√ß√£o dos Dados Reais:**

#### Pr√©-processamento Completo:

**1. Limpeza:**
```python
# Verificar e tratar dados faltantes
df = df.interpolate(method='time', limit=2)  # Interpolar gaps pequenos
df = df.dropna()  # Remover NaNs restantes

# Validar consist√™ncia temporal
df = df.sort_index()
assert df.index.is_monotonic_increasing, "Timestamps fora de ordem!"

# Remover duplicatas de timestamp
df = df[~df.index.duplicated(keep='first')]
```

**2. Tratamento de Outliers:**
```python
# Detectar outliers usando IQR (mais robusto que z-score para dados reais)
def remove_outliers_iqr(df, column, multiplier=1.5):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - multiplier * IQR
    upper_bound = Q3 + multiplier * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Aplicar para CPU e mem√≥ria
df = remove_outliers_iqr(df, 'cpu_usage')
df = remove_outliers_iqr(df, 'memory_usage')
```

**3. Normaliza√ß√£o:**
```python
from sklearn.preprocessing import StandardScaler

# Salvar scaler para uso consistente em todas as execu√ß√µes
scaler = StandardScaler()
df[['cpu_usage_scaled', 'memory_usage_scaled']] = \
    scaler.fit_transform(df[['cpu_usage', 'memory_usage']])

# Salvar scaler para reprodutibilidade
import joblib
joblib.dump(scaler, 'scaler_cloud_data.pkl')
```

**4. Engenharia de Features:**
```python
# Features temporais
df['hour'] = df.index.hour
df['day_of_week'] = df.index.dayofweek
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

# Lags (valores passados)
for lag in [1, 2, 3, 6, 12, 24]:
    df[f'cpu_lag_{lag}h'] = df['cpu_usage'].shift(lag)
    df[f'memory_lag_{lag}h'] = df['memory_usage'].shift(lag)

# M√©dias m√≥veis
df['cpu_ma_24h'] = df['cpu_usage'].rolling(window=24, min_periods=1).mean()
df['memory_ma_24h'] = df['memory_usage'].rolling(window=24, min_periods=1).mean()

# Remover linhas com NaN criados pelos lags
df = df.dropna()
```

**5. Divis√£o Treino/Teste (Temporal):**
```python
# Importante: NUNCA fazer shuffle em s√©ries temporais!
train_size = int(len(df) * 0.7)

train_df = df.iloc[:train_size]
test_df = df.iloc[train_size:]

print(f"Treino: {len(train_df)} observa√ß√µes ({train_df.index.min()} a {train_df.index.max()})")
print(f"Teste: {len(test_df)} observa√ß√µes ({test_df.index.min()} a {test_df.index.max()})")

# Salvar splits
train_df.to_csv('data/train_dataset.csv')
test_df.to_csv('data/test_dataset.csv')
```

**6. Valida√ß√£o Cruzada Temporal (Time Series Split):**
```python
from sklearn.model_selection import TimeSeriesSplit

# 5-fold temporal (n√£o aleat√≥rio!)
tscv = TimeSeriesSplit(n_splits=5)

for fold, (train_idx, val_idx) in enumerate(tscv.split(train_df)):
    fold_train = train_df.iloc[train_idx]
    fold_val = train_df.iloc[val_idx]
    
    # Salvar cada fold
    fold_train.to_csv(f'data/fold_{fold}_train.csv')
    fold_val.to_csv(f'data/fold_{fold}_val.csv')
```
---
## 11. Instrumenta√ß√£o e Protocolo Operacional

### 11.1 Instrumentos de Coleta (Question√°rios, Logs, Planilhas, etc.)

#### Instrumentos Principais:

| Instrumento | Descri√ß√£o | Formato | Uso |
|------------|-----------|---------|-----|
| **Script de Gera√ß√£o de Dados** | Gera s√©ries temporais sint√©ticas | Python (.py) | Criar dataset experimental |
| **Script de Treinamento** | Treina os 4 modelos de previs√£o | Python (.py) | Executar tratamentos |
| **Script de Avalia√ß√£o** | Calcula MAE, RMSE, MAPE | Python (.py) | Coletar vari√°veis dependentes |
| **Arquivo de Resultados** | Armazena erros de cada execu√ß√£o | CSV (.csv) | Consolidar resultados |
| **Log de Execu√ß√£o** | Registra timestamp, ordem, erros | TXT/JSON (.log) | Auditoria e debug |
| **Notebook de An√°lise** | An√°lise estat√≠stica e visualiza√ß√µes | Jupyter (.ipynb) | An√°lise p√≥s-experimento |
| **Arquivo de Configura√ß√£o** | Par√¢metros dos modelos e experimento | YAML/JSON (.yaml) | Controle de configura√ß√£o |

#### Estrutura dos Instrumentos:

**1. Arquivo de Resultados (resultados.csv):**
```csv
execucao_id,modelo,repeticao,seed,mae,rmse,mape,tempo_exec,fold,mae_fold,timestamp
1,RL,1,4235,125.34,178.92,12.5,5.2,1,130.21,2024-12-02 10:15:23
1,RL,1,4235,125.34,178.92,12.5,5.2,2,118.45,2024-12-02 10:15:23
...
```

**2. Log de Execu√ß√£o (experimento.log):**
```
2024-12-02 10:15:20 - INFO - Iniciando experimento TCC-PRED-CUSTO-2024-001
2024-12-02 10:15:21 - INFO - Carregando dados sint√©ticos
2024-12-02 10:15:22 - INFO - Executando modelo RL, repeti√ß√£o 1, seed 4235
2024-12-02 10:15:23 - INFO - RL completado - MAE: 125.34
...
```

**3. Arquivo de Configura√ß√£o (config.yaml):**
```yaml
experimento:
  id: TCC-PRED-CUSTO-2024-001
  versao: 1.4
  repeticoes: 30
  k_folds: 5
  seed_mestre: 42

modelos:
  regressao_linear:
    biblioteca: sklearn.linear_model.LinearRegression
    parametros: {}
  
  media_movel:
    janela: 7
  
  arima:
    ordem: [1, 1, 1]  # (p, d, q) - ser√° otimizado via grid search
  
  exponential_smoothing:
    trend: add
    seasonal: add
    seasonal_periods: 24
```

### 11.2 Materiais de Suporte (Instru√ß√µes, Guias)

#### Materiais Criados:

1. **README.md do Projeto:**
   - Vis√£o geral do experimento
   - Instru√ß√µes de instala√ß√£o
   - Como reproduzir experimento

2. **HOWTO_RUN.md:**
   - Passo a passo detalhado de execu√ß√£o
   - Comandos a serem executados
   - Troubleshooting comum

3. **Guia de An√°lise:**
   - Como interpretar resultados
   - Checklist de valida√ß√£o
   - Testes estat√≠sticos a aplicar

4. **Documenta√ß√£o de C√≥digo:**
   - Docstrings em todas as fun√ß√µes
   - Coment√°rios inline explicativos
   - Type hints para clareza

#### Exemplo de Conte√∫do (HOWTO_RUN.md):

```markdown
# Como Executar o Experimento

## Pr√©-requisitos
- Python 3.10+
- Bibliotecas: pandas, numpy, scikit-learn, statsmodels, matplotlib

## Instala√ß√£o
```bash
pip install -r requirements.txt
```

## Execu√ß√£o

### Passo 1: Gerar Dados Sint√©ticos
```bash
python scripts/gerar_dados.py --dias 30 --seed 42
```

### Passo 2: Executar Experimento
```bash
python scripts/executar_experimento.py --config config.yaml
```

### Passo 3: Analisar Resultados
```bash
jupyter notebook analise/analise_resultados.ipynb
```

## Verifica√ß√£o
- Conferir arquivo `resultados.csv` (deve ter 600 linhas: 120 execu√ß√µes √ó 5 folds)
- Verificar log `experimento.log` (sem erros)
- Gerar plots de diagn√≥stico


### 11.3 Procedimento Experimental (Protocolo ‚Äì Vis√£o Passo a Passo)

#### Protocolo Operacional Detalhado:

---

**FASE 1: PREPARA√á√ÉO (Pr√©-Execu√ß√£o)**

**Passo 1.1 - Setup do Ambiente**
- Instalar Python 3.10+ e bibliotecas necess√°rias
- Clonar reposit√≥rio do experimento
- Verificar disponibilidade de hardware
- **Dura√ß√£o:** 30 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Ambiente funcional

**Passo 1.2 - Gera√ß√£o de Dados Sint√©ticos**
- Executar script `gerar_dados.py`
- Validar qualidade dos dados gerados (se√ß√£o 10.2)
- Salvar dataset em `data/dataset_cloud.csv`
- **Dura√ß√£o:** 10 minutos
- **Respons√°vel:** Pesquisador
- **Output:** `dataset_cloud.csv` (720 linhas √ó 6 colunas)

**Passo 1.3 - Valida√ß√£o do Dataset**
- An√°lise explorat√≥ria visual (plots de s√©ries temporais)
- Verifica√ß√£o de estat√≠sticas descritivas
- Confirma√ß√£o com orientador sobre realismo
- **Dura√ß√£o:** 30 minutos
- **Respons√°vel:** Pesquisador + Orientador
- **Output:** Dataset aprovado

**Passo 1.4 - Prepara√ß√£o dos Seeds**
- Gerar 30 seeds aleat√≥rios (numpy.random.seed(42))
- Salvar em `config/seeds.txt`
- **Dura√ß√£o:** 5 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Lista de 30 seeds

---

**FASE 2: EXECU√á√ÉO DO EXPERIMENTO**

**Passo 2.1 - Pr√©-processamento**
- Carregar dataset
- Aplicar normaliza√ß√£o (StandardScaler)
- Salvar objeto scaler para uso posterior
- **Dura√ß√£o:** 5 minutos
- **Respons√°vel:** Script autom√°tico
- **Output:** Dados normalizados

**Passo 2.2 - Loop Principal de Execu√ß√£o**

Para cada repeti√ß√£o r = 1 at√© 30:
  Para cada modelo m em [RL, MM, ARIMA, ES]:
    
    a) **Divis√£o Treino/Teste**
       - Usar seed[r] para reprodutibilidade
       - Treino: 70% (primeiros 504 registros)
       - Teste: 30% (√∫ltimos 216 registros)
    
    b) **Treinamento do Modelo**
       - Treinar modelo m nos dados de treino
       - Registrar tempo de treinamento
    
    c) **Gera√ß√£o de Previs√µes**
       - Gerar previs√µes para conjunto de teste
    
    d) **C√°lculo de M√©tricas (Holdout)**
       - Calcular MAE, RMSE, MAPE no conjunto de teste
    
    e) **Valida√ß√£o Cruzada k-fold**
       - Aplicar 5-fold cross-validation nos dados de treino
       - Calcular MAE em cada fold
       - Registrar m√©dia e desvio padr√£o
    
    f) **Registro de Resultados**
       - Salvar em `resultados.csv`:
         execucao_id, modelo, repeticao, seed, mae, rmse, mape, tempo_exec
       - Salvar m√©tricas de cada fold
    
    g) **Logging**
       - Registrar em `experimento.log`:
         timestamp, modelo, status, m√©tricas principais

**Dura√ß√£o Total:** ~45-60 minutos
**Respons√°vel:** Script autom√°tico (`executar_experimento.py`)
**Output:** `resultados.csv` com 120 linhas (1 por execu√ß√£o)

**Passo 2.3 - Verifica√ß√£o de Integridade**
- Conferir se 120 execu√ß√µes foram completadas
- Verificar aus√™ncia de erros no log
- Validar que n√£o h√° valores faltantes em `resultados.csv`
- **Dura√ß√£o:** 10 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Confirma√ß√£o de experimento completo

---

**FASE 3: AN√ÅLISE DOS RESULTADOS**

**Passo 3.1 - Estat√≠stica Descritiva**
- Calcular m√©dia, mediana, desvio padr√£o de MAE, RMSE, MAPE por modelo
- Gerar tabelas de resumo
- **Dura√ß√£o:** 15 minutos
- **Respons√°vel:** Notebook Jupyter
- **Output:** Tabelas descritivas

**Passo 3.2 - Visualiza√ß√µes**
- Boxplots de MAE por modelo
- Gr√°ficos de s√©ries previstas vs. reais
- Heatmap de correla√ß√£o entre m√©tricas e custo
- **Dura√ß√£o:** 30 minutos
- **Respons√°vel:** Notebook Jupyter
- **Output:** Figuras para relat√≥rio

**Passo 3.3 - Teste de Normalidade**
- Shapiro-Wilk test nos res√≠duos de cada modelo
- Decis√£o: ANOVA (se normal) ou Kruskal-Wallis (se n√£o-normal)
- **Dura√ß√£o:** 10 minutos
- **Respons√°vel:** Script Python
- **Output:** p-valor de normalidade

**Passo 3.4 - Teste de Hip√≥teses**
- Aplicar ANOVA ou Kruskal-Wallis (H0: Œº1 = Œº2 = Œº3 = Œº4)
- Se p < 0.05: aplicar post-hoc tests (Tukey HSD)
- Identificar quais pares de modelos diferem significativamente
- **Dura√ß√£o:** 15 minutos
- **Respons√°vel:** Script Python
- **Output:** p-valor, conclus√£o sobre H0

**Passo 3.5 - An√°lise de Correla√ß√£o**
- Calcular correla√ß√£o de Pearson entre cada m√©trica (CPU, mem√≥ria, etc.) e custo
- Identificar vari√°veis mais preditivas
- **Dura√ß√£o:** 10 minutos
- **Respons√°vel:** Script Python
- **Output:** Matriz de correla√ß√£o

**Passo 3.6 - Verifica√ß√£o de Crit√©rios de Sucesso**
- Verificar se erro < 20% em pelo menos um modelo
- Confirmar diferen√ßa estat√≠stica significativa (se houver)
- Documentar cumprimento dos crit√©rios da se√ß√£o 6.2
- **Dura√ß√£o:** 15 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Checklist de crit√©rios atendidos

---

**FASE 4: DOCUMENTA√á√ÉO**

**Passo 4.1 - Compila√ß√£o dos Resultados**
- Consolidar tabelas, gr√°ficos e conclus√µes
- Preencher se√ß√µes do documento de TCC
- **Dura√ß√£o:** 2-3 horas
- **Respons√°vel:** Pesquisador
- **Output:** Se√ß√µes de resultados e discuss√£o

**Passo 4.2 - Revis√£o com Orientador**
- Apresentar resultados ao orientador
- Incorporar feedback
- **Dura√ß√£o:** 1 hora (reuni√£o)
- **Respons√°vel:** Pesquisador + Orientador
- **Output:** Resultados validados

**Passo 4.3 - Empacotamento para Reprodu√ß√£o**
- Organizar c√≥digo, dados, resultados em reposit√≥rio
- Escrever README final
- Testar reprodu√ß√£o em ambiente limpo
- **Dura√ß√£o:** 2 horas
- **Respons√°vel:** Pesquisador
- **Output:** Reposit√≥rio reproduz√≠vel

---

### Fluxograma Operacional

```mermaid
flowchart TD
    A[Definir escopo das m√©tricas] --> B[Gerar dados sint√©ticos via Python]
    B --> C[Pr√©-processamento das m√©tricas]
    C --> D{Dados cont√™m valores ausentes ou outliers?}
    D -->|Sim| E[Tratamento de dados: imputa√ß√£o ou remo√ß√£o]
    D -->|N√£o| F[Normaliza√ß√£o dos dados]
    E --> F
    F --> G[Constru√ß√£o do dataset final]
    G --> H[Divis√£o treino/valida√ß√£o - 70%/30%]
    H --> I[Aplica√ß√£o dos modelos de previs√£o]
    I --> J[Coleta das m√©tricas MAE, RMSE, MAPE]
    J --> K{Res√≠duos passaram no teste de normalidade?}
    K -->|Sim| L[Aplica√ß√£o de ANOVA]
    K -->|N√£o| M[Aplica√ß√£o de Kruskal-Wallis]
    L --> N{p-valor < 0.05?}
    M --> N
    N -->|Sim| O[Modelos apresentam diferen√ßa significativa]
    N -->|N√£o| P[Modelos n√£o diferem significativamente]
    O --> Q[Compara√ß√£o e sele√ß√£o do melhor modelo]
    P --> Q
    Q --> R{Erro < 20% em pelo menos um modelo?}
    R -->|Sim| S[Crit√©rio de sucesso atendido]
    R -->|N√£o| T[Revisar hiperpar√¢metros ou adicionar features]
    T --> I
    S --> U[Registro e interpreta√ß√£o dos resultados]
    U --> V[An√°lise de correla√ß√£o entre m√©tricas e custos]
    V --> W[Documenta√ß√£o final e conclus√µes]
```

### 11.4 Plano de Piloto (se Haver√° Piloto, Escopo e Crit√©rios de Ajuste)

**Decis√£o:** **N√£o ser√° realizado experimento piloto formal**

#### Justificativa:

1. **Uso de Dados Sint√©ticos:**
   - Dados s√£o gerados sob controle total
   - N√£o h√° incerteza sobre disponibilidade ou qualidade
   - Poss√≠vel validar gera√ß√£o antes de experimento principal

2. **Modelos Estabelecidos:**
   - Todos os 4 modelos s√£o bem conhecidos na literatura
   - Implementa√ß√µes em bibliotecas maduras (Scikit-learn, Statsmodels)
   - Baixo risco de problemas t√©cnicos inesperados

3. **Custo-Benef√≠cio:**
   - Experimento completo leva ~1 hora
   - Piloto tomaria tempo similar
   - Melhor investir tempo em valida√ß√£o pr√©via do dataset

#### Valida√ß√£o Alternativa ao Piloto:

**"Dry Run" (Execu√ß√£o de Teste):**

Antes do experimento principal, realizar:

1. **Teste com n=5 repeti√ß√µes:**
   - Executar cada modelo 5 vezes
   - Verificar que c√≥digo roda sem erros
   - Validar formato dos outputs
   - **Dura√ß√£o:** ~10 minutos

2. **Inspe√ß√£o Manual:**
   - Verificar se m√©tricas est√£o em ranges plaus√≠veis
   - Conferir se logs est√£o sendo gerados corretamente
   - Validar que seeds produzem resultados diferentes

3. **Crit√©rios de Prosseguimento:**
   - ‚úÖ Zero erros de execu√ß√£o
   - ‚úÖ Resultados dentro de ranges esperados (MAE entre 50-300 R$)
   - ‚úÖ Diferen√ßas vis√≠veis entre modelos
   - ‚úÖ Logs completos e leg√≠veis

**Se "Dry Run" Falhar:**
- Depurar c√≥digo
- Ajustar par√¢metros de gera√ß√£o de dados
- Revisar configura√ß√£o
- Repetir dry run at√© sucesso

---

## 12. Plano de An√°lise de Dados (Pr√©-Execu√ß√£o)

### 12.1 Estrat√©gia Geral de An√°lise (Como Responder√° √†s Quest√µes)

#### Mapeamento Quest√µes ‚Üí An√°lises:

**Quest√µes sobre Acur√°cia dos Modelos (Q1.1, Q2.1, Q2.2):**

**An√°lise:**
- Estat√≠stica descritiva: m√©dia, mediana, desvio padr√£o de MAE, RMSE, MAPE por modelo
- Tabelas comparativas
- Visualiza√ß√£o: boxplots, violin plots

**Como Responde:**
- "Qual modelo tem menor MAE?" ‚Üí Identificar modelo com menor m√©dia de MAE
- "Qual tem menor RMSE/MAPE?" ‚Üí An√°logo

---

**Quest√µes sobre Diferen√ßa Estat√≠stica (Q1.3, Q5.3):**

**An√°lise:**
- Teste de normalidade (Shapiro-Wilk)
- ANOVA ou Kruskal-Wallis (compara√ß√£o entre 4 grupos)
- Post-hoc tests (Tukey HSD ou Dunn's test)
- Tamanho de efeito (Œ∑¬≤ para ANOVA ou Œµ¬≤ para Kruskal-Wallis)

**Como Responde:**
- "H√° diferen√ßa significativa?" ‚Üí p-valor < 0.05 ‚Üí Sim
- "Quais modelos diferem?" ‚Üí Post-hoc indica pares significativos

---

**Quest√µes sobre Janelas Temporais (Q1.2, Q2.3):**

**An√°lise:**
- Compara√ß√£o explorat√≥ria de MAE em janelas de 7, 14, 30 dias
- Gr√°ficos de linha mostrando erro vs. tamanho de janela
- ANOVA de dois fatores (se tempo permitir): Modelo √ó Janela

**Como Responde:**
- "Erro diminui com janelas maiores?" ‚Üí Comparar m√©dias; testar tend√™ncia

---

**Quest√µes sobre Vari√°veis Preditoras (Q3.1, Q3.2, Q3.3):**

**An√°lise:**
- Correla√ß√£o de Pearson entre cada m√©trica e custo
- Heatmap de correla√ß√µes
- An√°lise de import√¢ncia de features (para Regress√£o Linear: coeficientes)

**Como Responde:**
- "Qual m√©trica mais correlacionada?" ‚Üí Maior |r| de Pearson
- "CPU √© melhor que mem√≥ria?" ‚Üí Comparar r(CPU, custo) vs. r(Mem√≥ria, custo)

---

**Quest√µes sobre Generaliza√ß√£o (Q4.1, Q4.2, Q4.3):**

**An√°lise:**
- Valida√ß√£o cruzada k-fold: calcular erro m√©dio nos folds
- Comparar erro de treino vs. erro de teste (diferen√ßa %)
- Detectar overfitting: se diferen√ßa > 15% ‚Üí flag

**Como Responde:**
- "Modelo generaliza?" ‚Üí Diferen√ßa treino/teste < 15%
- "Qual erro de valida√ß√£o cruzada?" ‚Üí M√©dia dos erros nos k folds

---

**Quest√µes sobre Estabilidade (Q5.1, Q5.2):**

**An√°lise:**
- Calcular desvio padr√£o dos erros de cada modelo
- Coeficiente de varia√ß√£o: CV = œÉ/Œº
- Detectar overfitting: diferen√ßa treino/teste por modelo

**Como Responde:**
- "Qual modelo mais est√°vel?" ‚Üí Menor desvio padr√£o
- "H√° overfitting?" ‚Üí Se diferen√ßa treino/teste > 10-15%

### 12.2 M√©todos Estat√≠sticos Planejados

#### Testes Estat√≠sticos:

**1. Teste de Normalidade:**
- **Nome:** Shapiro-Wilk test
- **Quando:** Antes de ANOVA
- **Hip√≥teses:**
  - H0: Os res√≠duos seguem distribui√ß√£o normal
  - H1: Os res√≠duos n√£o seguem distribui√ß√£o normal
- **Crit√©rio:** Œ± = 0.05
- **Decis√£o:** Se p > 0.05 ‚Üí Usar ANOVA; se p < 0.05 ‚Üí Usar Kruskal-Wallis

**C√≥digo:**
```python
from scipy.stats import shapiro

for modelo in ['RL', 'MM', 'ARIMA', 'ES']:
    residuos = df[df['modelo'] == modelo]['mae']
    stat, p_value = shapiro(residuos)
    print(f'{modelo}: p-valor = {p_value:.4f}')
```

---

**2. Compara√ß√£o Entre Modelos (Param√©trico):**
- **Nome:** ANOVA One-Way
- **Quando:** Se res√≠duos forem normais
- **Hip√≥teses:**
  - H0: Œº_RL = Œº_MM = Œº_ARIMA = Œº_ES
  - H1: Pelo menos um Œº_i ‚â† Œº_j
- **Crit√©rio:** Œ± = 0.05
- **Estat√≠stica:** F de Fisher
- **Interpreta√ß√£o:**
  - p < 0.05 ‚Üí Rejeitar H0 (diferen√ßa significativa existe)
  - p ‚â• 0.05 ‚Üí N√£o rejeitar H0

**C√≥digo:**
```python
from scipy.stats import f_oneway

grupo_rl = df[df['modelo'] == 'RL']['mae']
grupo_mm = df[df['modelo'] == 'MM']['mae']
grupo_arima = df[df['modelo'] == 'ARIMA']['mae']
grupo_es = df[df['modelo'] == 'ES']['mae']

f_stat, p_value = f_oneway(grupo_rl, grupo_mm, grupo_arima, grupo_es)
print(f'F = {f_stat:.4f}, p-valor = {p_value:.4f}')
```

---

**3. Compara√ß√£o Entre Modelos (N√£o-Param√©trico):**
- **Nome:** Kruskal-Wallis H test
- **Quando:** Se res√≠duos n√£o forem normais
- **Hip√≥teses:** Iguais ao ANOVA, mas sobre medianas
- **Crit√©rio:** Œ± = 0.05
- **Estat√≠stica:** H (qui-quadrado aproximado)

**C√≥digo:**
```python
from scipy.stats import kruskal

h_stat, p_value = kruskal(grupo_rl, grupo_mm, grupo_arima, grupo_es)
print(f'H = {h_stat:.4f}, p-valor = {p_value:.4f}')
```

---

**4. Compara√ß√µes Post-Hoc (Param√©trico):**
- **Nome:** Tukey's Honestly Significant Difference (HSD)
- **Quando:** Ap√≥s rejeitar H0 em ANOVA
- **Objetivo:** Identificar quais pares de modelos diferem
- **Crit√©rio:** Œ± = 0.05 com corre√ß√£o para m√∫ltiplas compara√ß√µes

**C√≥digo:**
```python
from scipy.stats import tukey_hsd

res = tukey_hsd(grupo_rl, grupo_mm, grupo_arima, grupo_es)
print(res)
```

---

**5. Compara√ß√µes Post-Hoc (N√£o-Param√©trico):**
- **Nome:** Dunn's test com corre√ß√£o de Bonferroni
- **Quando:** Ap√≥s rejeitar H0 em Kruskal-Wallis
- **Objetivo:** Compara√ß√µes pareadas
- **Crit√©rio:** Œ±_ajustado = 0.05 / 6 = 0.0083 (6 compara√ß√µes poss√≠veis)

---

**6. Correla√ß√£o:**
- **Nome:** Correla√ß√£o de Pearson
- **Quando:** Analisar rela√ß√£o entre m√©tricas e custo
- **Hip√≥teses:**
  - H0: œÅ = 0 (sem correla√ß√£o)
  - H1: œÅ ‚â† 0
- **Crit√©rio:** Œ± = 0.05
- **Interpreta√ß√£o de |r|:**
  - 0.0-0.3: Fraca
  - 0.3-0.7: Moderada
  - 0.7-1.0: Forte

**C√≥digo:**
```python
from scipy.stats import pearsonr

correlacoes = {}
for metrica in ['cpu', 'memoria', 'storage', 'requisicoes']:
    r, p_value = pearsonr(df[metrica], df['custo'])
    correlacoes[metrica] = {'r': r, 'p': p_value}
```

---

**7. Tamanho de Efeito:**
- **Nome:** Eta-squared (Œ∑¬≤) para ANOVA
- **F√≥rmula:** Œ∑¬≤ = SS_between / SS_total
- **Interpreta√ß√£o:**
  - 0.01: Efeito pequeno
  - 0.06: Efeito m√©dio
  - 0.14: Efeito grande

---

**8. Intervalos de Confian√ßa:**
- **95% CI para m√©dia de cada modelo**
- **F√≥rmula:** CI = xÃÑ ¬± t_{Œ±/2} √ó (s / ‚àön)
- **Interpreta√ß√£o:** Se CIs n√£o se sobrep√µem, sugere diferen√ßa significativa

### 12.3 Tratamento de Dados Faltantes e Outliers

#### Dados Faltantes:

**Preven√ß√£o (por constru√ß√£o):**
- Dados sint√©ticos n√£o ter√£o valores faltantes por design
- Valida√ß√£o pr√©-experimento garante completude

**Se Ocorrerem (bug ou erro de execu√ß√£o):**

**Regra 1: Exclus√£o de Execu√ß√£o Completa**
- Se uma execu√ß√£o falhar (erro de c√≥digo, crash), **remover completamente**
- N√£o imputar dados faltantes de m√©tricas de avalia√ß√£o
- **Justificativa:** Impedir vi√©s; melhor ter n=29 do que dados imputados incorretos

**Regra 2: Re-execu√ß√£o**
- Se execu√ß√£o falhou por erro t√©cnico, **re-executar** com mesmo seed
- Documentar ocorr√™ncia no log

**C√≥digo de Verifica√ß√£o:**
```python
# Verificar dados faltantes
assert df.isna().sum().sum() == 0, "Dados faltantes detectados!"

# Verificar n√∫mero de execu√ß√µes
assert len(df) == 120, f"Esperado 120 execu√ß√µes, obtido {len(df)}"
```

#### Outliers:

**Defini√ß√£o de Outlier:**
- Valores al√©m de **3 desvios-padr√£o** da m√©dia do grupo
- Ou valores imposs√≠veis (MAE negativo, MAPE > 200%)

**Tratamento:**

**Op√ß√£o 1: Investiga√ß√£o (Preferencial)**
1. Identificar outlier
2. Verificar log de execu√ß√£o correspondente
3. Se houver erro de execu√ß√£o ‚Üí **remover** e re-executar
4. Se outlier for leg√≠timo (modelo realmente ruim) ‚Üí **manter**

**Op√ß√£o 2: Winsoriza√ß√£o (Se Necess√°rio)**
- Substituir outliers pelos valores no percentil 1% e 99%
- **Usar apenas se**: outliers forem devido a variabilidade natural, n√£o erros
- **Documentar:** quais valores foram modificados

**C√≥digo de Detec√ß√£o:**
```python
def detectar_outliers(df, coluna, n_std=3):
    """Detecta outliers usando regra de n desvios-padr√£o"""
    media = df[coluna].mean()
    std = df[coluna].std()
    outliers = df[(df[coluna] < media - n_std*std) | 
                  (df[coluna] > media + n_std*std)]
    return outliers

# Aplicar
outliers_mae = detectar_outliers(df, 'mae', n_std=3)
if len(outliers_mae) > 0:
    print(f'Outliers detectados: {len(outliers_mae)}')
    print(outliers_mae[['modelo', 'repeticao', 'mae']])
```

**Decis√£o Final:**
- **Padr√£o:** Manter outliers leg√≠timos (refletem variabilidade real)
- **Exce√ß√£o:** Remover apenas se houver evid√™ncia de erro t√©cnico
- **Transpar√™ncia:** Documentar todas as remo√ß√µes e justificativas

---

## 13. Avalia√ß√£o de Validade (Amea√ßas e Mitiga√ß√£o)

Esta se√ß√£o identifica as principais amea√ßas √† validade do experimento, seguindo a classifica√ß√£o de Wohlin et al. (2012): validade de conclus√£o, validade interna, validade de constructo e validade externa. Para cada categoria, s√£o listadas as amea√ßas espec√≠ficas ao contexto deste estudo e as estrat√©gias planejadas de mitiga√ß√£o.

### 13.1 Validade de Conclus√£o

**Defini√ß√£o:** A validade de conclus√£o refere-se √† capacidade de tirar conclus√µes corretas sobre a rela√ß√£o entre tratamento (tipo de modelo) e resultado (erro de previs√£o), considerando a robustez estat√≠stica.

#### Amea√ßa 1.1: Poder Estat√≠stico Insuficiente

**Descri√ß√£o:**
Com n=30 repeti√ß√µes por modelo, o poder estat√≠stico √© de aproximadamente 80% para detectar diferen√ßas de efeito m√©dio (d de Cohen ‚âà 0.5), correspondendo a diferen√ßas de ~15-20% no erro m√©dio. Se as diferen√ßas reais entre modelos forem sutis (< 10%), o experimento pode **n√£o detectar diferen√ßas que realmente existem** (Erro Tipo II).

**Impacto:**
- Risco de concluir erroneamente que modelos t√™m desempenho equivalente
- Particularmente cr√≠tico se modelos avan√ßados (ARIMA, ES) apresentarem melhoria marginal sobre modelos simples

**Estrat√©gias de Mitiga√ß√£o:**
1. **Valida√ß√£o Cruzada k-fold (k=5):** Aumenta o n√∫mero efetivo de avalia√ß√µes (30 √ó 5 = 150 por modelo), melhorando a sensibilidade
2. **An√°lise de Tamanho de Efeito:** Calcular Œ∑¬≤ (eta-squared) mesmo quando p ‚â• 0.05, para quantificar magnitude das diferen√ßas
3. **Intervalos de Confian√ßa:** Reportar 95% CI para todas as m√©dias, permitindo interpreta√ß√£o pr√°tica al√©m de signific√¢ncia estat√≠stica
4. **An√°lise de Sensibilidade:** Se resultados forem inconclusivos, considerar aumentar n para 50 repeti√ß√µes ou usar Œ± mais liberal (0.10)

**Monitoramento:**
- Calcular poder estat√≠stico post-hoc ap√≥s coleta de dados
- Verificar se tamanho de efeito observado est√° dentro do detect√°vel (d ‚â• 0.5)

---

#### Amea√ßa 1.2: Viola√ß√£o de Suposi√ß√µes Estat√≠sticas

**Descri√ß√£o:**
ANOVA requer:
1. **Normalidade:** Os res√≠duos de cada grupo devem seguir distribui√ß√£o normal
2. **Homocedasticidade:** Vari√¢ncias dos grupos devem ser homog√™neas
3. **Independ√™ncia:** Observa√ß√µes devem ser independentes

Erros de previs√£o podem n√£o seguir distribui√ß√£o normal (por exemplo, serem assim√©tricos ou ter caudas pesadas), violando a primeira suposi√ß√£o. Alguns modelos podem ter variabilidade intrinsecamente maior que outros, violando a segunda.

**Impacto:**
- ANOVA pode produzir p-valores incorretos
- Conclus√µes sobre signific√¢ncia estat√≠stica podem ser inv√°lidas

**Estrat√©gias de Mitiga√ß√£o:**
1. **Teste de Normalidade Pr√©vio:** Aplicar Shapiro-Wilk test aos res√≠duos de cada grupo (Œ± = 0.05)
2. **Teste N√£o-Param√©trico Alternativo:** Se normalidade for violada (p < 0.05), usar **Kruskal-Wallis H test** no lugar de ANOVA
3. **Teste de Homogeneidade de Vari√¢ncias:** Aplicar Levene's test; se violado, usar Welch's ANOVA
4. **Transforma√ß√µes:** Se necess√°rio, aplicar transforma√ß√£o logar√≠tmica ou Box-Cox aos dados antes da an√°lise
5. **Bootstrapping:** Usar bootstrap para calcular intervalos de confian√ßa n√£o-param√©tricos

**Monitoramento:**
- Inspe√ß√£o visual: Q-Q plots para avaliar normalidade
- An√°lise de res√≠duos: gr√°ficos de res√≠duos vs. valores ajustados

---

#### Amea√ßa 1.3: Problema de M√∫ltiplas Compara√ß√µes

**Descri√ß√£o:**
Com 4 modelos, h√° **6 compara√ß√µes pareadas poss√≠veis** (RL vs. MM, RL vs. ARIMA, RL vs. ES, MM vs. ARIMA, MM vs. ES, ARIMA vs. ES). Ao realizar m√∫ltiplos testes com Œ± = 0.05 cada, a chance de pelo menos um **falso positivo** (Erro Tipo I) aumenta:

P(pelo menos 1 falso positivo) = 1 - (1 - 0.05)‚Å∂ ‚âà 26.5%

**Impacto:**
- Infla√ß√£o da taxa de erro Tipo I
- Aumento do risco de declarar diferen√ßas significativas que s√£o, na verdade, acaso estat√≠stico

**Estrat√©gias de Mitiga√ß√£o:**
1. **Testes Post-Hoc com Corre√ß√£o:**
   - Ap√≥s ANOVA: Usar **Tukey's HSD** (controla automaticamente o family-wise error rate)
   - Ap√≥s Kruskal-Wallis: Usar **Dunn's test com corre√ß√£o de Bonferroni**
2. **Corre√ß√£o de Bonferroni (se necess√°rio):**
   - Ajustar Œ± para Œ±_ajustado = 0.05 / 6 = 0.0083 para compara√ß√µes individuais
3. **Prioriza√ß√£o de Compara√ß√µes:**
   - Definir compara√ß√µes de interesse prim√°rio a priori (ex: ARIMA vs. RL)
   - Limitar compara√ß√µes explorat√≥rias n√£o planejadas

**Monitoramento:**
- Documentar quais compara√ß√µes foram planejadas vs. explorat√≥rias
- Reportar tanto p-valores brutos quanto ajustados

---

#### Amea√ßa 1.4: Variabilidade de Implementa√ß√£o dos Modelos

**Descri√ß√£o:**
Diferen√ßas observadas entre modelos podem ser parcialmente devidas a **diferen√ßas na qualidade da implementa√ß√£o**, n√£o apenas a superioridade inerente do algoritmo. Por exemplo:
- Um modelo pode ter bugs sutis que aumentam artificialmente seu erro
- Hiperpar√¢metros padr√£o de bibliotecas podem favorecer alguns modelos
- Otimiza√ß√£o de c√≥digo pode variar (ex: ARIMA pode ser mais lento e ter converg√™ncia inst√°vel)

**Impacto:**
- Confus√£o entre efic√°cia do algoritmo e qualidade da implementa√ß√£o
- Resultados n√£o refletem potencial real de cada modelo

**Estrat√©gias de Mitiga√ß√£o:**
1. **Uso de Bibliotecas Consolidadas:**
   - Scikit-learn: Regress√£o Linear, valida√ß√£o cruzada
   - Statsmodels: ARIMA, Exponential Smoothing
   - Valida√ß√£o: Bibliotecas s√£o amplamente testadas e usadas academicamente
2. **Valida√ß√£o de Implementa√ß√£o:**
   - Testar cada modelo com datasets conhecidos (benchmarks p√∫blicos)
   - Comparar resultados com exemplos da documenta√ß√£o oficial
   - Revis√£o de c√≥digo com orientador
3. **Documenta√ß√£o de Hiperpar√¢metros:**
   - Documentar todos os hiperpar√¢metros usados (mesmo padr√µes)
   - Justificar escolhas (ex: grid search para ARIMA, valores padr√£o para RL)
4. **An√°lise de Sensibilidade (Opcional):**
   - Testar varia√ß√µes de hiperpar√¢metros principais
   - Verificar se conclus√µes se mant√™m com configura√ß√µes alternativas

**Monitoramento:**
- Logs detalhados de execu√ß√£o de cada modelo
- Revis√£o de warnings e convergence issues

---

#### Amea√ßa 1.5: Variabilidade Aleat√≥ria N√£o Controlada

**Descri√ß√£o:**
Apesar da randomiza√ß√£o e das 30 repeti√ß√µes, resultados podem ter alta variabilidade devido a:
- Divis√µes treino/teste com caracter√≠sticas muito diferentes
- Inicializa√ß√µes aleat√≥rias de par√¢metros (em ARIMA, ES)
- Variabilidade natural dos algoritmos de otimiza√ß√£o

Isso pode levar a **intervalos de confian√ßa largos** que n√£o se distinguem entre modelos, mesmo que haja diferen√ßas reais.

**Impacto:**
- Conclus√µes incertas sobre qual modelo √© superior
- Necessidade de mais repeti√ß√µes para estabilizar resultados

**Estrat√©gias de Mitiga√ß√£o:**
1. **N√∫mero Adequado de Repeti√ß√µes:** n=30 √© suficiente pelo Teorema do Limite Central
2. **Seeds Documentados:** Todos os seeds aleat√≥rios salvos em CSV para reprodutibilidade total
3. **Valida√ß√£o Cruzada:** k-fold reduz depend√™ncia de uma √∫nica divis√£o treino/teste
4. **An√°lise de Vari√¢ncia:** Calcular e reportar desvio padr√£o e coeficiente de varia√ß√£o (CV = œÉ/Œº)
5. **Replica√ß√£o:** Se variabilidade for muito alta (CV > 50%), considerar aumentar n

**Monitoramento:**
- Inspe√ß√£o de boxplots para detectar variabilidade excessiva
- An√°lise de outliers (valores > 3 desvios-padr√£o)

---

### 13.2 Validade Interna

**Defini√ß√£o:** A validade interna refere-se √† capacidade de estabelecer rela√ß√£o causal correta entre o tratamento (tipo de modelo) e o resultado (erro de previs√£o), eliminando explica√ß√µes alternativas.

#### Amea√ßa 2.1: Hist√≥ria (History)

**Descri√ß√£o:**
Eventos externos durante a execu√ß√£o do experimento podem afetar os resultados de forma sistem√°tica:
- **Aquecimento de Hardware:** CPU pode aquecer ao longo das 120 execu√ß√µes, afetando performance e tempo de execu√ß√£o
- **Carga do Sistema:** Outros processos no sistema operacional podem consumir recursos
- **Atualiza√ß√µes de Software:** Atualiza√ß√µes autom√°ticas do SO ou antiv√≠rus podem interferir

Se modelos mais lentos (ARIMA) forem executados consistentemente ap√≥s aquecimento, podem ter desvantagem.

**Impacto:**
- Diferen√ßas observadas podem ser devidas a condi√ß√µes de execu√ß√£o, n√£o ao modelo em si
- Vi√©s sistem√°tico contra modelos mais lentos

**Estrat√©gias de Mitiga√ß√£o:**
1. **Randomiza√ß√£o Completa da Ordem de Execu√ß√£o:** As 120 execu√ß√µes ter√£o ordem completamente aleat√≥ria (n√£o bloco de 30 √ó RL, depois 30 √ó MM, etc.)
2. **Limpeza de Ambiente:**
   - Fechar aplica√ß√µes desnecess√°rias antes do experimento
   - Desabilitar atualiza√ß√µes autom√°ticas durante a execu√ß√£o
   - Restart do kernel Python a cada 30 execu√ß√µes (opcional)
3. **Monitoramento de Sistema:**
   - Registrar timestamp, temperatura de CPU e uso de mem√≥ria a cada execu√ß√£o
   - Detectar anomalias (ex: execu√ß√£o com uso de CPU > 90% por processo externo)
4. **An√°lise Post-Hoc:**
   - Testar se ordem de execu√ß√£o (1¬™, 2¬™, ..., 120¬™) correlaciona com erro
   - Regress√£o: Erro ~ Ordem_Execu√ß√£o; se significativo, flag como poss√≠vel confus√£o

**Monitoramento:**
- Logs de timestamp e condi√ß√µes de sistema
- An√°lise: ANOVA Erro ~ Posi√ß√£o_Execu√ß√£o (1-30, 31-60, 61-90, 91-120)

---

#### Amea√ßa 2.2: Matura√ß√£o (Maturation)

**Descri√ß√£o:**
Mudan√ßas no ambiente computacional ao longo do tempo de execu√ß√£o (~1 hora total):
- **Degrada√ß√£o de Hardware:** Poss√≠vel throttling t√©rmico de CPU ap√≥s uso prolongado
- **Degrada√ß√£o de Performance:** Cache ou mem√≥ria podem saturar
- **Fadiga do Pesquisador:** Menos relevante por ser automatizado, mas monitoramento pode se tornar menos atento

**Impacto:**
- Execu√ß√µes finais podem ter performance sistematicamente pior que iniciais
- Vi√©s temporal contra modelos executados mais tardiamente

**Estrat√©gias de Mitiga√ß√£o:**
1. **Randomiza√ß√£o:** Mesma estrat√©gia da Amea√ßa 2.1 (ordem aleat√≥ria mitiga matura√ß√£o)
2. **Execu√ß√£o Automatizada:** Script Python executa tudo sem interven√ß√£o humana, eliminando varia√ß√£o por fadiga
3. **Controle T√©rmico:**
   - Executar experimento em ambiente climatizado
   - Monitorar temperatura de CPU; se ultrapassar limiar (ex: 85¬∞C), pausar e resfriar
4. **Intervalos de Descanso (Opcional):**
   - Pausa de 5 minutos a cada 40 execu√ß√µes para resfriamento

**Monitoramento:**
- An√°lise de tend√™ncia temporal: Regress√£o Erro ~ Tempo_Decorrido
- Temperatura de CPU registrada em log

---

#### Amea√ßa 2.3: Instrumenta√ß√£o (Instrumentation)

**Descri√ß√£o:**
Mudan√ßas ou inconsist√™ncias na forma de medir as vari√°veis dependentes:
- **C√°lculo de M√©tricas:** Se f√≥rmulas de MAE, RMSE ou MAPE forem implementadas incorretamente ou mudarem durante o experimento
- **Precis√£o Num√©rica:** Erros de arredondamento ou overflow em c√°lculos
- **Vers√µes de Bibliotecas:** Atualiza√ß√£o acidental de Scikit-learn ou Statsmodels no meio do experimento

**Impacto:**
- Medidas de erro inconsistentes entre execu√ß√µes
- Invalida√ß√£o da comparabilidade dos resultados

**Estrat√©gias de Mitiga√ß√£o:**
1. **Implementa√ß√£o √önica e Validada:**
   - Fun√ß√µes de c√°lculo de m√©tricas escritas uma vez e testadas antes do experimento
   - Uso de implementa√ß√µes padr√£o (sklearn.metrics.mean_absolute_error, etc.)
2. **Ambiente Virtual Fixo:**
   - Criar ambiente virtual Python com vers√µes fixas de bibliotecas (requirements.txt)
   - N√£o atualizar bibliotecas durante o experimento
3. **Testes de Valida√ß√£o:**
   - Testar c√°lculos com dados sint√©ticos de resultado conhecido
   - Comparar com exemplos da documenta√ß√£o oficial
4. **Documenta√ß√£o de Vers√µes:**
   - Salvar output de `pip freeze` antes do experimento

**Monitoramento:**
- Verificar que todas as 120 execu√ß√µes usaram mesma vers√£o de bibliotecas
- Testes unit√°rios das fun√ß√µes de c√°lculo de m√©tricas

---

#### Amea√ßa 2.4: Sele√ß√£o (Selection Bias)

**Descri√ß√£o:**
Vi√©s na aloca√ß√£o de dados a diferentes modelos. No contexto deste experimento, seria se:
- Modelos diferentes recebessem subconjuntos diferentes dos dados
- Divis√µes treino/teste fossem sistematicamente diferentes entre modelos

**Impacto:**
- Compara√ß√£o injusta entre modelos
- Conclus√µes sobre superioridade de um modelo podem ser artefato da sele√ß√£o de dados

**Estrat√©gias de Mitiga√ß√£o:**
1. **Dados Id√™nticos para Todos os Modelos:**
   - Todos os 4 modelos recebem exatamente o mesmo dataset de entrada
   - Mesmas 720 observa√ß√µes (30 dias √ó 24 horas)
   - Mesmas 4 m√©tricas (CPU, mem√≥ria, storage, requisi√ß√µes)
2. **Divis√£o Treino/Teste Consistente por Repeti√ß√£o:**
   - Em cada repeti√ß√£o, todos os 4 modelos usam o mesmo seed para divis√£o treino/teste
   - Propor√ß√£o fixa 70%-30%
   - Mesmos 504 pontos de treino e 216 de teste para todos
3. **Sem Pr√©-Sele√ß√£o de Dados:**
   - Nenhum modelo recebe pr√©-processamento especial diferenciado
   - Mesma normaliza√ß√£o/padroniza√ß√£o aplicada a todos

**Monitoramento:**
- Verifica√ß√£o: Hash MD5 do dataset de entrada √© id√™ntico para todas as execu√ß√µes
- Assert: len(X_train) e len(X_test) s√£o iguais para todos os modelos em cada repeti√ß√£o

---

#### Amea√ßa 2.5: Overfitting Diferenciado Entre Modelos

**Descri√ß√£o:**
Alguns modelos podem sofrer overfitting (ajustar-se excessivamente aos dados de treino) mais que outros:
- **ARIMA:** Com ordem (p, d, q) muito alta, pode capturar ru√≠do do treino
- **Regress√£o Linear:** Menos propensa a overfitting com poucas features
- **Exponential Smoothing:** Pode se ajustar demais se Œ± estiver muito alto

Se overfitting n√£o for detectado, pode parecer que um modelo √© superior no treino, mas falha no teste.

**Impacto:**
- Modelo com melhor erro de treino pode ter pior erro de teste
- Avalia√ß√£o de generaliza√ß√£o comprometida

**Estrat√©gias de Mitiga√ß√£o:**
1. **Valida√ß√£o Cruzada Obrigat√≥ria:**
   - k-fold (k=5) para todos os modelos
   - Erro final √© m√©dia dos erros em 5 folds independentes
2. **Monitoramento Treino vs. Teste:**
   - Calcular M12 (Diferen√ßa Treino/Teste) para cada modelo
   - Flagging se diferen√ßa > 15% ‚Üí Poss√≠vel overfitting
3. **Regulariza√ß√£o (quando aplic√°vel):**
   - Regress√£o Linear: Considerar Ridge/Lasso se overfitting for detectado
   - ARIMA: Usar crit√©rios AIC/BIC para sele√ß√£o de ordem (p, d, q)
4. **Hiperpar√¢metros Conservadores:**
   - Preferir modelos mais simples (Occam's Razor)
   - ARIMA: Limitar p, d, q a valores razo√°veis (‚â§ 3)

**Monitoramento:**
- Plotar erro de treino vs. teste para cada modelo
- An√°lise de res√≠duos em dados de teste

---

#### Amea√ßa 2.6: Qualidade e Realismo dos Dados Sint√©ticos

**Descri√ß√£o:**
Embora o experimento utilize **dados reais do Google Cluster Data 2019** (n√£o puramente sint√©ticos), a **convers√£o de m√©tricas em custos √© estimada**, n√£o real:
- Custos s√£o calculados com tabelas de precifica√ß√£o p√∫blicas (AWS, Azure, GCP)
- N√£o refletem custos reais do Google (que usa precifica√ß√£o interna)
- Modelo de precifica√ß√£o simplificado (rela√ß√£o linear entre m√©tricas e custo)

**Impacto:**
- Rela√ß√£o entre m√©tricas e custo pode ser artificial
- Modelos podem se beneficiar de padr√µes que n√£o existiriam com custos reais
- Generaliza√ß√£o para custos reais de outros provedores pode ser limitada

**Estrat√©gias de Mitiga√ß√£o:**
1. **Modelo de Precifica√ß√£o Baseado em Literatura:**
   - Usar f√≥rmulas de c√°lculo de custo validadas em papers acad√™micos
   - Consultar tabelas p√∫blicas de precifica√ß√£o (AWS EC2, Azure VMs, GCP Compute Engine)
   - Documentar f√≥rmula exata usada
2. **Inclus√£o de Ru√≠do Realista:**
   - Adicionar varia√ß√£o estoc√°stica aos custos (¬± 5-10%) para simular flutua√ß√µes reais
   - Evitar rela√ß√µes perfeitamente lineares
3. **Valida√ß√£o com Especialistas:**
   - Revisar modelo de precifica√ß√£o com orientador
   - Comparar padr√µes de custo gerados com benchmarks da literatura
4. **Limita√ß√£o da Generaliza√ß√£o:**
   - Reconhecer explicitamente na discuss√£o que custos s√£o estimados
   - Recomendar valida√ß√£o com dados reais em trabalhos futuros

**Monitoramento:**
- An√°lise explorat√≥ria: Correla√ß√µes entre m√©tricas e custos devem ser plaus√≠veis (0.6-0.9)
- Compara√ß√£o com valores de refer√™ncia da literatura

---

### 13.3 Validade de Constructo

**Defini√ß√£o:** A validade de constructo refere-se a se as medidas escolhidas realmente representam os conceitos te√≥ricos de interesse e se n√£o h√° ambiguidade na interpreta√ß√£o.

#### Amea√ßa 3.1: Operacionaliza√ß√£o de "Custo"

**Descri√ß√£o:**
O conceito de "custo cloud" √© multifaceted, mas neste experimento √© **simplificado**:
- **Inclu√≠do:** Custo de compute (CPU, mem√≥ria), storage, requisi√ß√µes
- **Exclu√≠do:**
  - Custos de transfer√™ncia de dados entre regi√µes/zonas
  - Custos de servi√ßos gerenciados (bancos de dados, cache, load balancers)
  - Reserved instances, savings plans, descontos corporativos
  - Custos de suporte t√©cnico, SLAs

A m√©trica de custo usada pode **n√£o capturar completamente** o que stakeholders entendem por "custo real de cloud".

**Impacto:**
- Modelos podem prever bem o "custo simplificado" mas n√£o o "custo total real"
- Generaliza√ß√£o limitada para contextos onde custos exclu√≠dos s√£o significativos (ex: > 30% do custo total)

**Estrat√©gias de Mitiga√ß√£o:**
1. **Defini√ß√£o Expl√≠cita de Escopo:**
   - Documentar claramente quais componentes de custo s√£o inclu√≠dos/exclu√≠dos (Se√ß√£o 4.1)
   - Delimitar contextos de aplicabilidade (workloads compute-intensive sem servi√ßos gerenciados)
2. **Justificativa Te√≥rica:**
   - Fundamentar escolha em literatura (ex: papers que usam mesma simplifica√ß√£o)
   - Argumentar que componentes inclu√≠dos representam 60-80% do custo t√≠pico de IaaS
3. **An√°lise de Sensibilidade (Opcional):**
   - Testar modelo com diferentes pesos para componentes de custo
   - Verificar se conclus√µes se mant√™m com varia√ß√µes de ¬± 20% nos pesos
4. **Transpar√™ncia nos Resultados:**
   - Discutir limita√ß√µes da operacionaliza√ß√£o na se√ß√£o de discuss√£o
   - Recomendar extens√µes futuras (incluir custos de rede, servi√ßos gerenciados)

**Monitoramento:**
- Comparar propor√ß√µes de custo com benchmarks da literatura (ex: CPU deve ser 40-60% do total)

---

#### Amea√ßa 3.2: MAE como M√©trica Prim√°ria

**Descri√ß√£o:**
MAE (Mean Absolute Error) foi escolhida como m√©trica prim√°ria para compara√ß√£o, mas:
- **N√£o penaliza desproporcionalmente erros grandes:** Diferente de RMSE, que penaliza outliers
- **N√£o considera erro relativo:** Um erro de R$ 100 √© muito diferente em um custo de R$ 200 vs. R$ 10.000
- **Pode n√£o refletir impacto pr√°tico:** Stakeholders podem se preocupar mais com evitar grandes subestima√ß√µes (que causam estouro de or√ßamento) do que com erro m√©dio

Se modelos diferem primariamente em capacidade de evitar erros extremos, MAE pode n√£o capturar essa diferen√ßa.

**Impacto:**
- Modelo com menor MAE pode n√£o ser o mais √∫til na pr√°tica
- Ambiguidade sobre qual modelo √© "melhor" depende de qual aspecto do erro √© mais importante

**Estrat√©gias de Mitiga√ß√£o:**
1. **Uso de M√∫ltiplas M√©tricas:**
   - **MAE:** Erro m√©dio absoluto (m√©trica prim√°ria)
   - **RMSE:** Penaliza erros grandes (m√©trica secund√°ria)
   - **MAPE:** Erro percentual, relevante para compara√ß√£o relativa
   - **Erro m√°ximo:** Detectar casos extremos
2. **An√°lise Complementar:**
   - Reportar percentual de previs√µes com erro > 20%
   - Identificar casos onde erro foi particularmente grande (> 2 √ó MAE m√©dio)
3. **Justificativa da Escolha:**
   - MAE √© interpret√°vel (mesma unidade que custo - R$)
   - Menos sens√≠vel a outliers que RMSE
   - Amplamente usado em literatura de forecasting
4. **Discuss√£o Qualitativa:**
   - Analisar trade-offs entre m√©tricas
   - Discutir em quais contextos cada m√©trica √© mais relevante

**Monitoramento:**
- Comparar rankings de modelos por MAE vs. RMSE vs. MAPE
- Verificar se conclus√µes se mant√™m consistentes

---

#### Amea√ßa 3.3: "Acur√°cia" vs. "Utilidade Pr√°tica"

**Descri√ß√£o:**
O experimento mede **acur√°cia preditiva** (erro de previs√£o), mas n√£o mede **utilidade pr√°tica**:
- **N√£o mede:** Facilidade de implementa√ß√£o, tempo de execu√ß√£o, interpretabilidade, custo computacional
- **N√£o considera:** Prefer√™ncias de stakeholders (ex: CFO pode preferir modelo conservador que superestima custos para evitar surpresas)

Um modelo pode ter menor erro estat√≠stico mas ser menos √∫til (ex: ARIMA pode ser mais preciso mas muito lento e dif√≠cil de manter).

**Impacto:**
- Conclus√£o de "modelo superior" pode n√£o se traduzir em ado√ß√£o pr√°tica
- Gap entre validade estat√≠stica e relev√¢ncia organizacional

**Estrat√©gias de Mitiga√ß√£o:**
1. **Coleta de M√©tricas Adicionais:**
   - **Tempo de execu√ß√£o:** Registrar dura√ß√£o de treino + previs√£o para cada modelo
   - **Complexidade de implementa√ß√£o:** Linhas de c√≥digo, n√∫mero de hiperpar√¢metros
   - **Interpretabilidade:** Avalia√ß√£o qualitativa (ex: coeficientes de RL s√£o interpret√°veis)
2. **Discuss√£o de Trade-Offs:**
   - Se√ß√£o espec√≠fica comparando acur√°cia vs. simplicidade vs. velocidade
   - Matriz de decis√£o: quando cada modelo √© mais apropriado
3. **Recomenda√ß√µes Contextualizadas:**
   - "Use ARIMA se precis√£o √© cr√≠tica e tempo de treino n√£o √© problema"
   - "Use RL se interpretabilidade e velocidade s√£o prioridades"
4. **Valida√ß√£o com Stakeholders (Futura):**
   - Ap√≥s experimento, apresentar resultados a profissionais de DevOps/FinOps
   - Coletar feedback sobre utilidade percebida

**Monitoramento:**
- Tabela comparativa: Acur√°cia √ó Tempo √ó Complexidade √ó Interpretabilidade

---

#### Amea√ßa 3.4: Mono-Method Bias (Vi√©s de M√©todo √önico)

**Descri√ß√£o:**
Todas as vari√°veis dependentes (MAE, RMSE, MAPE) s√£o **m√©tricas quantitativas de erro**, medidas de forma automatizada. N√£o h√°:
- Valida√ß√£o qualitativa (entrevistas com usu√°rios)
- Observa√ß√£o de comportamento em produ√ß√£o
- Medidas subjetivas (confian√ßa na previs√£o, satisfa√ß√£o do usu√°rio)

Se houver aspectos importantes do conceito "modelo de previs√£o eficaz" que n√£o s√£o capturados por m√©tricas de erro, eles ser√£o omitidos.

**Impacto:**
- Vis√£o limitada do fen√¥meno estudado
- Poss√≠vel perda de insights importantes n√£o quantific√°veis

**Estrat√©gias de Mitiga√ß√£o:**
1. **Limita√ß√£o Expl√≠cita do Escopo:**
   - Reconhecer que experimento foca em acur√°cia t√©cnica, n√£o ado√ß√£o ou satisfa√ß√£o
   - Delimitar que objetivo √© compara√ß√£o quantitativa, n√£o estudo de usabilidade
2. **An√°lise Qualitativa Complementar (Opcional):**
   - Revis√£o de literatura sobre percep√ß√µes de usu√°rios de modelos de previs√£o
   - Discuss√£o te√≥rica sobre fatores organizacionais
3. **Triangula√ß√£o com Literatura:**
   - Comparar resultados com estudos de caso qualitativos publicados
   - Discutir converg√™ncia/diverg√™ncia de achados
4. **Recomenda√ß√£o de Pesquisas Futuras:**
   - Propor estudos mistos (quanti + quali) como extens√£o

**Monitoramento:**
- N/A (limita√ß√£o reconhecida, n√£o mitig√°vel neste experimento)

---

### 13.4 Validade Externa

**Defini√ß√£o:** A validade externa refere-se √† capacidade de generalizar os resultados para outros contextos, popula√ß√µes e situa√ß√µes al√©m do experimento espec√≠fico.

#### Amea√ßa 4.1: Especificidade do Provedor Cloud (Google)

**Descri√ß√£o:**
Os dados utilizados s√£o exclusivamente do **Google Cluster Data 2019**:
- Workloads espec√≠ficos da infraestrutura Google (Google Borg)
- Padr√µes de uso podem ser √∫nicos do ecossistema Google
- Caracter√≠sticas de escala de hyperscaler (muito larga escala)
- Precifica√ß√£o interna do Google difere de AWS, Azure, GCP p√∫blico

Resultados podem **n√£o se generalizar** para:
- AWS (EC2, Lambda, etc.)
- Azure (VMs, App Services, etc.)
- GCP p√∫blico (Compute Engine)
- Outros provedores (DigitalOcean, Linode, etc.)

**Impacto:**
- Modelos que performam bem com dados Google podem n√£o performar bem com dados AWS
- Padr√µes de workload e estruturas de custo s√£o provider-specific
- Limita√ß√£o severa da generaliza√ß√£o para ambientes multi-cloud

**Estrat√©gias de Mitiga√ß√£o:**
1. **Documenta√ß√£o Expl√≠cita do Contexto:**
   - Se√ß√µes 4.4 e 4.5 j√° listam esta limita√ß√£o
   - Delimitar claramente que resultados aplicam-se a "workloads similares aos traces Google"
2. **Uso de Modelo de Precifica√ß√£o Gen√©rico:**
   - Aplicar tabelas de precifica√ß√£o de m√∫ltiplos provedores (AWS, Azure, GCP) quando poss√≠vel
   - Comparar se conclus√µes se mant√™m com diferentes tabelas de pre√ßos
3. **Generaliza√ß√£o Te√≥rica:**
   - Argumentar que padr√µes fundamentais (tend√™ncia, sazonalidade) s√£o comuns a qualquer cloud
   - Focar em compara√ß√£o relativa entre modelos, n√£o valores absolutos de erro
4. **Recomenda√ß√£o de Valida√ß√£o Externa:**
   - Propor replica√ß√£o do experimento com datasets de outros provedores (Azure Public Dataset, etc.)
   - Disponibilizar c√≥digo para facilitar replica√ß√£o

**Monitoramento:**
- Compara√ß√£o de resultados com papers que usaram dados de outros provedores
- An√°lise de caracter√≠sticas do dataset Google vs. benchmarks de outros provedores

---

#### Amea√ßa 4.2: Per√≠odo Temporal Espec√≠fico (Maio 2019)

**Descri√ß√£o:**
Os dados cobrem **maio de 2019**:
- Padr√µes sazonais anuais n√£o s√£o capturados (apenas ~30 dias)
- Eventos espec√≠ficos daquele per√≠odo podem ter afetado os dados
- Tecnologia e arquiteturas cloud de 2019 podem diferir de 2024-2025
- Workloads podem ter mudado (ex: aumento de workloads de ML/IA)

Resultados podem n√£o se generalizar para:
- Outros per√≠odos do ano (ex: Black Friday, final de ano)
- Anos diferentes (mudan√ßas tecnol√≥gicas)
- Contextos p√≥s-pandemia (padr√µes de uso mudaram)

**Impacto:**
- Modelos podem capturar padr√µes espec√≠ficos de maio 2019 que n√£o se repetem
- Generaliza√ß√£o temporal limitada

**Estrat√©gias de Mitiga√ß√£o:**
1. **Sele√ß√£o de Per√≠odo T√≠pico:**
   - Verificar na documenta√ß√£o do Google Cluster Data se maio 2019 teve eventos at√≠picos
   - Evitar per√≠odos com feriados ou manuten√ß√µes grandes conhecidas
2. **An√°lise de M√∫ltiplas Janelas (Opcional):**
   - Se tempo permitir, testar com diferentes meses do dataset (abril, junho)
   - Verificar se conclus√µes se mant√™m
3. **Foco em Padr√µes Fundamentais:**
   - Analisar padr√µes di√°rios/semanais (que s√£o mais est√°veis ao longo dos anos)
   - Evitar conclus√µes sobre sazonalidade anual
4. **Transpar√™ncia:**
   - Reconhecer limita√ß√£o na discuss√£o
   - Recomendar valida√ß√£o com dados mais recentes

**Monitoramento:**
- An√°lise explorat√≥ria: Detectar eventos an√¥malos no per√≠odo selecionado
- Compara√ß√£o com papers que usaram outros per√≠odos

---

#### Amea√ßa 4.3: Escala e Complexidade (Hyperscaler vs. PMEs)

**Descri√ß√£o:**
Google Cluster Data representa **infraestrutura de larga escala** (hyperscaler):
- Milhares de jobs simult√¢neos
- M√∫ltiplos clusters com orquestra√ß√£o complexa (Borg)
- Workloads heterog√™neos e distribu√≠dos
- Padr√µes de uso de grandes volumes

Contextos de **pequenas e m√©dias empresas (PMEs)** podem ser drasticamente diferentes:
- Poucas dezenas de inst√¢ncias
- Workloads mais simples e homog√™neos
- Padr√µes de uso mais previs√≠veis ou mais err√°ticos (dependendo do neg√≥cio)
- Menor escala pode ter maior variabilidade relativa

**Impacto:**
- Modelos treinados com dados de larga escala podem n√£o performar bem em pequena escala
- Padr√µes de sazonalidade e tend√™ncia podem ser diferentes
- Generaliza√ß√£o limitada para startups e PMEs

**Estrat√©gias de Mitiga√ß√£o:**
1. **Delimita√ß√£o de Contexto de Aplicabilidade:**
   - Especificar que resultados aplicam-se a "ambientes cloud de m√©dia-alta escala"
   - Recomendar cautela ao aplicar em microempresas ou startups iniciais
2. **An√°lise de Subconjuntos (Opcional):**
   - Selecionar subset de jobs menores do dataset Google
   - Verificar se conclus√µes se mant√™m em workloads de escala reduzida
3. **Discuss√£o de Transferibilidade:**
   - Argumentar que modelos fundamentais (tend√™ncia, autocorrela√ß√£o) aplicam-se em diferentes escalas
   - Reconhecer que magnitudes de erro podem variar
4. **Recomenda√ß√£o de Calibra√ß√£o:**
   - Sugerir que usu√°rios de PMEs re-treinem modelos com seus pr√≥prios dados

**Monitoramento:**
- Compara√ß√£o de caracter√≠sticas do dataset Google com estat√≠sticas de uso cloud de PMEs (quando dispon√≠veis)

---

#### Amea√ßa 4.4: Tipo de Workload

**Descri√ß√£o:**
Google Cluster Data inclui workloads espec√≠ficos:
- Batch processing (processamento em lote)
- Jobs de an√°lise de dados
- Servi√ßos de backend do Google

Pode **n√£o representar** adequadamente:
- Aplica√ß√µes web t√≠picas (padr√µes de tr√°fego HTTP)
- Workloads de machine learning training (uso intensivo de GPU)
- Aplica√ß√µes serverless (fun√ß√µes com execu√ß√£o muito curta)
- Workloads de IoT ou edge computing
- Bancos de dados transacionais (OLTP)

**Impacto:**
- Modelos podem n√£o generalizar para workloads fora do escopo do dataset
- Padr√µes de uso (ex: picos s√∫bitos vs. uso constante) variam drasticamente por tipo de aplica√ß√£o

**Estrat√©gias de Mitiga√ß√£o:**
1. **Caracteriza√ß√£o do Dataset:**
   - Analisar e documentar tipos de jobs presentes no dataset
   - Classificar workloads (compute-intensive, memory-intensive, I/O-intensive)
2. **Delimita√ß√£o de Aplicabilidade:**
   - Especificar que resultados aplicam-se a "workloads de processamento distribu√≠do similar aos traces analisados"
   - Listar tipos de aplica√ß√µes onde resultados s√£o mais/menos aplic√°veis
3. **Heterogeneidade de Dados (Opcional):**
   - Selecionar subset diversificado de jobs (diferentes perfis de uso)
   - Aumentar representatividade dentro do poss√≠vel
4. **Recomenda√ß√£o de Valida√ß√£o:**
   - Propor extens√µes do estudo com datasets de outros tipos (Azure Public Dataset - LLM inference, MIT Supercloud - HPC)

**Monitoramento:**
- Tabela de caracter√≠sticas dos workloads analisados (% CPU-intensive, % memory-intensive, etc.)

---

#### Amea√ßa 4.5: Intera√ß√£o com Caracter√≠sticas Organizacionais

**Descri√ß√£o:**
O experimento √© **puramente t√©cnico**, sem considerar:
- Cultura organizacional (ex: empresas risk-averse vs. risk-tolerant)
- Processos de governan√ßa (ex: aprova√ß√£o de or√ßamentos)
- Maturidade em FinOps (empresas em est√°gios diferentes)
- Expertise t√©cnica da equipe (capacidade de implementar ARIMA vs. RL)

Ado√ß√£o e efic√°cia dos modelos podem depender fortemente de **fatores organizacionais n√£o controlados**.

**Impacto:**
- Modelo "melhor" tecnicamente pode n√£o ser adotado por barreiras organizacionais
- Generaliza√ß√£o para contextos organizacionais diversos √© incerta

**Estrat√©gias de Mitiga√ß√£o:**
1. **Foco em Validade T√©cnica:**
   - Reconhecer que experimento mede efic√°cia t√©cnica, n√£o ado√ß√£o organizacional
   - Delimitar que implementa√ß√£o pr√°tica depende de fatores contextuais
2. **Discuss√£o de Fatores Facilitadores:**
   - Listar pr√©-requisitos organizacionais para cada modelo
   - Ex: ARIMA requer expertise em s√©ries temporais; RL requer menos expertise
3. **Recomenda√ß√µes Contextualizadas:**
   - Matriz de decis√£o: "Use modelo X se contexto organizacional tem caracter√≠stica Y"
4. **Pesquisa Futura:**
   - Propor estudos de caso qualitativos em empresas reais
   - Investigar fatores organizacionais que afetam ado√ß√£o

**Monitoramento:**
- N/A (limita√ß√£o reconhecida, fora do escopo)

---

#### Amea√ßa 4.6: Generaliza√ß√£o para Horizontes de Previs√£o Diferentes

**Descri√ß√£o:**
O experimento foca em janelas temporais de **7, 14 e 30 dias** para treino, com horizonte de previs√£o impl√≠cito de curto-m√©dio prazo:
- N√£o testa previs√µes de longo prazo (6 meses, 1 ano)
- N√£o testa previs√µes de muito curto prazo (horas, minutos)

Modelos podem ter desempenho relativo diferente dependendo do horizonte:
- ARIMA pode ser superior para curto prazo mas degradar em longo prazo
- M√©dia m√≥vel pode ser adequada para muito curto prazo

**Impacto:**
- Conclus√µes sobre "modelo superior" s√£o espec√≠ficas ao horizonte testado
- Generaliza√ß√£o limitada para outros horizontes de previs√£o

**Estrat√©gias de Mitiga√ß√£o:**
1. **Especifica√ß√£o Expl√≠cita do Horizonte:**
   - Documentar que experimento foca em previs√µes de 1-30 dias √† frente
   - Delimitar contexto de aplicabilidade (planejamento de curto-m√©dio prazo)
2. **An√°lise de M√∫ltiplos Horizontes (Opcional):**
   - Se tempo permitir, testar horizontes de 1 dia, 7 dias, 14 dias, 30 dias
   - Verificar se rankings de modelos se mant√™m
3. **Justificativa Pr√°tica:**
   - Argumentar que horizontes de 1-30 dias s√£o mais relevantes para gest√£o operacional de custos
   - Previs√µes de 6+ meses s√£o mais estrat√©gicas e dependem de fatores de neg√≥cio
4. **Transpar√™ncia:**
   - Reconhecer na discuss√£o que resultados podem n√£o aplicar-se a horizontes muito diferentes

**Monitoramento:**
- Compara√ß√£o com literatura sobre performance de modelos em diferentes horizontes

---

### 13.5 Resumo das Principais Amea√ßas e Estrat√©gias de Mitiga√ß√£o

Esta tabela consolida as amea√ßas mais cr√≠ticas identificadas e as a√ß√µes planejadas para mitig√°-las.

| Categoria | Amea√ßa | Severidade | Impacto Principal | Estrat√©gias de Mitiga√ß√£o Planejadas | Status |
|-----------|--------|------------|-------------------|-------------------------------------|--------|
| **Validade de Conclus√£o** | Poder estat√≠stico insuficiente para diferen√ßas sutis (< 10%) | M√©dia | Falha em detectar diferen√ßas reais (Erro Tipo II) | ‚Ä¢ Valida√ß√£o cruzada k-fold (k=5)<br>‚Ä¢ An√°lise de tamanho de efeito (Œ∑¬≤)<br>‚Ä¢ Intervalos de confian√ßa 95%<br>‚Ä¢ Considerar n=50 se inconclusivo | ‚úÖ Planejado |
| **Validade de Conclus√£o** | Viola√ß√£o de normalidade dos res√≠duos | M√©dia | p-valores incorretos em ANOVA | ‚Ä¢ Shapiro-Wilk test pr√©-ANOVA<br>‚Ä¢ Kruskal-Wallis como alternativa n√£o-param√©trica<br>‚Ä¢ Levene's test para homocedasticidade<br>‚Ä¢ Transforma√ß√µes (log, Box-Cox) se necess√°rio | ‚úÖ Planejado |
| **Validade de Conclus√£o** | M√∫ltiplas compara√ß√µes inflam Erro Tipo I | Alta | Falsos positivos (diferen√ßas esp√∫rias) | ‚Ä¢ Tukey's HSD post-hoc (ANOVA)<br>‚Ä¢ Dunn's test + Bonferroni (Kruskal-Wallis)<br>‚Ä¢ Œ± ajustado = 0.0083 para compara√ß√µes<br>‚Ä¢ Prioriza√ß√£o de compara√ß√µes a priori | ‚úÖ Planejado |
| **Validade de Conclus√£o** | Variabilidade de implementa√ß√£o dos modelos | M√©dia | Diferen√ßas devido a bugs, n√£o efic√°cia | ‚Ä¢ Uso de bibliotecas consolidadas (Scikit-learn, Statsmodels)<br>‚Ä¢ Valida√ß√£o com benchmarks conhecidos<br>‚Ä¢ Revis√£o de c√≥digo com orientador<br>‚Ä¢ Documenta√ß√£o completa de hiperpar√¢metros | ‚úÖ Planejado |
| **Validade Interna** | Hist√≥ria (aquecimento de hardware, carga de sistema) | M√©dia | Vi√©s temporal sistem√°tico | ‚Ä¢ Randomiza√ß√£o completa da ordem de execu√ß√£o<br>‚Ä¢ Limpeza de ambiente (fechar apps, desabilitar updates)<br>‚Ä¢ Monitoramento de temperatura/CPU<br>‚Ä¢ An√°lise post-hoc: Erro ~ Ordem_Execu√ß√£o | ‚úÖ Planejado |
| **Validade Interna** | Overfitting diferenciado entre modelos | Alta | Modelo "melhor" em treino, pior em teste | ‚Ä¢ Valida√ß√£o cruzada k-fold obrigat√≥ria<br>‚Ä¢ Monitoramento M12 (diferen√ßa treino/teste)<br>‚Ä¢ Flagging se diferen√ßa > 15%<br>‚Ä¢ AIC/BIC para sele√ß√£o de ordem (ARIMA) | ‚úÖ Planejado |
| **Validade Interna** | Qualidade dos dados (custos estimados, n√£o reais) | Alta | Rela√ß√£o m√©trica-custo artificial | ‚Ä¢ Modelo de precifica√ß√£o baseado em literatura<br>‚Ä¢ Consulta a tabelas p√∫blicas (AWS, Azure, GCP)<br>‚Ä¢ Inclus√£o de ru√≠do estoc√°stico (¬± 5-10%)<br>‚Ä¢ Valida√ß√£o com orientador | ‚úÖ Planejado |
| **Validade de Constructo** | Operacionaliza√ß√£o simplificada de "custo" | M√©dia | N√£o captura custos de rede, servi√ßos gerenciados, descontos | ‚Ä¢ Defini√ß√£o expl√≠cita de escopo (Se√ß√£o 4.1)<br>‚Ä¢ Justificativa: componentes inclu√≠dos = 60-80% do total IaaS<br>‚Ä¢ Transpar√™ncia na discuss√£o<br>‚Ä¢ Recomenda√ß√£o de extens√µes futuras | ‚úÖ Planejado |
| **Validade de Constructo** | MAE como m√©trica prim√°ria n√£o captura todos aspectos | M√©dia | Pode n√£o refletir impacto pr√°tico (ex: evitar grandes erros) | ‚Ä¢ Uso de m√∫ltiplas m√©tricas (MAE, RMSE, MAPE, erro m√°ximo)<br>‚Ä¢ An√°lise complementar (% previs√µes com erro > 20%)<br>‚Ä¢ Justificativa de escolha<br>‚Ä¢ Discuss√£o de trade-offs | ‚úÖ Planejado |
| **Validade de Constructo** | "Acur√°cia" ‚â† "Utilidade Pr√°tica" | Baixa | Modelo mais preciso pode n√£o ser adotado | ‚Ä¢ Coleta de tempo de execu√ß√£o, complexidade<br>‚Ä¢ Discuss√£o de trade-offs acur√°cia √ó velocidade √ó interpretabilidade<br>‚Ä¢ Recomenda√ß√µes contextualizadas<br>‚Ä¢ Valida√ß√£o futura com stakeholders | ‚ö†Ô∏è Parcial |
| **Validade Externa** | Especificidade do provedor (Google) | Alta | N√£o generaliza para AWS, Azure, outros | ‚Ä¢ Documenta√ß√£o expl√≠cita do contexto<br>‚Ä¢ Uso de precifica√ß√£o gen√©rica (m√∫ltiplos provedores)<br>‚Ä¢ Foco em compara√ß√£o relativa, n√£o absoluta<br>‚Ä¢ Recomenda√ß√£o de replica√ß√£o com outros datasets | ‚ö†Ô∏è Limita√ß√£o Aceita |
| **Validade Externa** | Per√≠odo temporal espec√≠fico (maio 2019) | M√©dia | Padr√µes sazonais anuais n√£o capturados | ‚Ä¢ Sele√ß√£o de per√≠odo t√≠pico (verificar eventos at√≠picos)<br>‚Ä¢ An√°lise de m√∫ltiplas janelas se tempo permitir<br>‚Ä¢ Foco em padr√µes di√°rios/semanais (mais est√°veis)<br>‚Ä¢ Transpar√™ncia na discuss√£o | ‚ö†Ô∏è Limita√ß√£o Aceita |
| **Validade Externa** | Escala (hyperscaler vs. PMEs) | Alta | N√£o se aplica a startups/PMEs | ‚Ä¢ Delimita√ß√£o: aplic√°vel a m√©dia-alta escala<br>‚Ä¢ An√°lise de subconjuntos (jobs menores) opcional<br>‚Ä¢ Discuss√£o de transferibilidade<br>‚Ä¢ Recomenda√ß√£o de calibra√ß√£o para PMEs | ‚ö†Ô∏è Limita√ß√£o Aceita |
| **Validade Externa** | Tipo de workload espec√≠fico | M√©dia | N√£o generaliza para ML training, serverless, IoT, OLTP | ‚Ä¢ Caracteriza√ß√£o detalhada dos workloads do dataset<br>‚Ä¢ Delimita√ß√£o de aplicabilidade (processamento distribu√≠do)<br>‚Ä¢ Sele√ß√£o de subset heterog√™neo<br>‚Ä¢ Recomenda√ß√£o de valida√ß√£o com outros datasets | ‚ö†Ô∏è Limita√ß√£o Aceita |

**Legenda de Status:**
- ‚úÖ **Planejado:** Estrat√©gia de mitiga√ß√£o implementada/planejada no experimento
- ‚ö†Ô∏è **Limita√ß√£o Aceita:** Amea√ßa reconhecida mas n√£o totalmente mitig√°vel; ser√° explicitada na discuss√£o
- ‚ö†Ô∏è **Parcial:** Mitiga√ß√£o parcial implementada; limita√ß√£o residual reconhecida

---

#### Prioriza√ß√£o de Amea√ßas (Top 5 Cr√≠ticas)

Com base em **severidade** e **impacto potencial**, as 5 amea√ßas mais cr√≠ticas s√£o:

1. **M√∫ltiplas Compara√ß√µes (Validade de Conclus√£o)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Tukey's HSD post-hoc com corre√ß√£o autom√°tica
   - **Crit√©rio de Sucesso:** Reportar p-valores ajustados para todas as compara√ß√µes

2. **Overfitting Diferenciado (Validade Interna)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Valida√ß√£o cruzada k-fold obrigat√≥ria + monitoramento M12
   - **Crit√©rio de Sucesso:** Diferen√ßa treino/teste < 15% para todos os modelos

3. **Qualidade dos Dados - Custos Estimados (Validade Interna)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Modelo de precifica√ß√£o validado + inclus√£o de ru√≠do
   - **Crit√©rio de Sucesso:** Correla√ß√µes m√©trica-custo plaus√≠veis (0.6-0.9)

4. **Especificidade do Provedor Google (Validade Externa)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Uso de precifica√ß√£o gen√©rica + documenta√ß√£o expl√≠cita de limita√ß√µes
   - **Crit√©rio de Sucesso:** Discuss√£o transparente de contextos de aplicabilidade

5. **Escala Hyperscaler vs. PMEs (Validade Externa)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Delimita√ß√£o clara de contexto + recomenda√ß√£o de calibra√ß√£o
   - **Crit√©rio de Sucesso:** Se√ß√£o de discuss√£o com guidelines de transferibilidade

---

#### A√ß√µes de Monitoramento P√≥s-Experimento

**Checklist de Valida√ß√£o dos Resultados:**

- [ ] **Normalidade:** Shapiro-Wilk p-valor > 0.05 para todos os grupos?
- [ ] **Homocedasticidade:** Levene's test p-valor > 0.05?
- [ ] **Overfitting:** Diferen√ßa treino/teste < 15% para todos os modelos?
- [ ] **Outliers:** Outliers detectados investigados e documentados?
- [ ] **Randomiza√ß√£o:** An√°lise Erro ~ Ordem_Execu√ß√£o n√£o significativa (p > 0.05)?
- [ ] **Correla√ß√µes Plaus√≠veis:** 0.6 ‚â§ |r(m√©trica, custo)| ‚â§ 0.9?
- [ ] **Consist√™ncia de M√©tricas:** Rankings por MAE, RMSE e MAPE convergem?
- [ ] **Vers√µes de Software:** `pip freeze` documentado e consistente?
- [ ] **Reprodutibilidade:** Seeds salvos e experimento reproduz√≠vel?
- [ ] **Documenta√ß√£o de Limita√ß√µes:** Se√ß√£o de discuss√£o inclui todas as amea√ßas da Se√ß√£o 13.5?

**Se Problemas Forem Detectados:**
- **Viola√ß√£o de normalidade severa:** Usar Kruskal-Wallis + Dunn's test
- **Overfitting > 15%:** Analisar e reportar separadamente; considerar exclus√£o do modelo ou re-tuning
- **Ordem de execu√ß√£o significativa:** Incluir "ordem" como covari√°vel na an√°lise
- **Outliers inexplic√°veis:** Remover e re-executar; documentar justificativa

---

**Refer√™ncias :**

- Wohlin, C., Runeson, P., H√∂st, M., Ohlsson, M. C., Regnell, B., & Wessl√©n, A. (2012). *Experimentation in software engineering*. Springer Science & Business Media.
- Cook, T. D., & Campbell, D. T. (1979). *Quasi-experimentation: Design & analysis issues for field settings*. Houghton Mifflin.
- Shadish, W. R., Cook, T. D., & Campbell, D. T. (2002). *Experimental and quasi-experimental designs for generalized causal inference*. Houghton Mifflin.

---


