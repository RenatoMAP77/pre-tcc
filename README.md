# Plano de Experimento ‚Äì Previs√£o de Custos de Infraestrutura Cloud

## 1. Identifica√ß√£o B√°sica

### 1.1 T√≠tulo do Experimento
**Previs√£o de Custos de Infraestrutura Cloud Utilizando Modelos Baseados em M√©tricas Reais: Uma Compara√ß√£o entre Algoritmos Simples e T√©cnicas de S√©ries Temporais**

### 1.2 ID / C√≥digo
`TCC-PRED-CUSTO-2025-001`

### 1.3 Vers√£o do Documento e Hist√≥rico de Revis√£o

| Vers√£o | Data | Autor | Descri√ß√£o das Altera√ß√µes |
|--------|------|-------|--------------------------|
| v1.0 | 05/12/2025 | Renato Matos Alves Penna | Desenvolvimento do documento |
| v1.1 | 12/12/2025 | Renato Matos Alves Penna | Finaliza√ß√£o das 20 se√ß√µes |

### 1.4 Datas

- **Data de Cria√ß√£o:** 21/11/2025
- **√öltima Atualiza√ß√£o:** 12/12/2025

### 1.5 Autores

| Nome | √Årea | Contato |
|------|------|---------|
| Renato Matos Alves Penna | Computa√ß√£o / Engenharia de Software | renatomatosapbusiness@gmail.com |

### 1.6 Respons√°vel Principal (PI / Dono do Experimento)

**Orientador:** Danilo de Quadros Maia Filho  
**Respons√°vel pela Execu√ß√£o:** Renato Matos Alves Penna

### 1.7 Projeto / Produto / Iniciativa Relacionada

Este experimento est√° vinculado ao **Trabalho de Conclus√£o de Curso (TCC)** do curso de gradua√ß√£o, com foco em Engenharia de Software Experimental aplicada a Cloud Computing. O estudo visa contribuir tanto para o contexto acad√™mico quanto para aplica√ß√µes pr√°ticas em empresas e startups que buscam otimiza√ß√£o de custos em infraestrutura cloud.

---

## 2. Contexto e Problema

### 2.1 Descri√ß√£o do Problema / Oportunidade

A computa√ß√£o em nuvem tornou-se fundamental para organiza√ß√µes modernas, permitindo escalabilidade sob demanda e redu√ß√£o de custos de infraestrutura f√≠sica. Entretanto, a natureza din√¢mica e el√°stica dos recursos cloud apresenta um desafio cr√≠tico: **custos imprevis√≠veis e dif√≠ceis de estimar**.

#### Problema Central:
Organiza√ß√µes frequentemente enfrentam:
- **Gastos inesperados** devido a picos de uso n√£o antecipados
- **Dificuldade em prever or√ßamentos** mensais/trimestrais de infraestrutura
- **Falta de visibilidade** sobre quais m√©tricas de uso mais impactam os custos
- **Aus√™ncia de modelos preditivos** que auxiliem no planejamento financeiro

#### Oportunidade:
Criar modelos de previs√£o de custos baseados em m√©tricas reais de uso (CPU, mem√≥ria) pode:
- Permitir **planejamento financeiro mais preciso**
- Identificar **padr√µes de consumo** e oportunidades de otimiza√ß√£o
- Auxiliar **decis√µes t√©cnicas** com impacto financeiro quantific√°vel
- Prevenir **estouros de or√ßamento** atrav√©s de alertas antecipados

### 2.2 Contexto Organizacional e T√©cnico

#### Contexto Organizacional:
Este √© um **experimento acad√™mico** desenvolvido como Trabalho de Conclus√£o de Curso. Embora n√£o esteja vinculado a uma empresa espec√≠fica, o estudo foi projetado para ter **aplicabilidade pr√°tica** em contextos reais de:
- Startups e PMEs que utilizam infraestrutura cloud
- Times de DevOps respons√°veis por otimiza√ß√£o de custos
- Equipes de engenharia que precisam justificar decis√µes t√©cnicas financeiramente
- Departamentos financeiros que necessitam de previs√µes or√ßament√°rias confi√°veis

#### Contexto T√©cnico:
- **Ambiente:** An√°lise baseada em dados reais do Google Cluster Data 2019
- **Tecnologias:** Python 3.10+, bibliotecas de an√°lise de dados (Pandas, NumPy), machine learning (Scikit-learn, Statsmodels)
- **M√©tricas analisadas:** CPU e mem√≥ria RAM (dados reais); custos (estimados)
- **Modelos cloud:** Precifica√ß√£o estimada baseada em tabelas p√∫blicas de provedores (AWS, Azure, GCP)
- **Processo:** Metodologia experimental controlada com an√°lise estat√≠stica rigorosa

### 2.3 Trabalhos e Evid√™ncias Pr√©vias (Internos e Externos)

#### Evid√™ncias Externas (Literatura):
**Nota:** Esta se√ß√£o ser√° expandida na fase de revis√£o bibliogr√°fica, mas alguns temas relevantes incluem:
- Estudos sobre **time series forecasting** aplicados a custos de TI
- Papers sobre **cloud cost optimization** e FinOps
- Pesquisas comparando **modelos de previs√£o** (ARIMA, exponential smoothing, machine learning)
- Trabalhos sobre **m√©tricas de infraestrutura** como preditores de custos

#### Evid√™ncias Internas:
Este √© o primeiro experimento formal sobre o tema no contexto do TCC. Observa√ß√µes preliminares indicam que:
- Modelos de s√©ries temporais podem capturar padr√µes sazonais de uso
- M√©tricas de CPU e requisi√ß√µes apresentam correla√ß√£o forte com custos
- A granularidade dos dados (di√°ria vs. hor√°ria) afeta a precis√£o das previs√µes

### 2.4 Referencial Te√≥rico e Emp√≠rico Essencial

Esta se√ß√£o apresenta a fundamenta√ß√£o te√≥rica e emp√≠rica que embasa o experimento, organizando conhecimento cient√≠fico consolidado sobre previs√£o de custos cloud, modelos de s√©ries temporais e metodologias de avalia√ß√£o.

---

#### 2.4.1 Previs√£o de Custos e Workloads em Nuvem

A **previs√£o de workloads em ambientes cloud** √© fundamental para otimiza√ß√£o de recursos e controle de custos. Calheiros et al. [1] demonstraram em trabalho seminal que modelos ARIMA aplicados a traces do Wikipedia alcan√ßaram **91% de acur√°cia na previs√£o de carga**, habilitando provisionamento proativo de recursos. Este trabalho estabeleceu que **s√©ries temporais estat√≠sticas podem capturar padr√µes de uso cloud com precis√£o suficiente para decis√µes operacionais**.

Amiri & Mohammad-Khanli [2] realizaram survey abrangente classificando m√©todos de previs√£o de workload em tr√™s categorias: (1) estat√≠sticos (ARIMA, Exponential Smoothing), (2) machine learning (SVM, Random Forest), e (3) h√≠bridos. Seu trabalho demonstra que **todos os quatro modelos deste experimento (RL, MM, ARIMA, ES) s√£o amplamente utilizados e validados na literatura**.

Tsoumakos et al. [3] questionaram se machine learning complexo √© necess√°rio para previs√£o de uso cloud, concluindo que **m√©todos simples como m√©dia m√≥vel e exponential smoothing alcan√ßam alta acur√°cia devido √† correla√ß√£o temporal forte** nos dados. Este achado fundamenta a inclus√£o de modelos mais simples (MM, RL) neste experimento como baselines competitivos.

**Previs√£o direta de custos cloud** foi investigada por Khandelwal et al. [4] usando 12 meses de pre√ßos spot da Amazon EC2 com Random Forests, enquanto Chhetri et al. [5] **compararam diretamente ARIMA, ETS (Exponential Smoothing), STL e TBATS** para previs√£o de pre√ßos EC2, encontrando que Seasonal Na√Øve foi robusto para mercados com sazonalidade forte. Fragiadakis et al. [6] aplicaram ML a dados hist√≥ricos AWS (2016-2022) para prever evolu√ß√£o de pre√ßos IaaS, demonstrando viabilidade de modelos preditivos em contextos reais.

---

#### 2.4.2 Modelos de S√©ries Temporais: Fundamentos Te√≥ricos

**ARIMA (AutoRegressive Integrated Moving Average):**
A metodologia Box-Jenkins [7], formalizada em 1970 e atualizada em 2015, estabeleceu o framework sistem√°tico para modelagem ARIMA: (1) identifica√ß√£o da ordem (p, d, q) via ACF/PACF, (2) estima√ß√£o de par√¢metros por m√°xima verossimilhan√ßa, (3) diagn√≥stico de res√≠duos. Hamilton [8] e Brockwell & Davis [9] fornecem tratamento matem√°tico rigoroso de processos ARMA, condi√ß√µes de estacionariedade e teoria de previs√£o √≥tima. **ARIMA √© considerado estado-da-arte para s√©ries univariadas com padr√µes lineares e sazonalidade moderada.**

**Exponential Smoothing:**
Holt [10] estendeu suaviza√ß√£o exponencial simples para capturar tend√™ncias lineares (m√©todo de Holt), enquanto Winters [11] adicionou componentes sazonais criando **Holt-Winters Triple Exponential Smoothing**. Gardner [12, 13] realizou revis√µes abrangentes estabelecendo boas pr√°ticas de implementa√ß√£o e introduzindo o framework **ETS (Error, Trend, Seasonal)** que unifica todos os m√©todos de suaviza√ß√£o em modelo de espa√ßo de estados coerente. Hyndman et al. [14] formalizaram ETS matematicamente, permitindo sele√ß√£o autom√°tica de modelos via AIC. **Exponential smoothing √© especialmente eficaz para dados com sazonalidade pronunciada e tend√™ncias n√£o-lineares.**

**M√©dia M√≥vel e Regress√£o Linear:**
M√©dia m√≥vel (Moving Average) √© t√©cnica de suaviza√ß√£o que calcula m√©dia dos √∫ltimos k valores, removendo ru√≠do de alta frequ√™ncia [15]. Regress√£o Linear modela rela√ß√£o entre vari√°veis preditoras (CPU, mem√≥ria) e vari√°vel resposta (custo) assumindo rela√ß√£o funcional linear [8, 15]. **Ambos servem como baselines interpret√°veis para compara√ß√£o.**

**M√©tricas de Avalia√ß√£o:**
Hyndman & Koehler [16] analisaram criticamente m√©tricas de acur√°cia de previs√£o, recomendando **MAE (Mean Absolute Error)** para interpretabilidade, **RMSE (Root Mean Squared Error)** para penalizar erros grandes, e **MASE (Mean Absolute Scaled Error)** como m√©trica independente de escala. Este trabalho fundamenta a escolha de MAE como m√©trica prim√°ria deste experimento.

**Sele√ß√£o de Modelos:**
Akaike [17] introduziu AIC (Akaike Information Criterion) para sele√ß√£o de modelos balanceando ajuste e complexidade, enquanto Schwarz [18] prop√¥s BIC (Bayesian Information Criterion) com penalidade mais forte para complexidade. **AIC e BIC s√£o utilizados para sele√ß√£o autom√°tica de ordem ARIMA e tipo de modelo ETS.**

---

#### 2.4.3 Aplica√ß√µes em Google Cluster Data

**Caracteriza√ß√£o do Dataset:**
Tirmazi et al. [19] realizaram primeira an√°lise oficial comparando traces Google 2019 e 2011, cobrindo **8 clusters Borg em maio/2019 (2.4 TiB de dados)**. Achado cr√≠tico: **top 1% dos jobs consomem mais de 99% dos recursos**, indicando distribui√ß√£o altamente assim√©trica. Verma et al. [20] descreveram arquitetura do sistema Borg, incluindo estrat√©gias de aloca√ß√£o de recursos, task-packing e over-commitment que geram os dados analisados. Reiss et al. [21] analisaram trace 2011, descobrindo que **jobs de longa dura√ß√£o apresentam utiliza√ß√£o de recursos relativamente est√°vel**, validando que modelos preditivos podem alcan√ßar acur√°cia razo√°vel. **Wilkes [22] fornece documenta√ß√£o t√©cnica oficial do schema do trace 2019**, essencial para descri√ß√£o do dataset na Se√ß√£o 4.

**Modelos Preditivos em Google Traces:**
Janardhanan & Barrett [23] compararam LSTM e ARIMA usando **Google Cluster Data**, encontrando que LSTM alcan√ßou 17-23% de erro vs. 37-42% do ARIMA para cargas altamente vari√°veis. Shyam & Manvi [24] desenvolveram **modelo h√≠brido ARIMA-ANN** para previs√£o de CPU e mem√≥ria em traces Google, onde ARIMA captura padr√µes lineares e ANN modela res√≠duos n√£o-lineares, avaliando com RMSE, MAE e MAPE.

Bappy et al. [25] realizaram an√°lise profunda do **Google Cluster Data 2019** (mesma fonte deste experimento) investigando padr√µes de uso entre jobs com falha vs. finalizados, fornecendo insights sobre desperd√≠cio de recursos. Alibasa et al. [26] usaram **trace v3 (2019)** para prever dura√ß√£o, CPU e mem√≥ria com GRU/LSTM. Van Loo et al. [27] aplicaram K-means e Lasso em trace 2019, usando Random Forest e XGBoost para previs√£o de demanda.

Hosseinzadeh et al. [28] propuseram pCNN-LSTM para previs√£o multi-step de CPU no Google Cluster Trace, alcan√ßando **15% de melhoria sobre LSTM baseline**. Asmawi et al. [29] compararam ML tradicional (Logistic Regression, Random Forest, XGBoost) e LSTM em traces Google 2011, identificando **prioridade do job como feature mais importante**.

---

#### 2.4.4 Estudos Comparativos de M√©todos de Previs√£o

**M-Competition Series (Benchmarks de Refer√™ncia):**
As competi√ß√µes M3 [30] e M4 [31] s√£o benchmarks gold-standard para m√©todos de previs√£o. **Makridakis & Hibon [30]** compararam 24 m√©todos em 3.003 s√©ries, concluindo: (1) **m√©todos sofisticados n√£o necessariamente superam simples**; (2) Exponential Smoothing teve desempenho consistente; (3) ARIMA melhorou em rela√ß√£o a competi√ß√µes anteriores. **Makridakis et al. [31]** na M4 (100.000 s√©ries, 61 m√©todos) encontraram que **m√©todos h√≠bridos estat√≠sticos-ML superaram abordagens puras em ~10%**, mas ETS e ARIMA permaneceram baselines fortes.

**Cr√≠tica Fundamental:**
Makridakis et al. [32] compararam m√©todos estat√≠sticos (ETS, ARIMA) com 8 algoritmos ML, demonstrando que **m√©todos estat√≠sticos tradicionais superaram ML em todas as m√©tricas de acur√°cia com custo computacional menor**. Este resultado fundamenta a escolha de m√©todos estat√≠sticos neste experimento.

**Compara√ß√µes Diretas:**
Wadi et al. [33] compararam ARIMA e Exponential Smoothing, concluindo que **ARIMA √© superior para previs√µes de longo prazo** enquanto **ES √© melhor para dados flutuantes de curto prazo**. Bahuguna et al. [34] encontraram que ARIMA(0,0,2) performou melhor em s√©ries curtas enquanto Holt-Winters foi superior em s√©ries longas com sazonalidade. Siami-Namini et al. [35] mostraram LSTM superando ARIMA com redu√ß√£o de 84-87% no erro, mas com custo computacional substancialmente maior.

**Contexto Cloud Espec√≠fico:**
Saxena et al. [36] realizaram primeiro survey sistem√°tico comparando ML para previs√£o de workload cloud em traces Google, Alibaba e Bitbrains, concluindo que **aprendizado h√≠brido com suaviza√ß√£o estat√≠stica superou deep learning puro**. ACM [37] testou 320+ modelos incluindo ARIMA, TBATS, Holt-Winters em traces Adobe, demonstrando que meta-learners alcan√ßaram 84-98% de melhoria, fornecendo framework de sele√ß√£o de modelos.

---

#### 2.4.5 Abordagens H√≠bridas e Estado da Arte

A literatura recente demonstra que **modelos h√≠bridos combinando ARIMA com redes neurais ou exponential smoothing frequentemente superam m√©todos individuais** [24, 31, 36]. Autores [38] combinaram ARIMA e triple exponential smoothing com pondera√ß√£o din√¢mica para previs√£o de carga de containers Docker. Kontopoulou et al. [39] realizaram revis√£o extensiva comparando ARIMA e ML, concluindo que **modelos h√≠bridos estat√≠sticos-AI consistentemente superam abordagens individuais**.

Deochake [40] prop√¥s arquitetura FinOps (ABACUS) para otimiza√ß√£o de custos cloud integrando ML para or√ßamenta√ß√£o preditiva, fornecendo contexto operacional para aplica√ß√£o pr√°tica de modelos de previs√£o.

---

#### 2.4.6 S√≠ntese da Base Emp√≠rica

A literatura consolidada suporta as seguintes premissas deste experimento:

1. **Viabilidade:** ARIMA, Exponential Smoothing, Moving Average e Linear Regression s√£o m√©todos validados para previs√£o de workload/custo cloud [1, 2, 3, 5].

2. **Dataset:** Google Cluster Data 2019 √© dataset p√∫blico robusto amplamente utilizado em pesquisas de previs√£o [19, 23, 24, 25, 26, 27, 28].

3. **M√©tricas:** MAE, RMSE e MAPE s√£o m√©tricas padronizadas para avalia√ß√£o de acur√°cia [16, 24, 30, 31].

4. **Expectativa:** M√©todos estat√≠sticos simples podem ser competitivos com ML complexo devido √† alta correla√ß√£o temporal em dados cloud [3, 32], mas modelos ARIMA e ES tendem a superar baselines simples [1, 30].

5. **Metodologia:** Desenho experimental CRD com valida√ß√£o cruzada TimeSeriesSplit e testes estat√≠sticos (ANOVA/Kruskal-Wallis) seguem boas pr√°ticas de experimenta√ß√£o [15, 41].

**Lacuna Identificada:**
Apesar da abund√¢ncia de estudos comparando ML sofisticado (LSTM, GRU, CNN) com ARIMA, **existem poucos estudos sistem√°ticos comparando os quatro modelos b√°sicos (RL, MM, ARIMA, ES) no contexto espec√≠fico de previs√£o de custos cloud usando Google Cluster Data 2019**. Este experimento preenche essa lacuna fornecendo compara√ß√£o controlada, rigorosa e reproduz√≠vel.

---

## 3. Objetivos e Quest√µes (Goal / Question / Metric)

### 3.1 Objetivo Geral (Goal Template)

**Analisar** modelos de previs√£o de custos cloud baseados em m√©tricas reais de uso  
**com o prop√≥sito de** comparar sua acur√°cia e identificar qual apresenta melhor desempenho  
**com respeito a** erro de previs√£o (MAE, RMSE, MAPE) e capacidade de generaliza√ß√£o  
**do ponto de vista de** engenheiros de software, times de DevOps e gestores financeiros  
**no contexto de** ambientes cloud com workloads simulados representando aplica√ß√µes reais.

### 3.2 Objetivos Espec√≠ficos

1. **O1 - Desenvolver modelos de previs√£o:** Construir e implementar pelo menos quatro modelos distintos de previs√£o de custos (regress√£o linear, m√©dia m√≥vel, ARIMA, exponential smoothing) utilizando m√©tricas reais de uso de infraestrutura.

2. **O2 - Avaliar acur√°cia dos modelos:** Medir e comparar a precis√£o de cada modelo utilizando m√©tricas padronizadas de erro (MAE, RMSE, MAPE) em janela temporal de 30 dias.

3. **O3 - Identificar vari√°veis preditoras:** Analisar quais m√©tricas de infraestrutura (CPU, mem√≥ria) apresentam maior correla√ß√£o com os custos estimados e maior poder preditivo.

4. **O4 - Validar generaliza√ß√£o:** Verificar se os modelos mant√™m precis√£o adequada em dados n√£o utilizados no treinamento (valida√ß√£o cruzada), garantindo capacidade de generaliza√ß√£o para per√≠odos futuros.

5. **O5 - Comparar estabilidade:** Avaliar a robustez dos modelos diante de diferentes padr√µes de uso (picos, sazonalidade, tend√™ncias) e determinar qual apresenta previs√µes mais est√°veis.

### 3.3 Quest√µes de Pesquisa / de Neg√≥cio

**M√©trica Prim√°ria:** MAE (Mean Absolute Error) - Principal crit√©rio de compara√ß√£o
**M√©tricas Secund√°rias:** RMSE e MAPE - An√°lises complementares

#### Relacionadas ao Objetivo O1 (Desenvolver modelos):
- **Q1.1 (PRIM√ÅRIA):** Qual modelo de previs√£o apresenta o menor erro m√©dio absoluto (MAE)?
- **Q1.2:** Como os modelos se comportam com janela temporal de 30 dias?
- **Q1.3:** Existe diferen√ßa estatisticamente significativa entre o desempenho dos modelos?

#### Relacionadas ao Objetivo O2 (Avaliar acur√°cia):
- **Q2.1 (SECUND√ÅRIA):** Qual modelo apresenta menor erro quadr√°tico m√©dio (RMSE)?
- **Q2.2 (SECUND√ÅRIA):** Qual modelo oferece o menor erro percentual (MAPE)?
- **Q2.3:** Os modelos mant√™m acur√°cia consistente ao longo das 30 repeti√ß√µes?

#### Relacionadas ao Objetivo O3 (Identificar vari√°veis):
- **Q3.1:** Quais m√©tricas de infraestrutura (CPU, mem√≥ria) apresentam maior correla√ß√£o com os custos totais?
- **Q3.2:** Como varia√ß√µes no consumo de mem√≥ria afetam o custo previsto?
- **Q3.3:** O consumo de CPU √© um preditor melhor que o uso de mem√≥ria para custos estimados?

#### Relacionadas ao Objetivo O4 (Validar generaliza√ß√£o):
- **Q4.1:** Os modelos generalizam bem para per√≠odos n√£o vistos durante o treinamento?
- **Q4.2:** Qual √© o erro m√©dio de valida√ß√£o cruzada de cada modelo?
- **Q4.3:** Existe degrada√ß√£o significativa de performance entre treino e teste?

#### Relacionadas ao Objetivo O5 (Comparar estabilidade):
- **Q5.1:** Qual modelo apresenta menor vari√¢ncia nos erros de previs√£o?
- **Q5.2:** Algum modelo apresenta sinais de overfitting (diferen√ßa treino/teste > 10%)?
- **Q5.3:** Os modelos de s√©ries temporais s√£o mais est√°veis que modelos simples?

### 3.4 M√©tricas Associadas (GQM)

#### Tabela GQM Completa

| Objetivo | Quest√£o | M√©tricas Associadas |
|----------|---------|---------------------|
| **O1: Desenvolver modelos** | Q1.1: Qual modelo apresenta menor MAE? | M1 (MAE) |
| | Q1.2: Como se comportam em diferentes janelas? | M1 (MAE), M2 (RMSE) |
| | Q1.3: H√° diferen√ßa estat√≠stica entre modelos? | M1 (MAE), M11 (p-valor ANOVA) |
| **O2: Avaliar acur√°cia** | Q2.1: Qual modelo apresenta menor RMSE? | M2 (RMSE) |
| | Q2.2: Qual modelo oferece menor MAPE? | M3 (MAPE) |
| | Q2.3: Erros diminuem com janelas maiores? | M1 (MAE), M2 (RMSE) por janela |
| **O3: Identificar vari√°veis** | Q3.1: Quais m√©tricas t√™m maior correla√ß√£o? | M4 (Correla√ß√£o %), M7-M10 |
| | Q3.2: Como requisi√ß√µes afetam custo? | M5 (Custo/requisi√ß√£o), M10 (Requisi√ß√µes) |
| | Q3.3: CPU vs. Mem√≥ria como preditor? | M4 (Correla√ß√£o), M7 (CPU), M8 (Mem√≥ria) |
| **O4: Validar generaliza√ß√£o** | Q4.1: Modelos generalizam para novos per√≠odos? | M6 (Erro valida√ß√£o cruzada) |
| | Q4.2: Qual erro m√©dio de valida√ß√£o cruzada? | M6 (Erro valida√ß√£o cruzada) |
| | Q4.3: H√° degrada√ß√£o entre treino/teste? | M12 (Diferen√ßa treino/teste) |
| **O5: Comparar estabilidade** | Q5.1: Qual modelo tem menor vari√¢ncia? | M13 (Desvio padr√£o dos erros) |
| | Q5.2: Algum modelo apresenta overfitting? | M12 (Diferen√ßa treino/teste) |
| | Q5.3: S√©ries temporais s√£o mais est√°veis? | M13 (Desvio padr√£o), M12 (Diferen√ßa treino/teste) |

#### Tabela Detalhada de M√©tricas

| ID | M√©trica | Descri√ß√£o Completa | Unidade | Fonte dos Dados |
|----|---------|-------------------|---------|-----------------|
| **M1** | MAE (Mean Absolute Error) | Erro absoluto m√©dio entre valores reais e previstos | Valor monet√°rio (R$) | C√°lculo p√≥s-previs√£o |
| **M2** | RMSE (Root Mean Square Error) | Raiz quadrada do erro quadr√°tico m√©dio | Valor monet√°rio (R$) | C√°lculo p√≥s-previs√£o |
| **M3** | MAPE (Mean Absolute Percentage Error) | Erro percentual absoluto m√©dio | Percentual (%) | C√°lculo p√≥s-previs√£o |
| **M4** | Correla√ß√£o com Custo | Correla√ß√£o de Pearson entre m√©trica e custo final | Coeficiente (-1 a 1) | An√°lise estat√≠stica |
| **M5** | Custo por Requisi√ß√£o | Custo m√©dio por requisi√ß√£o processada | R$ por requisi√ß√£o | Dataset de custos |
| **M6** | Erro de Valida√ß√£o Cruzada | Erro m√©dio em k-fold cross-validation (k=5) | Percentual (%) | Valida√ß√£o cruzada |
| **M7** | Consumo M√©dio de CPU | Utiliza√ß√£o percentual m√©dia de CPU | Percentual (%) | M√©tricas simuladas |
| **M8** | Consumo M√©dio de Mem√≥ria | Uso m√©dio de mem√≥ria RAM | Megabytes (MB) | M√©tricas simuladas |
| **M9** | Volume de Armazenamento | Quantidade total de storage utilizado | Gigabytes (GB) | M√©tricas simuladas |
| **M10** | Quantidade de Requisi√ß√µes | Volume de requisi√ß√µes por per√≠odo | Requisi√ß√µes/segundo | M√©tricas simuladas |
| **M11** | P-valor (ANOVA/Kruskal-Wallis) | Signific√¢ncia estat√≠stica da diferen√ßa entre modelos | Valor p | Teste estat√≠stico |
| **M12** | Diferen√ßa Treino/Teste | Diferen√ßa percentual de erro entre treino e teste | Percentual (%) | Compara√ß√£o de erros |
| **M13** | Desvio Padr√£o dos Erros | Variabilidade dos erros de previs√£o | Valor monet√°rio (R$) | An√°lise estat√≠stica |

---

## 4. Escopo e Contexto do Experimento

### 4.1 Escopo Funcional / de Processo (Inclu√≠do e Exclu√≠do)

#### üìä Clarifica√ß√£o: Origem e Natureza dos Dados

**IMPORTANTE:** Este experimento utiliza uma **combina√ß√£o de dados reais e estimados**:

1. **Dados REAIS (do Google Cluster Data 2019):**
   - **Consumo de CPU:** M√©tricas reais de utiliza√ß√£o de CPU de workloads de produ√ß√£o
   - **Consumo de mem√≥ria RAM:** M√©tricas reais de uso de mem√≥ria
   - **Timestamps:** Eventos temporais reais (granularidade original de 5 minutos)
   - **Job/Task events:** Informa√ß√µes reais de jobs executados

2. **Dados ESTIMADOS/CALCULADOS:**
   - **Custos monet√°rios:** Calculados aplicando tabelas p√∫blicas de precifica√ß√£o (AWS, Azure, GCP) √†s m√©tricas reais de uso
   - **Volume de armazenamento:** N√£o dispon√≠vel diretamente no Google Cluster Data; ser√° estimado baseado em CPU/mem√≥ria ou exclu√≠do do escopo
   - **Requisi√ß√µes/tr√°fego de rede:** N√£o dispon√≠vel diretamente no Google Cluster Data; ser√° estimado ou exclu√≠do do escopo

3. **Processamento dos Dados:**
   - **Agrega√ß√£o temporal:** Dados originais (5 minutos) s√£o agregados para granularidade hor√°ria (1 hora)
   - **Per√≠odo de an√°lise:** 30 dias cont√≠nuos extra√≠dos do dataset de maio de 2019
   - **Resultado final:** 720 observa√ß√µes (30 dias √ó 24 horas) por m√©trica

**Conclus√£o:** As m√©tricas de uso (CPU e mem√≥ria) s√£o **reais**; os custos s√£o **estimados** com base nessas m√©tricas reais. Storage e requisi√ß√µes podem ser **exclu√≠dos** ou **estimados** dependendo da disponibilidade.

---

#### ‚úÖ Inclu√≠do no Escopo:

**M√©tricas de Infraestrutura:**
- Consumo de CPU (percentual de utiliza√ß√£o) - **REAL**
- Consumo de mem√≥ria RAM (em MB) - **REAL**
- Custos monet√°rios (em R$) - **ESTIMADOS com base em CPU e mem√≥ria reais**

**Modelos de Previs√£o:**
- Regress√£o Linear
- M√©dia M√≥vel Simples
- ARIMA (AutoRegressive Integrated Moving Average)
- Exponential Smoothing (Suaviza√ß√£o Exponencial)

**Janelas Temporais de An√°lise:**
- **Janela principal:** Previs√µes baseadas em 30 dias (an√°lise principal)
- **Janelas explorat√≥rias (opcionais):** 7 e 14 dias (apenas se tempo permitir)

**M√©tricas de Avalia√ß√£o:**
- MAE, RMSE, MAPE
- Erro de valida√ß√£o cruzada (k=5)
- An√°lise de correla√ß√£o entre m√©tricas e custos
- Testes estat√≠sticos (ANOVA ou Kruskal-Wallis)

**An√°lises:**
- Compara√ß√£o estat√≠stica entre modelos
- Identifica√ß√£o de vari√°veis mais preditivas
- An√°lise de estabilidade e generaliza√ß√£o
- Detec√ß√£o de overfitting

#### ‚ùå Exclu√≠do do Escopo:

**Aspectos T√©cnicos:**
- Implementa√ß√£o em ambiente cloud real (ser√° simulado)
- Integra√ß√£o com APIs de provedores cloud
- Monitoramento em tempo real
- Sistemas de alertas autom√°ticos
- Deploy de modelos em produ√ß√£o

**M√©tricas Adicionais:**
- **Volume de armazenamento (storage)** - N√£o dispon√≠vel no Google Cluster Data 2019
- **Quantidade de requisi√ß√µes/tr√°fego de rede** - N√£o dispon√≠vel no Google Cluster Data 2019
- Custos de transfer√™ncia de dados entre regi√µes
- Custos de servi√ßos gerenciados (bancos de dados, cache)
- Custos de suporte t√©cnico ou SLAs
- M√©tricas de lat√™ncia ou disponibilidade

**Modelos Avan√ßados:**
- Redes neurais ou deep learning
- Modelos ensemble complexos
- Prophet (Facebook) ou t√©cnicas de boosting
- Modelos espec√≠ficos de provedores (AWS Forecast, etc.)

**Aspectos Organizacionais:**
- An√°lise de ROI ou business case
- Processos de governan√ßa financeira
- Pol√≠ticas de chargeback entre departamentos
- Compliance ou auditoria financeira

### 4.2 Contexto do Estudo (Tipo de Organiza√ß√£o, Projeto, Experi√™ncia)

#### Tipo de Organiza√ß√£o:
**Contexto Acad√™mico** - Trabalho de Conclus√£o de Curso  
Embora seja um estudo acad√™mico, foi projetado para ter **aplicabilidade pr√°tica** em:
- Startups de tecnologia
- Pequenas e m√©dias empresas (PMEs) com infraestrutura cloud
- Times de DevOps em organiza√ß√µes de qualquer porte

#### Tipo de Projeto:
- **Natureza:** Experimento controlado com an√°lise quantitativa
- **Dura√ß√£o:** 5 meses (planejamento e execu√ß√£o)
- **Complexidade:** M√©dia (4 modelos, 3 janelas temporais, m√∫ltiplas m√©tricas)

#### Perfil de Experi√™ncia:
- **Pesquisador:** Estudante de gradua√ß√£o com conhecimento intermedi√°rio em:
  - Engenharia de Software
  - An√°lise de dados e estat√≠stica
  - Cloud computing (conceitual)
  - Python e bibliotecas de machine learning

#### Criticidade:
- **Baixa criticidade operacional** (ambiente simulado)
- **Alta criticidade acad√™mica** (requisito de TCC)
- **Potencial impacto pr√°tico** m√©dio-alto para empresas que adotarem os resultados

### 4.3 Premissas

1. **Dados de Uso:**
   - √â poss√≠vel obter e processar dados reais de traces p√∫blicos de cloud computing
   - Os traces do Google Cluster Data 2019 s√£o representativos de workloads cloud reais
   - A granularidade dos dados (5 minutos para 1 hora ap√≥s agrega√ß√£o) √© suficiente para capturar padr√µes relevantes

2. **Per√≠odo Analisado:**
   - 30 dias de hist√≥rico do dataset s√£o suficientes para treinamento
   - O per√≠odo extra√≠do representa comportamento t√≠pico de sistemas cloud
   - N√£o h√° eventos extraordin√°rios no per√≠odo espec√≠fico selecionado que distor√ßam completamente os padr√µes

3. **C√°lculo de Custos:**
   - As tabelas de precifica√ß√£o dos provedores permanecem est√°veis durante o per√≠odo
   - √â poss√≠vel estimar custos baseando-se em tabelas p√∫blicas (AWS, Azure, GCP)
   - A convers√£o de m√©tricas de uso (CPU, mem√≥ria) em custo monet√°rio segue modelo linear simplificado

4. **Modelos de Previs√£o:**
   - Os modelos escolhidos s√£o representativos das abordagens mais comuns
   - As implementa√ß√µes das bibliotecas (Scikit-learn, Statsmodels) s√£o confi√°veis
   - Hiperpar√¢metros padr√£o s√£o adequados para uma primeira compara√ß√£o

5. **Recursos Computacionais:**
   - O hardware dispon√≠vel √© suficiente para processar o dataset e treinar os modelos em tempo h√°bil
   - Python 3.10+ e bibliotecas necess√°rias est√£o dispon√≠veis e funcionais
   - Dataset do Kaggle (sample) √© acess√≠vel e tem tamanho gerenci√°vel

6. **Conhecimento T√©cnico:**
   - O pesquisador possui conhecimento suficiente para implementar os modelos
   - H√° suporte do orientador para decis√µes metodol√≥gicas cr√≠ticas
   - Documenta√ß√£o do Google Cluster Data √© suficiente para interpretar os dados corretamente

### 4.4 Restri√ß√µes

1. **Temporais:**
   - Prazo de 5 meses para conclus√£o (incluindo documenta√ß√£o)
   - Necessidade de cumprir datas de entrega intermedi√°rias (entregas 1-4)

2. **Financeiras:**
   - Or√ßamento zero (uso de ferramentas gratuitas/open-source apenas)
   - Uso de datasets p√∫blicos gratuitos (Google Cluster Data via Kaggle ou BigQuery free tier)

3. **T√©cnicas:**
   - Limita√ß√£o a modelos implement√°veis com bibliotecas Python gratuitas
   - Depend√™ncia de dados de traces p√∫blicos (contexto espec√≠fico do Google)
   - Processamento local (sem clusters ou infraestrutura distribu√≠da)
   - Necessidade de agregar/processar dados brutos do trace

4. **Metodol√≥gicas:**
   - Desenho experimental com fator √∫nico (tipo de modelo)
   - Dataset fixo (per√≠odo espec√≠fico de maio 2019)
   - Foco em an√°lise quantitativa (sem entrevistas ou estudos de caso)

5. **Organizacionais:**
   - Projeto individual (sem equipe de desenvolvimento)
   - Depend√™ncia da disponibilidade do orientador para revis√µes

6. **Escopo:**
   - Limita√ß√£o a 4 modelos de previs√£o (quest√£o de viabilidade)
   - Apenas m√©tricas de CPU e mem√≥ria do dataset (storage/rede s√£o estimados ou ausentes)
   - Dataset espec√≠fico de um provedor (Google), n√£o multi-cloud

### 4.5 Limita√ß√µes Previstas

#### Limita√ß√µes de Validade Externa (Generaliza√ß√£o):

1. **Contexto Espec√≠fico do Dataset:**
   - Dados provenientes exclusivamente de clusters Google (n√£o AWS, Azure, outros)
   - Workloads espec√≠ficos do Google (podem n√£o representar todas as empresas)
   - Per√≠odo espec√≠fico (maio 2019) pode n√£o capturar sazonalidades anuais
   - Diferentes provedores cloud t√™m caracter√≠sticas diferentes

2. **Precifica√ß√£o Estimada:**
   - Custos calculados com tabelas p√∫blicas, n√£o refletem custos reais Google
   - N√£o considera descontos corporativos, reserved instances ou savings plans
   - Modelo de precifica√ß√£o simplificado (linear) pode n√£o capturar complexidades reais

3. **Escala e Complexidade:**
   - Dataset de larga escala pode ter caracter√≠sticas diferentes de PMEs
   - M√∫ltiplos servi√ßos e interdepend√™ncias do Google n√£o s√£o replic√°veis em empresas menores
   - Padr√µes de uso de um hyperscaler podem n√£o se aplicar a todos os contextos

#### Limita√ß√µes de Validade Interna:

1. **Vari√°veis de Confus√£o:**
   - Poss√≠vel correla√ß√£o esp√∫ria entre m√©tricas devido √† simula√ß√£o
   - Dificuldade em isolar completamente o efeito de cada vari√°vel

2. **Vieses de Implementa√ß√£o:**
   - Escolha de hiperpar√¢metros pode favorecer alguns modelos
   - Qualidade da implementa√ß√£o pode variar entre modelos

#### Limita√ß√µes de Validade de Constructo:

1. **Medi√ß√£o de Custos:**
   - Custos simulados podem n√£o refletir descontos, reserved instances ou savings plans
   - Varia√ß√µes de pre√ßo por regi√£o n√£o s√£o consideradas

2. **Complexidade Reduzida:**
   - M√©tricas de infraestrutura s√£o simplifica√ß√£o da realidade
   - Fatores humanos e organizacionais n√£o s√£o capturados

#### Limita√ß√µes Pr√°ticas:

1. **Recursos Limitados:**
   - Tempo e capacidade computacional limitam a complexidade dos modelos
   - Impossibilidade de testar todos os modelos e configura√ß√µes poss√≠veis

2. **Experi√™ncia:**
   - Primeira experi√™ncia formal com experimenta√ß√£o controlada
   - Curva de aprendizado pode afetar qualidade inicial

**Estrat√©gias de Mitiga√ß√£o:** Estas limita√ß√µes ser√£o reconhecidas explicitamente nos resultados e discuss√£o do trabalho, com recomenda√ß√µes claras sobre contextos onde os resultados s√£o mais ou menos aplic√°veis.

---

## 5. Stakeholders e Impacto Esperado

### 5.1 Stakeholders Principais

| Stakeholder | Papel | Interesse no Experimento |
|-------------|-------|--------------------------|
| **Empresas e Startups** | Tomadores de decis√£o financeira | Modelos que ajudem a prever e controlar custos cloud |
| **Times DevOps** | Operadores de infraestrutura | Ferramentas para planejamento de escalabilidade e otimiza√ß√£o de recursos |
| **Desenvolvedores** | Criadores de aplica√ß√µes | Entendimento do impacto financeiro de decis√µes t√©cnicas (arquitetura, padr√µes de uso) |
| **Times Financeiros** | Gestores de or√ßamento | Previs√µes mais confi√°veis para planejamento or√ßament√°rio |
| **Gestores de TI** | Lideran√ßa t√©cnica | Dados para justificar investimentos e decis√µes estrat√©gicas |
| **Orientador Acad√™mico** | Supervisor do TCC | Qualidade metodol√≥gica e rigor cient√≠fico do experimento |
| **Comunidade Acad√™mica** | Pesquisadores | Contribui√ß√£o para √°rea de Engenharia de Software Experimental e FinOps |

### 5.2 Interesses e Expectativas dos Stakeholders

#### Empresas e Startups:
- **Expectativa:** Identificar modelo de previs√£o aplic√°vel na pr√°tica
- **Interesse:** Reduzir gastos inesperados em at√© 15-30%
- **Utilidade:** Implementar alertas preditivos de estouro de or√ßamento
- **Benef√≠cio:** ROI positivo atrav√©s de melhor planejamento financeiro

#### Times DevOps:
- **Expectativa:** Compreender quais m√©tricas monitorar prioritariamente
- **Interesse:** Correla√ß√£o clara entre m√©tricas t√©cnicas e impacto financeiro
- **Utilidade:** Dados para dimensionar infraestrutura preventivamente
- **Benef√≠cio:** Redu√ß√£o de incidentes relacionados a recursos (out of memory, throttling)

#### Desenvolvedores:
- **Expectativa:** Entender como decis√µes de c√≥digo/arquitetura afetam custos
- **Interesse:** Modelos que relacionem padr√µes de uso com custos espec√≠ficos
- **Utilidade:** Guidelines para desenvolvimento cost-aware
- **Benef√≠cio:** C√≥digo mais eficiente e econ√¥mico

#### Times Financeiros:
- **Expectativa:** Previs√µes confi√°veis para or√ßamentos trimestrais/anuais
- **Interesse:** Erro de previs√£o < 20%
- **Utilidade:** Justificativas quantitativas para aloca√ß√£o de recursos
- **Benef√≠cio:** Redu√ß√£o de ajustes or√ßament√°rios emergenciais

#### Gestores de TI:
- **Expectativa:** Evid√™ncias para tomada de decis√£o estrat√©gica
- **Interesse:** Compara√ß√£o objetiva entre diferentes abordagens preditivas
- **Utilidade:** Business case para investimento em ferramentas de FinOps
- **Benef√≠cio:** Melhor governan√ßa de custos cloud

#### Orientador e Comunidade Acad√™mica:
- **Expectativa:** Experimento metodologicamente rigoroso
- **Interesse:** Contribui√ß√£o cient√≠fica para √°rea de Engenharia de Software Experimental
- **Utilidade:** Refer√™ncia para futuros trabalhos em FinOps e previs√£o de custos
- **Benef√≠cio:** Avan√ßo do conhecimento na interse√ß√£o de ES e cloud computing

### 5.3 Impactos Potenciais no Processo / Produto

#### Durante a Execu√ß√£o do Experimento:

**Impactos Positivos:**
- **Aprendizado:** Ganho de conhecimento em t√©cnicas de s√©ries temporais e an√°lise preditiva
- **Metodologia:** Experi√™ncia pr√°tica com experimenta√ß√£o controlada
- **Documenta√ß√£o:** Cria√ß√£o de material de refer√™ncia sobre previs√£o de custos cloud

**Impactos Neutros:**
- **Tempo:** Dedica√ß√£o de ~5 meses ao experimento (esperado para TCC)
- **Recursos:** Uso de recursos computacionais locais (sem custo adicional)

**Impactos Negativos (Mitigados):**
- **Risco m√≠nimo:** Por ser simula√ß√£o, n√£o h√° risco de impactar sistemas em produ√ß√£o
- **Escopo limitado:** Foco em dados sint√©ticos pode gerar expectativas n√£o atendidas

#### P√≥s-Experimento:

**Impacto Acad√™mico:**
- Contribui√ß√£o para corpus de conhecimento em FinOps
- Poss√≠vel publica√ß√£o em workshops ou confer√™ncias de ES
- Refer√™ncia para trabalhos futuros sobre cloud cost optimization

**Impacto Pr√°tico:**
- Empresas podem implementar modelos testados
- Redu√ß√£o de desperd√≠cio financeiro em infraestrutura cloud
- Melhoria em processos de planejamento e governan√ßa

**Impacto no Produto/Processo:**
- **Curto prazo:** N√£o h√° produto direto, mas documenta√ß√£o e c√≥digo reutiliz√°veis
- **M√©dio prazo:** Potencial de evolu√ß√£o para ferramenta de previs√£o
- **Longo prazo:** Base para sistema de FinOps completo (alertas, dashboards, recomenda√ß√µes)

---

## 6. Riscos de Alto N√≠vel, Premissas e Crit√©rios de Sucesso

### 6.1 Riscos de Alto N√≠vel (Neg√≥cio, T√©cnicos, etc.)

#### Riscos de Neg√≥cio:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Resultados n√£o aplic√°veis na pr√°tica** | M√©dia | Alto | Usar dataset real (Google Cluster Data); validar com literatura |
| **Baixo interesse de stakeholders** | Baixa | M√©dio | Demonstrar aplicabilidade atrav√©s de casos de uso concretos |
| **Expectativas n√£o atendidas** | M√©dia | M√©dio | Comunicar claramente escopo e limita√ß√µes desde o in√≠cio |

#### Riscos T√©cnicos:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Dados reais com problemas de qualidade** | M√©dia | Alto | Pr√©-valida√ß√£o rigorosa; tratamento de outliers e valores faltantes |
| **Modelos com baixo poder preditivo** | M√©dia | Alto | Testar m√∫ltiplos modelos; ajustar hiperpar√¢metros se necess√°rio |
| **Problemas de implementa√ß√£o** | Baixa | M√©dio | Usar bibliotecas consolidadas (Scikit-learn, Statsmodels) |
| **Hardware insuficiente para processar dataset** | M√©dia | M√©dio | Usar sample do Kaggle (gerenci√°vel) ao inv√©s do dataset completo |
| **Bugs ou erros de c√≥digo** | M√©dia | M√©dio | Testes unit√°rios; revis√£o de c√≥digo; valida√ß√£o de resultados |

#### Riscos de Dados:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Dataset indispon√≠vel ou alterado** | Baixa | Alto | Fazer download e backup local; usar m√∫ltiplas fontes (Kaggle + BigQuery) |
| **Inconsist√™ncia no per√≠odo analisado** | Baixa | M√©dio | Valida√ß√£o de qualidade dos dados extra√≠dos; an√°lise explorat√≥ria |
| **Falta de variabilidade nos dados** | Baixa | M√©dio | Google Cluster Data tem alta variabilidade natural de workloads reais |

#### Riscos Metodol√≥gicos:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Vi√©s na compara√ß√£o de modelos** | M√©dia | Alto | Usar mesma m√©trica de avalia√ß√£o e mesmo dataset para todos |
| **Overfitting n√£o detectado** | M√©dia | Alto | Valida√ß√£o cruzada rigorosa; an√°lise de diferen√ßa treino/teste |
| **Falta de signific√¢ncia estat√≠stica** | M√©dia | Alto | Garantir tamanho de amostra adequado (30 execu√ß√µes por modelo) |

#### Riscos de Cronograma:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Atrasos na implementa√ß√£o** | M√©dia | Alto | Buffer de tempo no cronograma; entregas incrementais |
| **Complexidade subestimada** | M√©dia | M√©dio | Revis√£o peri√≥dica do progresso com orientador |
| **Problemas pessoais/sa√∫de** | Baixa | Alto | Adiantar entregas quando poss√≠vel; comunica√ß√£o transparente |

#### Riscos Externos:

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| **Mudan√ßas em precifica√ß√£o de provedores** | Baixa | Baixo | Usar tabelas de pre√ßo fixas do momento inicial |
| **Indisponibilidade do orientador** | Baixa | M√©dio | Agendar reuni√µes com anteced√™ncia; documentar decis√µes |

### 6.2 Crit√©rios de Sucesso Globais (Go / No-Go)

#### Crit√©rios M√≠nimos de Sucesso (Must-Have):

‚úÖ **Crit√©rio 1: Modelos Funcionais**
- **Meta:** Implementar com sucesso pelo menos 3 dos 4 modelos propostos
- **Medida:** C√≥digo execut√°vel que gera previs√µes
- **Limiar:** 100% dos modelos rodando sem erros cr√≠ticos

‚úÖ **Crit√©rio 2: Avalia√ß√£o de Acur√°cia**
- **Meta:** Calcular MAE, RMSE e MAPE para todos os modelos
- **Medida:** M√©tricas de erro computadas e documentadas
- **Limiar:** Todas as m√©tricas calculadas para todos os modelos

‚úÖ **Crit√©rio 3: Compara√ß√£o Estat√≠stica**
- **Meta:** Realizar teste estat√≠stico comparando desempenho dos modelos
- **Medida:** ANOVA ou Kruskal-Wallis com p-valor calculado
- **Limiar:** Teste realizado com interpreta√ß√£o clara dos resultados

‚úÖ **Crit√©rio 4: Identifica√ß√£o de Melhor Modelo**
- **Meta:** Determinar qual modelo apresenta menor erro
- **Medida:** Ranking dos modelos por MAE
- **Limiar:** Conclus√£o clara sobre qual modelo √© superior

#### Crit√©rios Desej√°veis de Sucesso (Should-Have):

üéØ **Crit√©rio 5: Erro Aceit√°vel**
- **Meta:** Atingir erro m√©dio < 20% em ao menos um modelo
- **Medida:** MAPE do melhor modelo
- **Limiar:** MAPE < 20% (desej√°vel); < 30% (aceit√°vel)

üéØ **Crit√©rio 6: Identifica√ß√£o de Vari√°veis Preditoras**
- **Meta:** Determinar quais m√©tricas mais influenciam o custo
- **Medida:** Correla√ß√£o entre m√©tricas (CPU, mem√≥ria, etc.) e custo
- **Limiar:** Identificar pelo menos 2 m√©tricas com correla√ß√£o > 0.6

üéØ **Crit√©rio 7: Generaliza√ß√£o**
- **Meta:** Validar que modelos generalizam para dados n√£o vistos
- **Medida:** Diferen√ßa entre erro de treino e teste
- **Limiar:** Diferen√ßa < 15% (sem overfitting severo)

üéØ **Crit√©rio 8: Signific√¢ncia Estat√≠stica**
- **Meta:** Provar diferen√ßa significativa entre modelos
- **Medida:** p-valor do teste estat√≠stico
- **Limiar:** p < 0.05 (diferen√ßa significativa)

#### Crit√©rios Extras de Sucesso (Nice-to-Have):

‚≠ê **Crit√©rio 9: An√°lise de Estabilidade**
- **Meta:** Avaliar robustez dos modelos em diferentes cen√°rios
- **Medida:** Vari√¢ncia dos erros
- **Limiar:** Modelo mais est√°vel identificado

‚≠ê **Crit√©rio 10: Documenta√ß√£o Completa**
- **Meta:** Documentar todo o processo experimental
- **Medida:** Se√ß√µes do plano experimental preenchidas
- **Limiar:** 100% das se√ß√µes 1-12 completas

#### Crit√©rios de Qualidade Cient√≠fica:

üìä **Crit√©rio 11: Rigor Metodol√≥gico**
- Desenho experimental apropriado
- Vari√°veis de controle identificadas e mantidas constantes
- An√°lise estat√≠stica correta

üìä **Crit√©rio 12: Reprodutibilidade**
- C√≥digo documentado e versionado
- Instru√ß√µes claras para replica√ß√£o
- Dados sint√©ticos ger√°veis novamente

### 6.3 Crit√©rios de Parada Antecipada (Pr√©-Execu√ß√£o)

O experimento deve ser **adiado ou cancelado** se qualquer uma das seguintes condi√ß√µes ocorrer antes do in√≠cio da execu√ß√£o:

‚ùå **Parada Tipo 1 - Recursos Insuficientes:**
- Hardware dispon√≠vel n√£o consegue processar os modelos em tempo h√°bil
- Bibliotecas necess√°rias n√£o funcionam no ambiente dispon√≠vel
- **A√ß√£o:** Reduzir escopo (menos modelos ou janelas menores) ou buscar recursos alternativos

‚ùå **Parada Tipo 2 - Inviabilidade Metodol√≥gica:**
- Impossibilidade de gerar dados sint√©ticos real√≠sticos
- Modelos escolhidos s√£o inadequados para o problema ap√≥s revis√£o mais profunda
- **A√ß√£o:** Revisar desenho experimental com orientador

‚ùå **Parada Tipo 3 - Mudan√ßa de Escopo:**
- Orientador solicita mudan√ßa radical no tema do TCC
- Prazos acad√™micos s√£o alterados drasticamente
- **A√ß√£o:** Renegociar escopo ou prazos

‚ùå **Parada Tipo 4 - Problemas Pessoais:**
- Problemas de sa√∫de graves do pesquisador
- Impossibilidade de dedicar tempo m√≠nimo necess√°rio
- **A√ß√£o:** Solicitar extens√£o de prazo ou trancamento

‚ùå **Parada Tipo 5 - Riscos Identificados como Cr√≠ticos:**
- Ap√≥s revis√£o, identifica√ß√£o de risco n√£o mitig√°vel com alto impacto
- Feedback do orientador indicando inviabilidade fundamental
- **A√ß√£o:** Replanejamento completo ou mudan√ßa de tema

**Processo de Decis√£o:**
1. Identifica√ß√£o do problema que motiva a parada
2. Discuss√£o com orientador
3. Explora√ß√£o de alternativas de mitiga√ß√£o
4. Decis√£o formal (continuar, adiar ou cancelar)
5. Documenta√ß√£o da decis√£o

---

## 7. Modelo Conceitual e Hip√≥teses

### 7.1 Modelo Conceitual do Experimento

#### Modelo Conceitual Geral

O modelo conceitual deste experimento baseia-se na premissa de que **custos de infraestrutura cloud s√£o fun√ß√£o direta de m√©tricas de uso** e que **modelos matem√°ticos podem capturar padr√µes hist√≥ricos para prever custos futuros**.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    MODELO CONCEITUAL                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

        M√âTRICAS DE USO                    MODELO DE              CUSTO
       (Independentes)                     PREVIS√ÉO              PREVISTO
                                          (Tratamento)          (Dependente)
                                                
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                      
    ‚îÇ  CPU (%)        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                 
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ                                 
                           ‚îÇ                                 
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Mem√≥ria (MB)   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ Regress√£o    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ  Custo   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ         ‚îÇ Linear       ‚îÇ       ‚îÇ (R$)     ‚îÇ
                           ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ                ‚îÇ                     ‚îÇ
    ‚îÇ Storage (GB)    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                ‚îÇ                     ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
                           ‚îÇ         ‚îÇ M√©dia M√≥vel  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
    ‚îÇ Requisi√ß√µes     ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ                     ‚îÇ
    ‚îÇ (req/s)         ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ ARIMA        ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
                                            ‚îÇ                     ‚îÇ
         Padr√µes                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
         Hist√≥ricos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÇ Exponential  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         (s√©ries temporais)          ‚îÇ Smoothing    ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                            
                                            ‚îÇ
                                            ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ   AVALIA√á√ÉO  ‚îÇ
                                     ‚îÇ MAE, RMSE,   ‚îÇ
                                     ‚îÇ    MAPE      ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                            ‚îÇ
                                            ‚ñº
                                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                     ‚îÇ  COMPARA√á√ÉO  ‚îÇ
                                     ‚îÇ ESTAT√çSTICA  ‚îÇ
                                     ‚îÇ (ANOVA/K-W)  ‚îÇ
                                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Rela√ß√µes Causais Assumidas:

1. **M√©tricas ‚Üí Custo:**
   - Maior uso de CPU ‚Üí Maior custo de compute
   - Mais requisi√ß√µes ‚Üí Maior custo de rede e compute
   - Mais armazenamento ‚Üí Maior custo de storage
   - Mais mem√≥ria ‚Üí Maior custo de inst√¢ncias maiores

2. **Hist√≥rico ‚Üí Previs√£o:**
   - Padr√µes passados de uso permitem prever padr√µes futuros
   - Tend√™ncias e sazonalidade se repetem ao longo do tempo
   - Correla√ß√µes entre m√©tricas s√£o est√°veis

3. **Modelo ‚Üí Precis√£o:**
   - Diferentes modelos capturam diferentes aspectos dos dados
   - Modelos mais complexos (ARIMA) podem capturar padr√µes n√£o-lineares
   - Modelos simples (m√©dia m√≥vel) podem ser mais robustos a ru√≠do

#### Vari√°vel Moderadora:
- **Janela Temporal:** O tamanho da janela de observa√ß√£o (7, 14 ou 30 dias) pode moderar a rela√ß√£o entre modelo e precis√£o

#### Pressuposto Central:
**"O tipo de modelo de previs√£o utilizado influencia significativamente o erro de previs√£o de custos cloud, sendo poss√≠vel identificar um modelo superior para o contexto estudado."**

### 7.2 Hip√≥teses Formais (H0, H1)

#### Hip√≥tese Principal:

**H0 (Hip√≥tese Nula):**
> N√£o existe diferen√ßa estatisticamente significativa na precis√£o (medida por MAE, RMSE ou MAPE) entre os modelos de previs√£o analisados (Regress√£o Linear, M√©dia M√≥vel, ARIMA e Exponential Smoothing).

**Formalmente:** Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ = Œº‚ÇÑ

Onde:
- Œº‚ÇÅ = erro m√©dio da Regress√£o Linear
- Œº‚ÇÇ = erro m√©dio da M√©dia M√≥vel
- Œº‚ÇÉ = erro m√©dio do ARIMA
- Œº‚ÇÑ = erro m√©dio do Exponential Smoothing

**H1 (Hip√≥tese Alternativa):**
> Existe diferen√ßa estatisticamente significativa na precis√£o entre pelo menos dois dos modelos de previs√£o analisados.

**Formalmente:** ‚àÉ i,j ‚àà {1,2,3,4} tal que Œº·µ¢ ‚â† Œº‚±º

---

#### Hip√≥teses Espec√≠ficas (Sub-Hip√≥teses):

**H1.1 - Regress√£o Linear vs. S√©ries Temporais:**
- **H1.1.0 (Nula):** A regress√£o linear apresenta erro m√©dio igual aos modelos de s√©ries temporais (ARIMA e Exponential Smoothing)
- **H1.1.1 (Alternativa):** A regress√£o linear apresenta erro m√©dio diferente dos modelos de s√©ries temporais
- **Dire√ß√£o esperada:** Modelos de s√©ries temporais tendem a ter menor erro (capturam depend√™ncia temporal)

**H1.2 - ARIMA vs. Modelos Simples:**
- **H1.2.0 (Nula):** ARIMA apresenta erro m√©dio igual aos modelos simples (Regress√£o Linear e M√©dia M√≥vel)
- **H1.2.1 (Alternativa):** ARIMA apresenta erro m√©dio menor que modelos simples
- **Dire√ß√£o esperada:** ARIMA < (Regress√£o Linear, M√©dia M√≥vel)
- **Justificativa:** ARIMA captura autocorrela√ß√£o, tend√™ncia e sazonalidade

**H1.3 - Exponential Smoothing em Dados com Tend√™ncia:**
- **H1.3.0 (Nula):** Exponential Smoothing n√£o gera previs√µes mais est√°veis que outros modelos em dados com tend√™ncia
- **H1.3.1 (Alternativa):** Exponential Smoothing gera previs√µes mais est√°veis (menor vari√¢ncia de erro) em dados com tend√™ncia
- **Dire√ß√£o esperada:** œÉ¬≤(Exp.Smoothing) < œÉ¬≤(outros modelos)
- **Justificativa:** Suaviza√ß√£o exponencial d√° peso maior a observa√ß√µes recentes, reduzindo impacto de ru√≠do

**H1.4 - Efeito da Janela Temporal:**
- **H1.4.0 (Nula):** O tamanho da janela temporal (7, 14 ou 30 dias) n√£o afeta significativamente o erro de previs√£o
- **H1.4.1 (Alternativa):** Janelas temporais maiores resultam em menor erro de previs√£o
- **Dire√ß√£o esperada:** Erro(30 dias) < Erro(14 dias) < Erro(7 dias)
- **Justificativa:** Mais dados hist√≥ricos permitem melhor captura de padr√µes

**H1.5 - Correla√ß√£o M√©trica-Custo:**
- **H1.5.0 (Nula):** N√£o h√° diferen√ßa significativa na correla√ß√£o de diferentes m√©tricas (CPU, mem√≥ria, requisi√ß√µes, storage) com o custo final
- **H1.5.1 (Alternativa):** CPU e requisi√ß√µes apresentam correla√ß√£o significativamente maior com custo do que mem√≥ria e storage
- **Dire√ß√£o esperada:** Corr(CPU, Custo) > Corr(Mem√≥ria, Custo)

### 7.3 N√≠vel de Signific√¢ncia e Considera√ß√µes de Poder

#### N√≠vel de Signific√¢ncia:
**Œ± = 0.05 (5%)**

- Padr√£o amplamente aceito em ci√™ncias experimentais
- Representa 5% de chance de rejeitar H0 quando ela √© verdadeira (Erro Tipo I)
- Ser√° usado em todos os testes estat√≠sticos (ANOVA, Kruskal-Wallis, testes t)

**Interpreta√ß√£o:**
- Se p-valor < 0.05 ‚Üí Rejeitar H0 (diferen√ßa √© estatisticamente significativa)
- Se p-valor ‚â• 0.05 ‚Üí N√£o rejeitar H0 (n√£o h√° evid√™ncia suficiente de diferen√ßa)

#### Poder Estat√≠stico:

**Poder Desejado:** 1 - Œ≤ = 0.80 (80%)

- Representa 80% de chance de detectar uma diferen√ßa real quando ela existe
- Œ≤ = 0.20 (20% de chance de Erro Tipo II - n√£o detectar diferen√ßa que existe)

**C√°lculo de Tamanho de Amostra:**
Para alcan√ßar poder de 80% com Œ± = 0.05:
- **Repeti√ß√µes por modelo:** n = 30 execu√ß√µes
- **Total de observa√ß√µes:** 30 √ó 4 modelos = 120 observa√ß√µes
- **Justificativa:** Teorema do Limite Central garante distribui√ß√£o normal com n ‚â• 30

**Tamanho de Efeito Detect√°vel:**
Com n = 30 por grupo, √© poss√≠vel detectar:
- Diferen√ßa de efeito m√©dio (d de Cohen ‚âà 0.5)
- Diferen√ßa de ~15-20% no erro m√©dio entre modelos

**Considera√ß√µes:**

1. **Repetibilidade:**
   - Cada modelo ser√° executado 30 vezes com inicializa√ß√µes aleat√≥rias diferentes
   - Reduz impacto de variabilidade aleat√≥ria
   - Permite c√°lculo confi√°vel de intervalos de confian√ßa

2. **M√∫ltiplas Compara√ß√µes:**
   - Com 4 modelos, h√° 6 compara√ß√µes par-a-par poss√≠veis
   - Considerar corre√ß√£o de Bonferroni se necess√°rio: Œ±_ajustado = 0.05/6 = 0.0083
   - Usar post-hoc tests (Tukey HSD) ap√≥s ANOVA se H0 for rejeitada

3. **Valida√ß√£o Cruzada:**
   - K-fold com k = 5 aumenta o poder estat√≠stico
   - Cada modelo √© avaliado em 5 parti√ß√µes diferentes dos dados
   - Total efetivo de avalia√ß√µes: 30 execu√ß√µes √ó 5 folds = 150 avalia√ß√µes por modelo

4. **Sensibilidade:**
   - Se diferen√ßas forem sutis (< 10% de erro), poder pode ser insuficiente
   - Nesse caso, aumentar n para 50 ou considerar Œ± = 0.10 mais liberal

**Limita√ß√£o:**
Por usar dados sint√©ticos, o poder estat√≠stico √© suficiente para detectar diferen√ßas entre modelos, mas a validade externa (generaliza√ß√£o para dados reais) requer valida√ß√£o futura.

---

## 8. Vari√°veis, Fatores, Tratamentos e Objetos de Estudo

### 8.1 Objetos de Estudo

Os **objetos de estudo** s√£o as s√©ries temporais de m√©tricas de uso de infraestrutura cloud e os custos associados.

**Descri√ß√£o Detalhada:**

1. **S√©ries Temporais de M√©tricas:**
   - **CPU:** Percentual de utiliza√ß√£o ao longo do tempo
   - **Mem√≥ria:** Consumo em MB ao longo do tempo
   - **Armazenamento:** Volume em GB ao longo do tempo
   - **Requisi√ß√µes:** Taxa de requisi√ß√µes por segundo ao longo do tempo

2. **S√©rie Temporal de Custos:**
   - Custo calculado para cada per√≠odo de tempo (hora)
   - Baseado em tabelas de precifica√ß√£o de provedores cloud
   - Agrega√ß√£o das m√©tricas com pesos espec√≠ficos

**Caracter√≠sticas dos Objetos:**
- **Granularidade:** Hor√°ria (1 registro por hora)
- **Dura√ß√£o:** 30 dias (720 registros)
- **Tipo:** Dados sint√©ticos real√≠sticos
- **Formato:** S√©ries temporais univariadas e multivariadas

### 8.2 Sujeitos / Participantes (Vis√£o Geral)

**Importante:** Este experimento **n√£o envolve sujeitos humanos**. Os "sujeitos" s√£o as **execu√ß√µes dos modelos** sobre os dados.

**Caracteriza√ß√£o:**
- **Tipo:** Execu√ß√µes algor√≠tmicas (modelos de previs√£o)
- **Quantidade:** 30 execu√ß√µes √ó 4 modelos = 120 execu√ß√µes totais
- **Aleatoriza√ß√£o:** Cada execu√ß√£o usa seed aleat√≥ria diferente para:
  - Divis√£o treino/teste
  - Inicializa√ß√£o de par√¢metros (quando aplic√°vel)
  - Sele√ß√£o de folds na valida√ß√£o cruzada

**Equivalente a "Participantes" em Experimentos Tradicionais:**
- Cada execu√ß√£o de um modelo pode ser vista como um "participante"
- Diferentes execu√ß√µes capturam variabilidade natural do processo
- Permite an√°lise estat√≠stica robusta (m√©dia, desvio padr√£o, intervalos de confian√ßa)

### 8.3 Vari√°veis Independentes (Fatores) e seus N√≠veis

#### Fator Principal:

**F1: MODELO DE PREVIS√ÉO**

| N√≠vel | Descri√ß√£o | Sigla | Caracter√≠sticas |
|-------|-----------|-------|-----------------|
| **N√≠vel 1** | Regress√£o Linear | RL | Modelo simples, assume rela√ß√£o linear entre m√©tricas e custo |
| **N√≠vel 2** | M√©dia M√≥vel Simples | MM | M√©dia dos √∫ltimos N per√≠odos, sem considerar tend√™ncia |
| **N√≠vel 3** | ARIMA | ARIMA | Modelo de s√©ries temporais, captura autocorrela√ß√£o e tend√™ncia |
| **N√≠vel 4** | Exponential Smoothing | ES | Suaviza√ß√£o exponencial, d√° peso maior a observa√ß√µes recentes |

**Natureza do Fator:**
- **Tipo:** Categ√≥rico nominal
- **N√≠veis:** 4
- **Manipula√ß√£o:** Controlada experimentalmente (escolha do pesquisador)

#### Fator Secund√°rio (Explorat√≥rio - N√ÉO inclu√≠do na an√°lise principal):

**F2: JANELA TEMPORAL**

| N√≠vel | Descri√ß√£o | Uso |
|-------|-----------|-----|
| **N√≠vel 1** | 30 dias | **JANELA PRINCIPAL** - √önica janela analisada no experimento principal |
| **N√≠vel 2** | 7 dias | Explorat√≥rio (apenas se tempo permitir) |
| **N√≠vel 3** | 14 dias | Explorat√≥rio (apenas se tempo permitir) |

**Natureza do Fator:**
- **Tipo:** Categ√≥rico ordinal
- **N√≠veis:** 1 na an√°lise principal (30 dias); 3 se an√°lise explorat√≥ria for realizada
- **Manipula√ß√£o:** **N√ÉO SER√Å ANALISADO** como fator experimental
- **Justificativa:** Incluir 3 janelas temporais triplicaria o tempo de execu√ß√£o (de ~15h para ~45h), invi√°vel para o cronograma do TCC
- **Decis√£o:** Fixar janela em 30 dias (an√°lise principal); an√°lise explorat√≥ria com 7 e 14 dias fica como trabalho futuro

### 8.4 Tratamentos (Condi√ß√µes Experimentais)

Os **tratamentos** correspondem aos 4 modelos de previs√£o que ser√£o aplicados:

#### Tratamento T1: Regress√£o Linear (RL)

**Descri√ß√£o:**
Modelo que assume rela√ß√£o linear entre m√©tricas de uso (X) e custo (Y):

Y = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑CPU + Œ≤‚ÇÇ¬∑Mem√≥ria + Œ≤‚ÇÉ¬∑Storage + Œ≤‚ÇÑ¬∑Requisi√ß√µes + Œµ

**Caracter√≠sticas:**
- **Complexidade:** Baixa
- **Vantagens:** Simples, interpret√°vel, r√°pido
- **Desvantagens:** N√£o captura depend√™ncia temporal, assume linearidade
- **Implementa√ß√£o:** `sklearn.linear_model.LinearRegression`
- **Hiperpar√¢metros:** Nenhum (usa defaults)

#### Tratamento T2: M√©dia M√≥vel Simples (MM)

**Descri√ß√£o:**
Previs√£o baseada na m√©dia dos √∫ltimos N per√≠odos:

≈∂‚Çú‚Çä‚ÇÅ = (Y‚Çú + Y‚Çú‚Çã‚ÇÅ + ... + Y‚Çú‚Çã‚Çô‚Çä‚ÇÅ) / N

**Caracter√≠sticas:**
- **Complexidade:** Muito baixa
- **Vantagens:** Extremamente simples, n√£o requer treinamento
- **Desvantagens:** N√£o captura tend√™ncias, lag em mudan√ßas bruscas
- **Implementa√ß√£o:** Numpy / Pandas
- **Hiperpar√¢metros:** N = 7 per√≠odos (janela de 7 horas)

#### Tratamento T3: ARIMA

**Descri√ß√£o:**
Modelo AutoRegressive Integrated Moving Average - captura autocorrela√ß√£o, tend√™ncia e m√©dia m√≥vel:

ARIMA(p, d, q):
- p = ordem autoregressiva
- d = ordem de diferencia√ß√£o (estacionariedade)
- q = ordem de m√©dia m√≥vel

**Caracter√≠sticas:**
- **Complexidade:** Alta
- **Vantagens:** Captura depend√™ncia temporal, tend√™ncias, sazonalidade
- **Desvantagens:** Requer estacionariedade, pode ser lento, dif√≠cil de interpretar
- **Implementa√ß√£o:** `statsmodels.tsa.arima.model.ARIMA`
- **Hiperpar√¢metros - Grid Search:**
  - **p (ordem AR):** {0, 1, 2}
  - **d (diferencia√ß√£o):** {0, 1}
  - **q (ordem MA):** {0, 1, 2}
  - **M√©todo de sele√ß√£o:** AIC (Akaike Information Criterion)
  - **Total de combina√ß√µes:** 3 √ó 2 √ó 3 = 18 configura√ß√µes
  - **Crit√©rio de escolha:** Menor AIC entre as 18 configura√ß√µes

#### Tratamento T4: Exponential Smoothing (ES)

**Descri√ß√£o:**
Suaviza√ß√£o exponencial - d√° peso exponencialmente decrescente a observa√ß√µes mais antigas:

≈∂‚Çú‚Çä‚ÇÅ = Œ±¬∑Y‚Çú + (1-Œ±)¬∑≈∂‚Çú

Onde Œ± √© o par√¢metro de suaviza√ß√£o (0 < Œ± < 1)

**Caracter√≠sticas:**
- **Complexidade:** M√©dia
- **Vantagens:** Reage rapidamente a mudan√ßas, suaviza ru√≠do, simples de entender
- **Desvantagens:** N√£o captura sazonalidade complexa (vers√£o simples)
- **Implementa√ß√£o:** `statsmodels.tsa.holtwinters.ExponentialSmoothing`
- **Hiperpar√¢metros - Configura√ß√£o Espec√≠fica:**
  - **Modelo:** Holt-Winters (Triple Exponential Smoothing)
  - **Tend√™ncia (trend):** {'add', 'mul', None}
  - **Sazonalidade (seasonal):** {'add', None}
  - **Per√≠odo sazonal (seasonal_periods):** 24 (ciclo di√°rio de 24 horas)
  - **M√©todo de otimiza√ß√£o:** Least squares (padr√£o statsmodels)
  - **Suaviza√ß√£o (smoothing_level, smoothing_trend, smoothing_seasonal):** Otimizados automaticamente

### 8.5 Vari√°veis Dependentes (Respostas)

As **vari√°veis dependentes** s√£o as m√©tricas que medem a qualidade da previs√£o:

| ID | Vari√°vel | Descri√ß√£o | F√≥rmula | Unidade | Interpreta√ß√£o |
|----|----------|-----------|---------|---------|---------------|
| **VD1** | MAE | Mean Absolute Error | `Œ£|y·µ¢ - ≈∑·µ¢| / n` | R$ | Menor √© melhor; mesma escala do custo |
| **VD2** | RMSE | Root Mean Squared Error | `‚àö(Œ£(y·µ¢ - ≈∑·µ¢)¬≤ / n)` | R$ | Menor √© melhor; penaliza erros grandes |
| **VD3** | MAPE | Mean Absolute Percentage Error | `Œ£|(y·µ¢ - ≈∑·µ¢)/y·µ¢| / n √ó 100` | % | Menor √© melhor; erro relativo |
| **VD4** | Erro Valida√ß√£o | Erro em valida√ß√£o cruzada | M√©dia dos erros em k-folds | % | Mede generaliza√ß√£o |
| **VD5** | Vari√¢ncia Erro | Variabilidade do erro | `Var(erros)` | R$¬≤ | Menor √© melhor; mede estabilidade |
| **VD6** | R¬≤ | Coeficiente de Determina√ß√£o | `1 - (RSS/TSS)` | Adimensional | Maior √© melhor (0 a 1) |

**Vari√°vel Prim√°ria (Outcome Principal):**
- **MAE** ser√° usada como m√©trica prim√°ria para compara√ß√£o
- Raz√£o: Interpret√°vel, mesma escala do custo, robusta a outliers

**Vari√°veis Secund√°rias:**
- RMSE, MAPE: Complementam a an√°lise
- Erro Valida√ß√£o: Verifica generaliza√ß√£o
- Vari√¢ncia Erro: Avalia estabilidade

### 8.6 Vari√°veis de Controle / Bloqueio

Vari√°veis que **n√£o s√£o objeto de estudo** mas que podem afetar os resultados e, portanto, devem ser **mantidas constantes**:

| Vari√°vel de Controle | Como ser√° Controlada | Justificativa |
|----------------------|----------------------|---------------|
| **Dataset de Entrada** | Todos os modelos usar√£o exatamente os mesmos dados sint√©ticos | Garantir comparabilidade |
| **Per√≠odo de An√°lise** | Mesmos 30 dias para todos os modelos | Eliminar varia√ß√£o temporal |
| **Divis√£o Treino/Teste** | Mesma divis√£o 70%-30% para todos (com mesmo seed em cada execu√ß√£o) | Equidade na avalia√ß√£o |
| **M√©tricas de Entrada** | Mesmas 4 m√©tricas (CPU, mem√≥ria, storage, requisi√ß√µes) | Isonomia de informa√ß√£o |
| **Granularidade Temporal** | Granularidade hor√°ria para todos | Consist√™ncia temporal |
| **Ambiente Computacional** | Mesma m√°quina, mesmo Python, mesmas bibliotecas | Eliminar varia√ß√£o de hardware/software |
| **Pr√©-processamento** | Mesma normaliza√ß√£o/padroniza√ß√£o para todos os modelos | Igualdade de condi√ß√µes |
| **M√©trica de Avalia√ß√£o** | Mesmos c√°lculos de MAE, RMSE, MAPE para todos | Comparabilidade direta |
| **Ordem de Execu√ß√£o** | Ordem randomizada das execu√ß√µes | Evitar vi√©s temporal |
| **Tabela de Pre√ßos** | Mesma tabela de pre√ßos fixa | Eliminar mudan√ßas externas |

**Bloqueio:**
N√£o h√° necessidade de bloqueio formal pois:
- N√£o h√° sujeitos humanos (que poderiam ter caracter√≠sticas individuais)
- Todas as execu√ß√µes usam o mesmo ambiente computacional
- Aleatoriza√ß√£o da ordem de execu√ß√£o √© suficiente

### 8.7 Poss√≠veis Vari√°veis de Confus√£o Conhecidas

Vari√°veis que **podem distorcer os resultados** se n√£o forem adequadamente tratadas:

#### Confus√£o 1: Qualidade da Implementa√ß√£o

**Descri√ß√£o:** Modelos mais complexos podem ter implementa√ß√£o com mais bugs ou menos otimizada

**Mitiga√ß√£o:**
- Usar bibliotecas consolidadas (Scikit-learn, Statsmodels)
- Testar implementa√ß√µes com datasets conhecidos
- Validar resultados intermedi√°rios

**Monitoramento:**
- Revisar c√≥digo com orientador
- Comparar com exemplos da documenta√ß√£o oficial

---

#### Confus√£o 2: Hiperpar√¢metros N√£o-√ìtimos

**Descri√ß√£o:** Alguns modelos podem n√£o ter hiperpar√¢metros otimizados, favorecendo outros

**Mitiga√ß√£o:**
- Usar valores padr√£o das bibliotecas como baseline
- Para ARIMA, fazer grid search simples de par√¢metros (p,d,q)
- Documentar escolha de hiperpar√¢metros

**Monitoramento:**
- Se resultados forem inesperados, revisar hiperpar√¢metros
- An√°lise de sensibilidade (opcional)

---

#### Confus√£o 3: Overfitting Despercebido

**Descri√ß√£o:** Modelo pode ter bom desempenho no treino mas p√©ssimo no teste

**Mitiga√ß√£o:**
- Valida√ß√£o cruzada k-fold (k=5)
- Monitorar diferen√ßa entre erro de treino e teste
- Usar m√©trica de generaliza√ß√£o expl√≠cita

**Monitoramento:**
- Calcular M12 (Diferen√ßa treino/teste)
- Flagging se diferen√ßa > 15%

---

#### Confus√£o 4: Dados Sint√©ticos N√£o-Real√≠sticos

**Descri√ß√£o:** Simula√ß√£o pode favorecer artificialmente um tipo de modelo

**Mitiga√ß√£o:**
- Basear simula√ß√£o em papers e documenta√ß√£o
- Incluir ru√≠do, tend√™ncia e sazonalidade
- Validar padr√µes com especialistas (orientador)

**Monitoramento:**
- An√°lise explorat√≥ria dos dados sint√©ticos
- Compara√ß√£o com benchmarks da literatura

---

#### Confus√£o 5: Vari√¢ncia Aleat√≥ria

**Descri√ß√£o:** Resultados podem variar significativamente entre execu√ß√µes devido a aleatoriedade

**Mitiga√ß√£o:**
- Executar cada modelo 30 vezes
- Usar seeds aleat√≥rias diferentes
- Reportar m√©dia e intervalo de confian√ßa

**Monitoramento:**
- Calcular desvio padr√£o dos erros
- Verificar se intervalos de confian√ßa se sobrep√µem

---

#### Confus√£o 6: Ordem de Execu√ß√£o

**Descri√ß√£o:** Modelos executados primeiro podem ter condi√ß√µes diferentes (cache, temperatura CPU)

**Mitiga√ß√£o:**
- Randomizar ordem de execu√ß√£o dos modelos
- Limpar cache entre execu√ß√µes
- Medir tempo de execu√ß√£o para detectar anomalias

**Monitoramento:**
- An√°lise de vari√¢ncia por ordem de execu√ß√£o
- Verificar se h√° padr√µes sistem√°ticos

---

### Resumo das Vari√°veis (Tabela Consolidada)

| Vari√°vel | Tipo | Descri√ß√£o | Valores/N√≠veis | Papel no Experimento |
|----------|------|-----------|----------------|----------------------|
| **Modelo de Previs√£o** | Independente (Fator) | Algoritmo usado para prever custos | RL, MM, ARIMA, ES | Tratamento principal |
| **Janela Temporal** | Independente (Fator Secund√°rio) | Per√≠odo de hist√≥rico usado | 7, 14, 30 dias | An√°lise explorat√≥ria |
| **MAE** | Dependente (Resposta) | Erro absoluto m√©dio | Cont√≠nuo (R$) | Outcome prim√°rio |
| **RMSE** | Dependente (Resposta) | Raiz do erro quadr√°tico m√©dio | Cont√≠nuo (R$) | Outcome secund√°rio |
| **MAPE** | Dependente (Resposta) | Erro percentual m√©dio | Cont√≠nuo (%) | Outcome secund√°rio |
| **Erro Valida√ß√£o** | Dependente (Resposta) | Erro em valida√ß√£o cruzada | Cont√≠nuo (%) | Medida de generaliza√ß√£o |
| **Vari√¢ncia Erro** | Dependente (Resposta) | Estabilidade das previs√µes | Cont√≠nuo (R$¬≤) | Medida de robustez |
| **CPU M√©dia** | Controle | Utiliza√ß√£o m√©dia de CPU | Cont√≠nuo (%) | Mantida constante |
| **Mem√≥ria M√©dia** | Controle | Consumo m√©dio de RAM | Cont√≠nuo (MB) | Mantida constante |
| **Storage** | Controle | Volume de armazenamento | Cont√≠nuo (GB) | Mantida constante |
| **Requisi√ß√µes** | Controle | Taxa de requisi√ß√µes | Cont√≠nuo (req/s) | Mantida constante |
| **Dataset** | Controle | Dados usados para treino/teste | Mesmo para todos | Mantida constante |
| **Divis√£o Treino/Teste** | Controle | Propor√ß√£o 70%-30% | Fixa | Mantida constante |
| **Qualidade Implementa√ß√£o** | Confus√£o | Bugs ou otimiza√ß√£o de c√≥digo | Vari√°vel | Mitigada por bibliotecas |
| **Hiperpar√¢metros** | Confus√£o | Configura√ß√£o dos modelos | Vari√°vel | Documentada e justificada |

---
## 9. Desenho Experimental

### 9.1 Tipo de Desenho (Completamente Randomizado, Blocos, Fatorial, etc.)

**Tipo de Desenho:** **Completamente Aleatorizado (Completely Randomized Design - CRD)** com repeti√ß√µes

#### Justificativa:

1. **Adequa√ß√£o ao Problema:**
   - H√° **apenas um fator experimental** (tipo de modelo de previs√£o)
   - **Janela temporal √© FIXA em 30 dias** (n√£o √© fator experimental)
   - N√£o h√° necessidade de blocos (ambiente homog√™neo, dados reais do Google Cluster)
   - Todos os modelos s√£o aplicados aos mesmos dados, garantindo equidade

2. **Vantagens para Este Contexto:**
   - **Simplicidade:** F√°cil de implementar e analisar
   - **Flexibilidade:** Permite diferentes n√∫meros de repeti√ß√µes por tratamento se necess√°rio
   - **Poder Estat√≠stico:** Com 30 repeti√ß√µes, fornece poder adequado para detectar diferen√ßas

3. **Caracter√≠sticas do Desenho:**
   - **Aleatoriza√ß√£o completa:** Ordem de execu√ß√£o dos modelos √© randomizada
   - **Repeti√ß√µes:** 30 execu√ß√µes independentes de cada modelo
   - **Controle rigoroso:** Todas as vari√°veis de controle mantidas constantes
   - **Valida√ß√£o cruzada:** k-fold (k=5) adiciona robustez

#### Estrutura do Experimento:

```
Tratamentos:    T1 (RL)  |  T2 (MM)  |  T3 (ARIMA)  |  T4 (ES)
                   ‚Üì           ‚Üì            ‚Üì            ‚Üì
Repeti√ß√µes:     n=30        n=30         n=30         n=30
                   ‚Üì           ‚Üì            ‚Üì            ‚Üì
Medidas:        MAE         MAE          MAE          MAE
                RMSE        RMSE         RMSE         RMSE
                MAPE        MAPE         MAPE         MAPE
                   ‚Üì           ‚Üì            ‚Üì            ‚Üì
An√°lise:    ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ANOVA ou Kruskal-Wallis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí
                   ‚Üì
           Compara√ß√µes Post-Hoc (Tukey HSD)
```

#### Alternativa N√£o Selecionada:

**Desenho Fatorial (2 fatores):**
- Poderia incluir "Janela Temporal" (7, 14, 30 dias) como segundo fator
- Resultaria em 4 √ó 3 = 12 combina√ß√µes de tratamentos (36 c√©lulas experimentais)
- **N√£o selecionado porque:**
  - Triplicaria o tempo de execu√ß√£o (~15h ‚Üí ~45h)
  - Aumentaria complexidade sem adicionar valor proporcional ao objetivo principal
  - Cronograma do TCC invi√°vel para experimento dessa magnitude
- **Decis√£o Final:** Janela temporal fixa em 30 dias; an√°lise explorat√≥ria com 7 e 14 dias fica como **trabalho futuro**

### 9.2 Randomiza√ß√£o e Aloca√ß√£o

#### Estrat√©gia de Randomiza√ß√£o:

**O que ser√° randomizado:**

1. **Ordem de Execu√ß√£o dos Modelos:**
   - As 120 execu√ß√µes (30 √ó 4 modelos) ter√£o ordem completamente aleat√≥ria
   - Evita vi√©s de ordem temporal (aquecimento de CPU, cache, etc.)
   
2. **Seeds para Divis√£o Treino/Teste:**
   - Cada uma das 30 repeti√ß√µes usar√° um seed aleat√≥rio diferente
   - Garante que cada execu√ß√£o tenha divis√£o treino/teste ligeiramente diferente
   - Seeds ser√£o pr√©-gerados e documentados para reprodutibilidade

3. **Inicializa√ß√£o de Par√¢metros (quando aplic√°vel):**
   - ARIMA: diferentes pontos de partida para otimiza√ß√£o
   - Exponential Smoothing: diferentes inicializa√ß√µes
   - Valida√ß√£o cruzada: ordem dos folds randomizada

#### Procedimento de Randomiza√ß√£o:

```python
# Pseudoc√≥digo do processo de randomiza√ß√£o

import numpy as np
import random

# 1. Gerar seeds para 30 repeti√ß√µes
np.random.seed(42)  # seed mestre para reprodutibilidade
seeds = np.random.randint(1, 10000, size=30)

# 2. Criar lista de todas as execu√ß√µes
execucoes = []
for modelo in ['RL', 'MM', 'ARIMA', 'ES']:
    for i, seed in enumerate(seeds):
        execucoes.append({
            'modelo': modelo,
            'repeticao': i + 1,
            'seed': seed
        })

# 3. Randomizar ordem de execu√ß√£o
random.seed(42)
random.shuffle(execucoes)

# 4. Executar na ordem randomizada
for exec in execucoes:
    executar_modelo(exec['modelo'], exec['seed'])
```

#### Documenta√ß√£o da Randomiza√ß√£o:

- **Seeds utilizados:** Salvos em arquivo CSV para reprodutibilidade total
- **Ordem de execu√ß√£o:** Registrada em log com timestamp
- **Verifica√ß√£o:** Ap√≥s experimento, confirmar que randomiza√ß√£o foi mantida

#### Controle de Confundidores:

**Fatores controlados (N√ÉO randomizados):**
- Dataset de entrada (mesmo para todos)
- Propor√ß√£o treino/teste (70%-30% fixa)
- M√©tricas de avalia√ß√£o (mesmas para todos)
- Ambiente computacional (mesma m√°quina)

### 9.3 Balanceamento e Contrabalan√ßo

#### Balanceamento:

**Balanceamento Completo Garantido:**

1. **N√∫mero de Repeti√ß√µes:**
   - Todos os 4 modelos: exatamente 30 execu√ß√µes cada
   - Total: 120 execu√ß√µes balanceadas (30-30-30-30)
   - Sem desbalanceamento planejado ou acidental

2. **Dados de Entrada:**
   - Todos os modelos recebem exatamente os mesmos dados
   - Mesmas 720 observa√ß√µes (30 dias √ó 24 horas)
   - Mesmas 4 m√©tricas de entrada (CPU, mem√≥ria, storage, requisi√ß√µes)

3. **Condi√ß√µes de Avalia√ß√£o:**
   - Mesma divis√£o treino/teste em cada repeti√ß√£o
   - Mesmas m√©tricas de avalia√ß√£o (MAE, RMSE, MAPE)
   - Mesmo procedimento de valida√ß√£o cruzada

#### Contrabalan√ßo (Counterbalancing):

**Contrabalan√ßo de Ordem:**

Embora n√£o haja "efeitos de aprendizagem" como em experimentos com humanos, o contrabalan√ßo de ordem mitiga efeitos de execu√ß√£o sequencial:

1. **Efeitos Mitigados:**
   - Aquecimento de hardware (CPU, cache)
   - Varia√ß√µes de carga do sistema operacional
   - Degrada√ß√£o de performance ao longo do tempo

2. **Estrat√©gia:**
   - Ordem de execu√ß√£o completamente randomizada (ver se√ß√£o 9.2)
   - Cada modelo aparece aproximadamente igual n√∫mero de vezes em cada posi√ß√£o
   - Verifica√ß√£o post-hoc: an√°lise de vari√¢ncia por ordem de execu√ß√£o

3. **Procedimento de Limpeza:**
   - Clear de mem√≥ria entre execu√ß√µes
   - Restart do kernel Python a cada 30 execu√ß√µes (opcional)
   - Monitoramento de temperatura e uso de CPU

#### Verifica√ß√£o de Balanceamento:

**Checklist Pr√©-Execu√ß√£o:**
- [ ] Confirmar n=30 para cada modelo
- [ ] Verificar que dataset √© id√™ntico para todos
- [ ] Validar que ordem est√° randomizada
- [ ] Confirmar que seeds s√£o √∫nicos e documentados

**Checklist P√≥s-Execu√ß√£o:**
- [ ] Verificar que todas as 120 execu√ß√µes foram conclu√≠das
- [ ] Confirmar aus√™ncia de outliers devido a erros de execu√ß√£o
- [ ] Analisar se ordem de execu√ß√£o introduziu vi√©s sistem√°tico

### 9.4 N√∫mero de Grupos e Sess√µes

#### N√∫mero de Grupos:

**4 Grupos (Tratamentos):**
1. Grupo 1: Regress√£o Linear (RL) - n=30
2. Grupo 2: M√©dia M√≥vel (MM) - n=30
3. Grupo 3: ARIMA - n=30
4. Grupo 4: Exponential Smoothing (ES) - n=30

**Total de Unidades Experimentais:** 120 execu√ß√µes

#### N√∫mero de Sess√µes:

**Defini√ß√£o de "Sess√£o":**
Uma sess√£o corresponde a uma execu√ß√£o completa de um modelo, incluindo:
- Carregamento dos dados
- Divis√£o treino/teste
- Treinamento do modelo
- Gera√ß√£o de previs√µes
- C√°lculo de m√©tricas de erro
- Valida√ß√£o cruzada

**Estrutura de Sess√µes:**

1. **Por Repeti√ß√£o:**
   - Cada repeti√ß√£o (1 a 30) = 1 sess√£o por modelo
   - Total: 30 sess√µes √ó 4 modelos = 120 sess√µes

2. **Por Valida√ß√£o Cruzada:**
   - Cada sess√£o inclui k=5 folds
   - Portanto: 120 sess√µes √ó 5 folds = 600 avalia√ß√µes de fold
   - Isso aumenta robustez sem aumentar n√∫mero de sess√µes principais

3. **Janelas Temporais (An√°lise Explorat√≥ria):**
   - Opcionalmente, repetir experimento com janelas de 7, 14 e 30 dias
   - Se realizado: 120 sess√µes √ó 3 janelas = 360 sess√µes totais
   - **Decis√£o:** Priorizar janela de 30 dias (an√°lise principal); outras janelas se tempo permitir

#### Dura√ß√£o Estimada:

**Por Sess√£o (SEM valida√ß√£o cruzada):**
- Regress√£o Linear: ~5 segundos
- M√©dia M√≥vel: ~2 segundos
- ARIMA: ~30-60 segundos (mais lento, com grid search)
- Exponential Smoothing: ~10 segundos

**IMPORTANTE: Com Valida√ß√£o Cruzada (k=5 folds):**

Cada sess√£o inclui 5 folds de valida√ß√£o cruzada, multiplicando o tempo por aproximadamente 5x:

**Tempo por Sess√£o (COM k-fold, k=5):**
- Regress√£o Linear: ~5s √ó 5 folds = 25s por repeti√ß√£o
- M√©dia M√≥vel: ~2s √ó 5 folds = 10s por repeti√ß√£o
- ARIMA: ~45s √ó 5 folds = 225s (3.75 min) por repeti√ß√£o
  - **Nota:** ARIMA com grid search pode levar 4-5 minutos por fold em alguns casos
  - **Estimativa conservadora:** ~5 min √ó 5 folds = 25 min por repeti√ß√£o
- Exponential Smoothing: ~10s √ó 5 folds = 50s por repeti√ß√£o

**Total Estimado (30 repeti√ß√µes √ó 4 modelos COM valida√ß√£o cruzada):**
- RL: 30 √ó 25s = 750s = 12.5 min
- MM: 30 √ó 10s = 300s = 5 min
- ARIMA: 30 √ó 25 min = 750 min = **12.5 horas**
- ES: 30 √ó 50s = 1500s = 25 min

**Tempo Total Realista:** ~13-15 horas (considerando ARIMA como gargalo)

**Estrat√©gia de Mitiga√ß√£o:**
- Executar em etapas (ex: 10 repeti√ß√µes por vez)
- Executar durante a noite/per√≠odos livres
- Considerar usar `n_jobs=-1` para paraleliza√ß√£o quando dispon√≠vel
- Otimizar grid search do ARIMA (limitar p, d, q a ranges menores)

#### Justificativa do N√∫mero de Sess√µes:

**N = 30 por grupo:**
- Atende requisito do Teorema do Limite Central (n ‚â• 30)
- Fornece poder estat√≠stico de 80% para detectar diferen√ßas m√©dias (d ‚âà 0.5)
- Permite c√°lculo robusto de intervalos de confian√ßa
- √â padr√£o em estudos experimentais

**N√£o aumentar para n = 50:**
- Retornos marginais decrescentes em poder estat√≠stico
- Tempo de execu√ß√£o dobraria (especialmente ARIMA)
- N = 30 j√° √© suficiente para conclus√µes robustas

---

## 10. Popula√ß√£o, Sujeitos e Amostragem

### 10.1 Popula√ß√£o-Alvo

**Defini√ß√£o da Popula√ß√£o:**

A popula√ß√£o-alvo deste experimento s√£o **workloads (cargas de trabalho) reais de aplica√ß√µes cloud**, caracterizadas por:

#### Caracter√≠sticas da Popula√ß√£o:

1. **Tipo de Aplica√ß√£o:**
   - Jobs e tasks executados em clusters de produ√ß√£o
   - Servi√ßos de processamento distribu√≠do
   - Aplica√ß√µes com padr√µes de uso vari√°veis ao longo do tempo
   - Workloads heterog√™neos (batch, servi√ßos online, an√°lise de dados)

2. **Perfil de Uso:**
   - Consumo vari√°vel de CPU (workloads reais de produ√ß√£o)
   - Uso din√¢mico de mem√≥ria RAM
   - Padr√µes temporais naturais (sem simula√ß√£o)
   - Heterogeneidade de recursos e utiliza√ß√£o

3. **Contexto Organizacional:**
   - Clusters de produ√ß√£o de larga escala
   - Ambiente gerenciado por sistema de orquestra√ß√£o (Google Borg)
   - Dados representativos de infraestrutura cloud real
   - Workloads de m√∫ltiplos usu√°rios e aplica√ß√µes

4. **Padr√µes Temporais:**
   - Presen√ßa de tend√™ncias naturais
   - Sazonalidade real (di√°ria, semanal)
   - Picos de uso espont√¢neos
   - Variabilidade natural de cargas de trabalho

#### Escopo da Generaliza√ß√£o:

**Onde os resultados SE APLICAM:**
- Ambientes cloud com workloads similares aos traces analisados
- Clusters gerenciados por orquestradores (Kubernetes, Borg, etc.)
- Horizontes de previs√£o de curto-m√©dio prazo (dias/semanas)
- Infraestruturas com precifica√ß√£o baseada em uso de recursos

**Onde os resultados PODEM N√ÉO SE APLICAR:**
- Workloads completamente diferentes dos traces (ex: IoT edge computing)
- Contextos com padr√µes de uso extremamente irregulares
- Ambientes com descontos especiais ou reserved instances complexos
- Aplica√ß√µes com requisitos de recursos completamente est√°ticos

### 10.2 Crit√©rios de Inclus√£o de Sujeitos

**Importante:** Este experimento usa **dados reais de traces p√∫blicos de cloud computing**, portanto "sujeitos" s√£o s√©ries temporais extra√≠das de workloads reais.

#### Fontes de Dados Candidatas:

**Fonte Prim√°ria (Recomendada):**

**1. Google Cluster Data 2019 (ClusterData2019)**
- **Descri√ß√£o:** Traces de 8 clusters Google Borg durante maio de 2019
- **Tamanho:** 2.4 TiB comprimidos (vers√£o completa), samples menores dispon√≠veis no Kaggle
- **M√©tricas Dispon√≠veis:**
  - CPU usage (histogramas a cada 5 minutos)
  - Memory usage
  - Job e task events
  - Resource requests
  - Timestamps precisos
- **Acesso:** 
  - BigQuery: `https://github.com/google/cluster-data`
  - Kaggle (sample): `https://www.kaggle.com/datasets/derrickmwiti/google-2019-cluster-sample`
- **Licen√ßa:** CC-BY (uso acad√™mico permitido)
- **Vantagens:** Dados reais, amplamente usado academicamente, bem documentado

**Fontes Alternativas (Backup):**

**2. MIT Supercloud Dataset**
- **Descri√ß√£o:** Logs de sistema HPC com GPU
- **M√©tricas:** CPU, GPU, mem√≥ria, file system
- **Granularidade:** 60 segundos (CPU/GPU)
- **Acesso:** `https://arxiv.org/abs/2108.02037`

**3. Azure Public Dataset**
- **Descri√ß√£o:** Workloads de infer√™ncia LLM
- **Acesso:** `https://github.com/Azure/AzurePublicDataset`

**4. IEEE DataPort - Cloud Performance Metrics**
- **Descri√ß√£o:** ~8,000 pontos de m√©tricas de sistema stateless
- **M√©tricas:** CPU, mem√≥ria, rede, TPS, response time
- **Granularidade:** 5 segundos
- **Acesso:** Requer IEEE DataPort subscription (gratuito para membros IEEE)

#### Crit√©rios de Inclus√£o para S√©ries Temporais Extra√≠das:

1. **Completude Temporal:**
   - Per√≠odo cont√≠nuo de pelo menos 30 dias
   - Granularidade m√°xima: 5 minutos (para compatibilidade com modelos)
   - Sem lacunas temporais significativas (< 5% de dados faltantes aceit√°vel)

2. **M√©tricas Necess√°rias:**
   - **Obrigat√≥rias:** CPU usage, Memory usage
   - **Desej√°veis:** Storage, Network I/O, Request count
   - **Para c√°lculo de custo:** Qualquer combina√ß√£o de CPU + Memory permite estimativa de custo

3. **Representatividade:**
   - Jobs/tasks de diferentes usu√°rios (n√£o apenas um usu√°rio)
   - Workloads heterog√™neos (n√£o apenas um tipo de aplica√ß√£o)
   - Presen√ßa de variabilidade natural (n√£o workloads artificialmente constantes)

4. **Qualidade dos Dados:**
   - Dados num√©ricos v√°lidos (n√£o corrompidos)
   - Timestamps consistentes e ordenados
   - Valores dentro de ranges plaus√≠veis (CPU: 0-100%, Memory > 0)

5. **Volume de Dados:**
   - M√≠nimo: 30 dias √ó 24h √ó 12 (para granularidade de 5 min) = ~8,640 observa√ß√µes por m√©trica
   - Ideal: 60-90 dias para maior robustez

#### Estrat√©gia de Sele√ß√£o do Dataset:

**Op√ß√£o Preferencial: Google Cluster Data 2019 (Sample via Kaggle)**

**Justificativa:**
1. **Realismo:** Dados reais de produ√ß√£o Google
2. **Qualidade:** Bem documentado e validado
3. **Acessibilidade:** Sample no Kaggle √© facilmente baix√°vel (sem necessidade de BigQuery)
4. **Uso Acad√™mico:** Centenas de papers usaram esses dados
5. **M√©tricas:** CPU e mem√≥ria dispon√≠veis com timestamps
6. **Tamanho Gerenci√°vel:** Sample de ~100MB vs. 2.4TiB da vers√£o completa

**Extra√ß√£o Espec√≠fica:**
- Selecionar subset de jobs/tasks com pelo menos 30 dias de dados
- Agregar m√©tricas por per√≠odo (ex: 1 hora) para reduzir granularidade
- Extrair 30-90 dias cont√≠nuos de um ou mais clusters

### 10.3 Crit√©rios de Exclus√£o de Sujeitos

#### S√©ries Temporais Exclu√≠das:

1. **Dados Incompletos ou Corrompidos:**
   - S√©ries com > 5% de valores faltantes
   - Timestamps inconsistentes ou desordenados
   - Valores corrompidos (NaN, Inf, valores negativos para CPU/mem√≥ria)

2. **Dados N√£o-Representativos:**
   - Jobs/tasks com dura√ß√£o < 24 horas (muito curtos)
   - Workloads completamente est√°ticos (vari√¢ncia ~0)
   - Outliers extremos sem explica√ß√£o (CPU > 100%, mem√≥ria negativa)

3. **Dados de Baixa Qualidade:**
   - Granularidade inconsistente (timestamps irregulares)
   - Lacunas temporais longas (> 1 hora sem dados)
   - Jobs marcados como "failed" ou "killed" (dependendo da an√°lise)

4. **Dados Fora do Escopo:**
   - Workloads muito espec√≠ficos que n√£o representam uso t√≠pico
   - Jobs de teste/debug (identific√°veis por padr√µes)
   - Dados de warmup ou shutdown de sistemas

#### Procedimento de Exclus√£o:

**Pr√©-Valida√ß√£o (antes do experimento):**

```python
import pandas as pd
import numpy as np

# 1. Carregar dados do Google Cluster (sample Kaggle ou BigQuery)
df = pd.read_csv('google_cluster_sample.csv')

# 2. Verificar valores faltantes
missing_pct = df.isna().sum() / len(df) * 100
print(f"% de dados faltantes por coluna:\n{missing_pct}")
assert missing_pct.max() < 5, "Mais de 5% de dados faltantes!"

# 3. Validar ranges
assert (df['cpu_usage'] >= 0).all() and (df['cpu_usage'] <= 1).all(), "CPU fora do range!"
assert (df['memory_usage'] >= 0).all(), "Mem√≥ria negativa detectada!"

# 4. Detectar s√©ries constantes
variancia = df.groupby('job_id')[['cpu_usage', 'memory_usage']].std()
jobs_validos = variancia[(variancia > 0.01).all(axis=1)].index
df = df[df['job_id'].isin(jobs_validos)]

# 5. Remover outliers extremos (z-score > 5)
from scipy import stats
z_scores = np.abs(stats.zscore(df[['cpu_usage', 'memory_usage']]))
df = df[(z_scores < 5).all(axis=1)]

# 6. Verificar completude temporal
df['timestamp'] = pd.to_datetime(df['timestamp'])
df = df.sort_values('timestamp')
gap_max = df['timestamp'].diff().max()
assert gap_max < pd.Timedelta('1 hour'), f"Lacuna temporal detectada: {gap_max}"

print(f"Dataset final: {len(df)} observa√ß√µes v√°lidas")
```

**Decis√£o de Exclus√£o:**
- Se s√©rie falhar em qualquer crit√©rio cr√≠tico ‚Üí **excluir**
- Documentar raz√£o da exclus√£o no log do experimento
- Manter registro de quantas s√©ries foram exclu√≠das e por qu√™

### 10.4 N√∫mero de Repeti√ß√µes Experimentais (por Modelo)

#### N√∫mero de Repeti√ß√µes:

**N = 30 repeti√ß√µes experimentais por modelo**

- **Total de Unidades Experimentais:** 120 (30 √ó 4 modelos)
- **Total de Avalia√ß√µes (com k-fold):** 600 (120 √ó 5 folds)

#### Justificativa Estat√≠stica:

**1. Teorema do Limite Central:**
- N ‚â• 30 garante distribui√ß√£o aproximadamente normal dos erros m√©dios
- Permite uso de testes param√©tricos (ANOVA) com seguran√ßa

**2. Poder Estat√≠stico:**
Para Œ± = 0.05 e poder = 0.80, com 4 grupos:
- N = 30 por grupo detecta tamanho de efeito d ‚âà 0.5 (m√©dio)
- Equivalente a diferen√ßa de ~15-20% no erro m√©dio entre modelos

**3. C√°lculo Formal (ANOVA One-Way):**

```
Par√¢metros:
- k = 4 grupos
- Œ± = 0.05
- Poder (1-Œ≤) = 0.80
- Efeito esperado: f = 0.25 (m√©dio)

F√≥rmula simplificada:
n ‚âà 2 √ó (Z_Œ±/2 + Z_Œ≤)¬≤ / (ES)¬≤
n ‚âà 2 √ó (1.96 + 0.84)¬≤ / (0.5)¬≤
n ‚âà 2 √ó 7.84 / 0.25
n ‚âà 31.36 ‚âà 30
```

**4. Valida√ß√£o Cruzada:**
- k-fold (k=5) multiplica efetivamente o poder
- Cada modelo √© avaliado 150 vezes (30 execu√ß√µes √ó 5 folds)
- Reduz impacto de variabilidade amostral

**5. Variabilidade com Dados Reais:**
- Com dados reais, cada execu√ß√£o usar√° diferentes seeds para:
  - Divis√£o treino/teste aleat√≥ria
  - Sele√ß√£o de diferentes subsets do dataset (se necess√°rio)
  - Inicializa√ß√£o de modelos
- Isso captura variabilidade natural dos dados

#### Tamanho M√≠nimo vs. M√°ximo:

**M√≠nimo Aceit√°vel:** N = 20
- Ainda fornece poder razo√°vel (~70%)
- √ötil se restri√ß√µes de processamento forem cr√≠ticas

**M√°ximo Vi√°vel:** N = 50
- Aumenta poder para ~90%
- Retornos marginais decrescentes
- Tempo de execu√ß√£o aumenta 67%

**Escolha:** N = 30 (balan√ßo √≥timo entre poder e viabilidade)

### 10.5 M√©todo de Sele√ß√£o / Recrutamento

**M√©todo:** **Amostragem de Traces P√∫blicos Reais de Cloud Computing**

Como n√£o h√° sujeitos humanos, o "recrutamento" consiste na **obten√ß√£o e extra√ß√£o de dados reais de datasets p√∫blicos**.

#### Processo de Obten√ß√£o dos Dados:

**Etapa 1: Download do Dataset**

**Op√ß√£o A: Kaggle (Recomendado para TCC)**
```bash
# Instalar Kaggle CLI
pip install kaggle

# Configurar credenciais (ap√≥s criar conta Kaggle)
# Baixar API token em https://www.kaggle.com/settings

# Fazer download do sample do Google Cluster 2019
kaggle datasets download -d derrickmwiti/google-2019-cluster-sample

# Descompactar
unzip google-2019-cluster-sample.zip
```

**Op√ß√£o B: BigQuery (Se necess√°rio dataset completo)**
```python
# Requer conta Google Cloud (possui free tier)
from google.cloud import bigquery

client = bigquery.Client()

query = """
SELECT 
    time,
    collection_id,
    average_usage_cpus,
    average_usage_memory
FROM `google.com:google-cluster-data.clusterdata_2019_a.task_usage`
WHERE time BETWEEN 600000000 AND 2592000000000  # ~30 dias
LIMIT 1000000
"""

df = client.query(query).to_dataframe()
df.to_csv('google_cluster_sample.csv', index=False)
```

**Etapa 2: Extra√ß√£o e Pr√©-processamento**

```python
import pandas as pd
import numpy as np

# Carregar dados
df = pd.read_csv('google_cluster_sample.csv')

# Converter timestamps (Google Cluster usa microsegundos desde epoch)
df['timestamp'] = pd.to_datetime(df['time'], unit='us')

# Renomear colunas para padronizar
df = df.rename(columns={
    'average_usage_cpus': 'cpu_usage',
    'average_usage_memory': 'memory_usage'
})

# Agregar por intervalo de tempo (ex: 1 hora) para reduzir granularidade
df = df.set_index('timestamp')
df_hourly = df.resample('1H').mean()

# Selecionar per√≠odo cont√≠nuo de 30 dias
start_date = df_hourly.index.min()
end_date = start_date + pd.Timedelta(days=30)
df_30d = df_hourly[(df_hourly.index >= start_date) & (df_hourly.index < end_date)]

print(f"Dataset final: {len(df_30d)} observa√ß√µes hor√°rias (~{len(df_30d)/24:.1f} dias)")
```

**Etapa 3: C√°lculo de Custos Estimados**

```python
# Calcular custo baseado em precifica√ß√£o t√≠pica de provedores
# Exemplo: AWS EC2 pricing simplificado

# Premissas de precifica√ß√£o (valores aproximados em R$/hora)
CPU_COST_PER_CORE_HOUR = 0.15  # R$ por core por hora
MEMORY_COST_PER_GB_HOUR = 0.02  # R$ por GB por hora

# Google Cluster normaliza CPU e mem√≥ria (0-1)
# Assumir inst√¢ncias com 4 cores e 16GB RAM (t√≠pico)
CORES = 4
RAM_GB = 16

df_30d['cpu_cost'] = df_30d['cpu_usage'] * CORES * CPU_COST_PER_CORE_HOUR
df_30d['memory_cost'] = df_30d['memory_usage'] * RAM_GB * MEMORY_COST_PER_GB_HOUR
df_30d['total_cost'] = df_30d['cpu_cost'] + df_30d['memory_cost']

# Salvar dataset final processado
df_30d.to_csv('dataset_cloud_preprocessado.csv')
```

**Etapa 4: Valida√ß√£o de Qualidade**
- Aplicar crit√©rios de inclus√£o (se√ß√£o 10.2)
- Aplicar crit√©rios de exclus√£o (se√ß√£o 10.3)
- An√°lise explorat√≥ria visual (plots de s√©ries temporais)
- Verificar estat√≠sticas descritivas

**Etapa 5: Documenta√ß√£o**
- Documentar fonte original dos dados (Google Cluster Data 2019)
- Registrar par√¢metros de extra√ß√£o e agrega√ß√£o
- Salvar metadata: per√≠odo exato, n√∫mero de jobs/tasks inclu√≠dos
- Garantir reprodutibilidade (c√≥digo + documenta√ß√£o)

#### Representatividade e Validade Externa:

**Vantagens de Usar Dados Reais:**

1. **Autenticidade:**
   - Padr√µes reais de uso de infraestrutura cloud
   - Variabilidade natural (n√£o artificialmente gerada)
   - Anomalias e eventos reais inclu√≠dos

2. **Credibilidade Cient√≠fica:**
   - Dataset amplamente usado em pesquisas (centenas de cita√ß√µes)
   - Dados validados pelo Google
   - Resultados compar√°veis com literatura existente

3. **Aplicabilidade Pr√°tica:**
   - Conclus√µes mais generaliz√°veis para ambientes reais
   - Maior confian√ßa de stakeholders (empresas, DevOps)
   - Valida√ß√£o externa mais forte

**Limita√ß√µes Reconhecidas:**

1. **Contexto Espec√≠fico:**
   - Dados de clusters Google Borg (n√£o todos os provedores)
   - Workloads espec√≠ficos de Google (n√£o universalmente representativos)
   - Per√≠odo espec√≠fico (maio 2019)

2. **Precifica√ß√£o Estimada:**
   - Custos calculados com base em tabelas p√∫blicas (n√£o custos reais Google)
   - N√£o considera descontos, reserved instances, ou pre√ßos negociados
   - Simplifica√ß√£o de modelo de precifica√ß√£o

3. **Pr√©-processamento:**
   - Agrega√ß√£o temporal (de 5 min para 1 hora) pode perder alguns padr√µes
   - Sele√ß√£o de subset pode n√£o capturar toda heterogeneidade

**Mitiga√ß√£o:**
- Documentar claramente limita√ß√µes no trabalho final
- Usar m√∫ltiplos subsets do dataset (variabilidade)
- Comparar resultados com literatura que usou mesmos dados

### 10.6 Treinamento e Prepara√ß√£o dos Sujeitos

**N√£o Aplic√°vel:** Este experimento n√£o envolve sujeitos humanos.

**Prepara√ß√£o dos Dados Reais:**

#### Pr√©-processamento Completo:

**1. Limpeza:**
```python
# Verificar e tratar dados faltantes
df = df.interpolate(method='time', limit=2)  # Interpolar gaps pequenos
df = df.dropna()  # Remover NaNs restantes

# Validar consist√™ncia temporal
df = df.sort_index()
assert df.index.is_monotonic_increasing, "Timestamps fora de ordem!"

# Remover duplicatas de timestamp
df = df[~df.index.duplicated(keep='first')]
```

**2. Tratamento de Outliers:**
```python
# Detectar outliers usando IQR (mais robusto que z-score para dados reais)
def remove_outliers_iqr(df, column, multiplier=1.5):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - multiplier * IQR
    upper_bound = Q3 + multiplier * IQR
    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]

# Aplicar para CPU e mem√≥ria
df = remove_outliers_iqr(df, 'cpu_usage')
df = remove_outliers_iqr(df, 'memory_usage')
```

**3. Normaliza√ß√£o:**
```python
from sklearn.preprocessing import StandardScaler

# Salvar scaler para uso consistente em todas as execu√ß√µes
scaler = StandardScaler()
df[['cpu_usage_scaled', 'memory_usage_scaled']] = \
    scaler.fit_transform(df[['cpu_usage', 'memory_usage']])

# Salvar scaler para reprodutibilidade
import joblib
joblib.dump(scaler, 'scaler_cloud_data.pkl')
```

**4. Engenharia de Features:**
```python
# Features temporais
df['hour'] = df.index.hour
df['day_of_week'] = df.index.dayofweek
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

# Lags (valores passados)
for lag in [1, 2, 3, 6, 12, 24]:
    df[f'cpu_lag_{lag}h'] = df['cpu_usage'].shift(lag)
    df[f'memory_lag_{lag}h'] = df['memory_usage'].shift(lag)

# M√©dias m√≥veis
df['cpu_ma_24h'] = df['cpu_usage'].rolling(window=24, min_periods=1).mean()
df['memory_ma_24h'] = df['memory_usage'].rolling(window=24, min_periods=1).mean()

# Remover linhas com NaN criados pelos lags
df = df.dropna()
```

**5. Divis√£o Treino/Teste (Temporal):**
```python
# Importante: NUNCA fazer shuffle em s√©ries temporais!
train_size = int(len(df) * 0.7)

train_df = df.iloc[:train_size]
test_df = df.iloc[train_size:]

print(f"Treino: {len(train_df)} observa√ß√µes ({train_df.index.min()} a {train_df.index.max()})")
print(f"Teste: {len(test_df)} observa√ß√µes ({test_df.index.min()} a {test_df.index.max()})")

# Salvar splits
train_df.to_csv('data/train_dataset.csv')
test_df.to_csv('data/test_dataset.csv')
```

**6. Valida√ß√£o Cruzada Temporal (Time Series Split):**
```python
from sklearn.model_selection import TimeSeriesSplit

# 5-fold temporal (n√£o aleat√≥rio!)
tscv = TimeSeriesSplit(n_splits=5)

for fold, (train_idx, val_idx) in enumerate(tscv.split(train_df)):
    fold_train = train_df.iloc[train_idx]
    fold_val = train_df.iloc[val_idx]
    
    # Salvar cada fold
    fold_train.to_csv(f'data/fold_{fold}_train.csv')
    fold_val.to_csv(f'data/fold_{fold}_val.csv')
```
---
## 11. Instrumenta√ß√£o e Protocolo Operacional

### 11.1 Instrumentos de Coleta (Question√°rios, Logs, Planilhas, etc.)

#### Instrumentos Principais:

| Instrumento | Descri√ß√£o | Formato | Uso |
|------------|-----------|---------|-----|
| **Script de Gera√ß√£o de Dados** | Gera s√©ries temporais sint√©ticas | Python (.py) | Criar dataset experimental |
| **Script de Treinamento** | Treina os 4 modelos de previs√£o | Python (.py) | Executar tratamentos |
| **Script de Avalia√ß√£o** | Calcula MAE, RMSE, MAPE | Python (.py) | Coletar vari√°veis dependentes |
| **Arquivo de Resultados** | Armazena erros de cada execu√ß√£o | CSV (.csv) | Consolidar resultados |
| **Log de Execu√ß√£o** | Registra timestamp, ordem, erros | TXT/JSON (.log) | Auditoria e debug |
| **Notebook de An√°lise** | An√°lise estat√≠stica e visualiza√ß√µes | Jupyter (.ipynb) | An√°lise p√≥s-experimento |
| **Arquivo de Configura√ß√£o** | Par√¢metros dos modelos e experimento | YAML/JSON (.yaml) | Controle de configura√ß√£o |

#### Estrutura dos Instrumentos:

**1. Arquivo de Resultados (resultados.csv):**
```csv
execucao_id,modelo,repeticao,seed,mae,rmse,mape,tempo_exec,fold,mae_fold,timestamp
1,RL,1,4235,125.34,178.92,12.5,5.2,1,130.21,2024-12-02 10:15:23
1,RL,1,4235,125.34,178.92,12.5,5.2,2,118.45,2024-12-02 10:15:23
...
```

**2. Log de Execu√ß√£o (experimento.log):**
```
2024-12-02 10:15:20 - INFO - Iniciando experimento TCC-PRED-CUSTO-2024-001
2024-12-02 10:15:21 - INFO - Carregando dados sint√©ticos
2024-12-02 10:15:22 - INFO - Executando modelo RL, repeti√ß√£o 1, seed 4235
2024-12-02 10:15:23 - INFO - RL completado - MAE: 125.34
...
```

**3. Arquivo de Configura√ß√£o (config.yaml):**
```yaml
experimento:
  id: TCC-PRED-CUSTO-2024-001
  versao: 1.4
  repeticoes: 30
  k_folds: 5
  seed_mestre: 42

modelos:
  regressao_linear:
    biblioteca: sklearn.linear_model.LinearRegression
    parametros: {}
  
  media_movel:
    janela: 7
  
  arima:
    ordem: [1, 1, 1]  # (p, d, q) - ser√° otimizado via grid search
  
  exponential_smoothing:
    trend: add
    seasonal: add
    seasonal_periods: 24
```

### 11.2 Materiais de Suporte (Instru√ß√µes, Guias)

#### Materiais Criados:

1. **README.md do Projeto:**
   - Vis√£o geral do experimento
   - Instru√ß√µes de instala√ß√£o
   - Como reproduzir experimento

2. **HOWTO_RUN.md:**
   - Passo a passo detalhado de execu√ß√£o
   - Comandos a serem executados
   - Troubleshooting comum

3. **Guia de An√°lise:**
   - Como interpretar resultados
   - Checklist de valida√ß√£o
   - Testes estat√≠sticos a aplicar

4. **Documenta√ß√£o de C√≥digo:**
   - Docstrings em todas as fun√ß√µes
   - Coment√°rios inline explicativos
   - Type hints para clareza

#### Exemplo de Conte√∫do (HOWTO_RUN.md):

```markdown
# Como Executar o Experimento

## Pr√©-requisitos
- Python 3.10+
- Bibliotecas: pandas, numpy, scikit-learn, statsmodels, matplotlib

## Instala√ß√£o
```bash
pip install -r requirements.txt
```

## Execu√ß√£o

### Passo 1: Gerar Dados Sint√©ticos
```bash
python scripts/gerar_dados.py --dias 30 --seed 42
```

### Passo 2: Executar Experimento
```bash
python scripts/executar_experimento.py --config config.yaml
```

### Passo 3: Analisar Resultados
```bash
jupyter notebook analise/analise_resultados.ipynb
```

## Verifica√ß√£o
- Conferir arquivo `resultados.csv` (deve ter 600 linhas: 120 execu√ß√µes √ó 5 folds)
- Verificar log `experimento.log` (sem erros)
- Gerar plots de diagn√≥stico


### 11.3 Procedimento Experimental (Protocolo ‚Äì Vis√£o Passo a Passo)

#### Protocolo Operacional Detalhado:

---

**FASE 1: PREPARA√á√ÉO (Pr√©-Execu√ß√£o)**

**Passo 1.1 - Setup do Ambiente**
- Instalar Python 3.10+ e bibliotecas necess√°rias
- Clonar reposit√≥rio do experimento
- Verificar disponibilidade de hardware
- **Dura√ß√£o:** 30 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Ambiente funcional

**Passo 1.2 - Download e Prepara√ß√£o dos Dados Reais**
- Baixar Google Cluster Data 2019 (via Kaggle ou BigQuery)
- Executar script `preparar_dados.py` para:
  - Extrair m√©tricas de CPU e mem√≥ria
  - Agregar de 5 min para granularidade hor√°ria (1h)
  - Selecionar per√≠odo cont√≠nuo de 30 dias
  - Calcular custos estimados baseados em tabelas de precifica√ß√£o
- Validar qualidade dos dados conforme crit√©rios da se√ß√£o 10.2
- Salvar dataset em `data/dataset_cloud_processado.csv`
- **Dura√ß√£o:** 30 minutos (inclui download)
- **Respons√°vel:** Pesquisador
- **Output:** `dataset_cloud_processado.csv` (~720 linhas √ó 4 colunas: timestamp, cpu, memory, cost)

**Passo 1.3 - Valida√ß√£o do Dataset**
- An√°lise explorat√≥ria visual (plots de s√©ries temporais)
- Verifica√ß√£o de estat√≠sticas descritivas
- Confirma√ß√£o com orientador sobre realismo
- **Dura√ß√£o:** 30 minutos
- **Respons√°vel:** Pesquisador + Orientador
- **Output:** Dataset aprovado

**Passo 1.4 - Prepara√ß√£o dos Seeds para Reprodutibilidade**
- **Objetivo:** Garantir reprodutibilidade e capturar variabilidade entre repeti√ß√µes
- **M√©todo:**
  - Gerar 30 seeds aleat√≥rios usando seed mestre fixo: `np.random.seed(42)`
  - Seeds: `seeds = np.random.randint(0, 10000, size=30)`
- **Uso dos Seeds:**
  - Cada repeti√ß√£o `r` (de 1 a 30) usa `seed[r]`
  - **Todos os 4 modelos na repeti√ß√£o `r` usam o mesmo `seed[r]`**
  - Isso garante que todos os modelos recebem mesma divis√£o treino/teste em cada repeti√ß√£o
  - Varia√ß√£o entre repeti√ß√µes captura robustez dos modelos
- **Salvar em:** `config/seeds.txt`
- **Dura√ß√£o:** 5 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Lista de 30 seeds + documenta√ß√£o de uso

---

**FASE 2: EXECU√á√ÉO DO EXPERIMENTO**

**Passo 2.1 - Pr√©-processamento**
- Carregar dataset
- Aplicar normaliza√ß√£o (StandardScaler)
- Salvar objeto scaler para uso posterior
- **Dura√ß√£o:** 5 minutos
- **Respons√°vel:** Script autom√°tico
- **Output:** Dados normalizados

**Passo 2.2 - Loop Principal de Execu√ß√£o**

Para cada repeti√ß√£o r = 1 at√© 30:
  Para cada modelo m em [RL, MM, ARIMA, ES]:
    
    a) **Divis√£o Treino/Teste**
       - Usar seed[r] para reprodutibilidade
       - Treino: 70% (primeiros 504 registros)
       - Teste: 30% (√∫ltimos 216 registros)
    
    b) **Treinamento do Modelo**
       - Treinar modelo m nos dados de treino
       - Registrar tempo de treinamento
    
    c) **Gera√ß√£o de Previs√µes**
       - Gerar previs√µes para conjunto de teste
    
    d) **C√°lculo de M√©tricas (Holdout)**
       - Calcular MAE, RMSE, MAPE no conjunto de teste
    
    e) **Valida√ß√£o Cruzada TimeSeriesSplit**
       - **IMPORTANTE:** Usar TimeSeriesSplit (n√£o k-fold tradicional) para preservar ordem temporal
       - Aplicar 5-fold time series cross-validation nos dados de treino
       - TimeSeriesSplit garante que treino sempre precede teste (sem shuffle)
       - Calcular MAE em cada fold
       - Registrar m√©dia e desvio padr√£o
    
    f) **Registro de Resultados**
       - Salvar em `resultados.csv`:
         execucao_id, modelo, repeticao, seed, mae, rmse, mape, tempo_exec
       - Salvar m√©tricas de cada fold
    
    g) **Logging**
       - Registrar em `experimento.log`:
         timestamp, modelo, status, m√©tricas principais

**Dura√ß√£o Total:** ~45-60 minutos
**Respons√°vel:** Script autom√°tico (`executar_experimento.py`)
**Output:** `resultados.csv` com 120 linhas (1 por execu√ß√£o)

**Passo 2.3 - Verifica√ß√£o de Integridade**
- Conferir se 120 execu√ß√µes foram completadas
- Verificar aus√™ncia de erros no log
- Validar que n√£o h√° valores faltantes em `resultados.csv`
- **Dura√ß√£o:** 10 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Confirma√ß√£o de experimento completo

---

**FASE 3: AN√ÅLISE DOS RESULTADOS**

**Passo 3.1 - Estat√≠stica Descritiva**
- Calcular m√©dia, mediana, desvio padr√£o de MAE, RMSE, MAPE por modelo
- Gerar tabelas de resumo
- **Dura√ß√£o:** 15 minutos
- **Respons√°vel:** Notebook Jupyter
- **Output:** Tabelas descritivas

**Passo 3.2 - Visualiza√ß√µes**
- Boxplots de MAE por modelo
- Gr√°ficos de s√©ries previstas vs. reais
- Heatmap de correla√ß√£o entre m√©tricas e custo
- **Dura√ß√£o:** 30 minutos
- **Respons√°vel:** Notebook Jupyter
- **Output:** Figuras para relat√≥rio

**Passo 3.3 - Teste de Normalidade**
- Shapiro-Wilk test nos res√≠duos de cada modelo
- Decis√£o: ANOVA (se normal) ou Kruskal-Wallis (se n√£o-normal)
- **Dura√ß√£o:** 10 minutos
- **Respons√°vel:** Script Python
- **Output:** p-valor de normalidade

**Passo 3.4 - Teste de Hip√≥teses**
- Aplicar ANOVA ou Kruskal-Wallis (H0: Œº1 = Œº2 = Œº3 = Œº4)
- Se p < 0.05: aplicar post-hoc tests (Tukey HSD)
- Identificar quais pares de modelos diferem significativamente
- **Dura√ß√£o:** 15 minutos
- **Respons√°vel:** Script Python
- **Output:** p-valor, conclus√£o sobre H0

**Passo 3.5 - An√°lise de Correla√ß√£o**
- Calcular correla√ß√£o de Pearson entre cada m√©trica (CPU, mem√≥ria, etc.) e custo
- Identificar vari√°veis mais preditivas
- **Dura√ß√£o:** 10 minutos
- **Respons√°vel:** Script Python
- **Output:** Matriz de correla√ß√£o

**Passo 3.6 - Verifica√ß√£o de Crit√©rios de Sucesso**
- Verificar se erro < 20% em pelo menos um modelo
- Confirmar diferen√ßa estat√≠stica significativa (se houver)
- Documentar cumprimento dos crit√©rios da se√ß√£o 6.2
- **Dura√ß√£o:** 15 minutos
- **Respons√°vel:** Pesquisador
- **Output:** Checklist de crit√©rios atendidos

---

**FASE 4: DOCUMENTA√á√ÉO**

**Passo 4.1 - Compila√ß√£o dos Resultados**
- Consolidar tabelas, gr√°ficos e conclus√µes
- Preencher se√ß√µes do documento de TCC
- **Dura√ß√£o:** 2-3 horas
- **Respons√°vel:** Pesquisador
- **Output:** Se√ß√µes de resultados e discuss√£o

**Passo 4.2 - Revis√£o com Orientador**
- Apresentar resultados ao orientador
- Incorporar feedback
- **Dura√ß√£o:** 1 hora (reuni√£o)
- **Respons√°vel:** Pesquisador + Orientador
- **Output:** Resultados validados

**Passo 4.3 - Empacotamento para Reprodu√ß√£o**
- Organizar c√≥digo, dados, resultados em reposit√≥rio
- Escrever README final
- Testar reprodu√ß√£o em ambiente limpo
- **Dura√ß√£o:** 2 horas
- **Respons√°vel:** Pesquisador
- **Output:** Reposit√≥rio reproduz√≠vel

---

### Fluxograma Operacional

```mermaid
flowchart TD
    A[Definir escopo das m√©tricas] --> B[Baixar e processar Google Cluster Data 2019]
    B --> C[Agregar dados 5min‚Üí1h e calcular custos estimados]
    C --> D{Dados cont√™m valores ausentes ou outliers?}
    D -->|Sim| E[Tratamento de dados: imputa√ß√£o ou remo√ß√£o]
    D -->|N√£o| F[Normaliza√ß√£o dos dados]
    E --> F
    F --> G[Constru√ß√£o do dataset final]
    G --> H[Divis√£o treino/valida√ß√£o - 70%/30%]
    H --> I[Aplica√ß√£o dos modelos de previs√£o]
    I --> J[Coleta das m√©tricas MAE, RMSE, MAPE]
    J --> K{Res√≠duos passaram no teste de normalidade?}
    K -->|Sim| L[Aplica√ß√£o de ANOVA]
    K -->|N√£o| M[Aplica√ß√£o de Kruskal-Wallis]
    L --> N{p-valor < 0.05?}
    M --> N
    N -->|Sim| O[Modelos apresentam diferen√ßa significativa]
    N -->|N√£o| P[Modelos n√£o diferem significativamente]
    O --> Q[Compara√ß√£o e sele√ß√£o do melhor modelo]
    P --> Q
    Q --> R{Erro < 20% em pelo menos um modelo?}
    R -->|Sim| S[Crit√©rio de sucesso atendido]
    R -->|N√£o| T[Revisar hiperpar√¢metros ou adicionar features]
    T --> I
    S --> U[Registro e interpreta√ß√£o dos resultados]
    U --> V[An√°lise de correla√ß√£o entre m√©tricas e custos]
    V --> W[Documenta√ß√£o final e conclus√µes]
```

### 11.4 Plano de Piloto (se Haver√° Piloto, Escopo e Crit√©rios de Ajuste)

**Decis√£o:** **N√£o ser√° realizado experimento piloto formal**

#### Justificativa:

1. **Uso de Dados Reais P√∫blicos:**
   - Dados do Google Cluster Data 2019 s√£o bem documentados e validados
   - Dataset j√° utilizado em centenas de pesquisas acad√™micas
   - Qualidade e disponibilidade garantidas
   - Poss√≠vel validar pr√©-processamento antes de experimento principal

2. **Modelos Estabelecidos:**
   - Todos os 4 modelos s√£o bem conhecidos na literatura
   - Implementa√ß√µes em bibliotecas maduras (Scikit-learn, Statsmodels)
   - Baixo risco de problemas t√©cnicos inesperados

3. **Custo-Benef√≠cio:**
   - Experimento completo leva ~1 hora
   - Piloto tomaria tempo similar
   - Melhor investir tempo em valida√ß√£o pr√©via do dataset

#### Valida√ß√£o Alternativa ao Piloto:

**"Dry Run" (Execu√ß√£o de Teste):**

Antes do experimento principal, realizar:

1. **Teste com n=5 repeti√ß√µes:**
   - Executar cada modelo 5 vezes
   - Verificar que c√≥digo roda sem erros
   - Validar formato dos outputs
   - **Dura√ß√£o:** ~10 minutos

2. **Inspe√ß√£o Manual:**
   - Verificar se m√©tricas est√£o em ranges plaus√≠veis
   - Conferir se logs est√£o sendo gerados corretamente
   - Validar que seeds produzem resultados diferentes

3. **Crit√©rios de Prosseguimento:**
   - ‚úÖ Zero erros de execu√ß√£o
   - ‚úÖ Resultados dentro de ranges esperados (MAE entre 50-300 R$)
   - ‚úÖ Diferen√ßas vis√≠veis entre modelos
   - ‚úÖ Logs completos e leg√≠veis

**Se "Dry Run" Falhar:**
- Depurar c√≥digo
- Ajustar par√¢metros de gera√ß√£o de dados
- Revisar configura√ß√£o
- Repetir dry run at√© sucesso

---

## 12. Plano de An√°lise de Dados (Pr√©-Execu√ß√£o)

### 12.1 Estrat√©gia Geral de An√°lise (Como Responder√° √†s Quest√µes)

#### Mapeamento Quest√µes ‚Üí An√°lises:

**Quest√µes sobre Acur√°cia dos Modelos (Q1.1, Q2.1, Q2.2):**

**An√°lise:**
- Estat√≠stica descritiva: m√©dia, mediana, desvio padr√£o de MAE, RMSE, MAPE por modelo
- Tabelas comparativas
- Visualiza√ß√£o: boxplots, violin plots

**Como Responde:**
- "Qual modelo tem menor MAE?" ‚Üí Identificar modelo com menor m√©dia de MAE
- "Qual tem menor RMSE/MAPE?" ‚Üí An√°logo

---

**Quest√µes sobre Diferen√ßa Estat√≠stica (Q1.3, Q5.3):**

**An√°lise:**
- Teste de normalidade (Shapiro-Wilk)
- ANOVA ou Kruskal-Wallis (compara√ß√£o entre 4 grupos)
- Post-hoc tests (Tukey HSD ou Dunn's test)
- Tamanho de efeito (Œ∑¬≤ para ANOVA ou Œµ¬≤ para Kruskal-Wallis)

**Como Responde:**
- "H√° diferen√ßa significativa?" ‚Üí p-valor < 0.05 ‚Üí Sim
- "Quais modelos diferem?" ‚Üí Post-hoc indica pares significativos

---

**Quest√µes sobre Janelas Temporais (Q1.2, Q2.3):**

**An√°lise:**
- Compara√ß√£o explorat√≥ria de MAE em janelas de 7, 14, 30 dias
- Gr√°ficos de linha mostrando erro vs. tamanho de janela
- ANOVA de dois fatores (se tempo permitir): Modelo √ó Janela

**Como Responde:**
- "Erro diminui com janelas maiores?" ‚Üí Comparar m√©dias; testar tend√™ncia

---

**Quest√µes sobre Vari√°veis Preditoras (Q3.1, Q3.2, Q3.3):**

**An√°lise:**
- Correla√ß√£o de Pearson entre cada m√©trica e custo
- Heatmap de correla√ß√µes
- An√°lise de import√¢ncia de features (para Regress√£o Linear: coeficientes)

**Como Responde:**
- "Qual m√©trica mais correlacionada?" ‚Üí Maior |r| de Pearson
- "CPU √© melhor que mem√≥ria?" ‚Üí Comparar r(CPU, custo) vs. r(Mem√≥ria, custo)

---

**Quest√µes sobre Generaliza√ß√£o (Q4.1, Q4.2, Q4.3):**

**An√°lise:**
- Valida√ß√£o cruzada k-fold: calcular erro m√©dio nos folds
- Comparar erro de treino vs. erro de teste (diferen√ßa %)
- Detectar overfitting: se diferen√ßa > 15% ‚Üí flag

**Como Responde:**
- "Modelo generaliza?" ‚Üí Diferen√ßa treino/teste < 15%
- "Qual erro de valida√ß√£o cruzada?" ‚Üí M√©dia dos erros nos k folds

---

**Quest√µes sobre Estabilidade (Q5.1, Q5.2):**

**An√°lise:**
- Calcular desvio padr√£o dos erros de cada modelo
- Coeficiente de varia√ß√£o: CV = œÉ/Œº
- Detectar overfitting: diferen√ßa treino/teste por modelo

**Como Responde:**
- "Qual modelo mais est√°vel?" ‚Üí Menor desvio padr√£o
- "H√° overfitting?" ‚Üí Se diferen√ßa treino/teste > 10-15%

### 12.2 M√©todos Estat√≠sticos Planejados

#### Testes Estat√≠sticos:

**1. Teste de Normalidade:**
- **Nome:** Shapiro-Wilk test
- **Quando:** Antes de ANOVA
- **Hip√≥teses:**
  - H0: Os res√≠duos seguem distribui√ß√£o normal
  - H1: Os res√≠duos n√£o seguem distribui√ß√£o normal
- **Crit√©rio:** Œ± = 0.05
- **Decis√£o:** Se p > 0.05 ‚Üí Usar ANOVA; se p < 0.05 ‚Üí Usar Kruskal-Wallis

**C√≥digo:**
```python
from scipy.stats import shapiro

for modelo in ['RL', 'MM', 'ARIMA', 'ES']:
    residuos = df[df['modelo'] == modelo]['mae']
    stat, p_value = shapiro(residuos)
    print(f'{modelo}: p-valor = {p_value:.4f}')
```

---

**2. Compara√ß√£o Entre Modelos (Param√©trico):**
- **Nome:** ANOVA One-Way
- **Quando:** Se res√≠duos forem normais
- **Hip√≥teses:**
  - H0: Œº_RL = Œº_MM = Œº_ARIMA = Œº_ES
  - H1: Pelo menos um Œº_i ‚â† Œº_j
- **Crit√©rio:** Œ± = 0.05
- **Estat√≠stica:** F de Fisher
- **Interpreta√ß√£o:**
  - p < 0.05 ‚Üí Rejeitar H0 (diferen√ßa significativa existe)
  - p ‚â• 0.05 ‚Üí N√£o rejeitar H0

**C√≥digo:**
```python
from scipy.stats import f_oneway

grupo_rl = df[df['modelo'] == 'RL']['mae']
grupo_mm = df[df['modelo'] == 'MM']['mae']
grupo_arima = df[df['modelo'] == 'ARIMA']['mae']
grupo_es = df[df['modelo'] == 'ES']['mae']

f_stat, p_value = f_oneway(grupo_rl, grupo_mm, grupo_arima, grupo_es)
print(f'F = {f_stat:.4f}, p-valor = {p_value:.4f}')
```

---

**3. Compara√ß√£o Entre Modelos (N√£o-Param√©trico):**
- **Nome:** Kruskal-Wallis H test
- **Quando:** Se res√≠duos n√£o forem normais
- **Hip√≥teses:** Iguais ao ANOVA, mas sobre medianas
- **Crit√©rio:** Œ± = 0.05
- **Estat√≠stica:** H (qui-quadrado aproximado)

**C√≥digo:**
```python
from scipy.stats import kruskal

h_stat, p_value = kruskal(grupo_rl, grupo_mm, grupo_arima, grupo_es)
print(f'H = {h_stat:.4f}, p-valor = {p_value:.4f}')
```

---

**4. Compara√ß√µes Post-Hoc (Param√©trico):**
- **Nome:** Tukey's Honestly Significant Difference (HSD)
- **Quando:** Ap√≥s rejeitar H0 em ANOVA
- **Objetivo:** Identificar quais pares de modelos diferem
- **Crit√©rio:** Œ± = 0.05 com corre√ß√£o para m√∫ltiplas compara√ß√µes

**C√≥digo:**
```python
from scipy.stats import tukey_hsd

res = tukey_hsd(grupo_rl, grupo_mm, grupo_arima, grupo_es)
print(res)
```

---

**5. Compara√ß√µes Post-Hoc (N√£o-Param√©trico):**
- **Nome:** Dunn's test com corre√ß√£o de Bonferroni
- **Quando:** Ap√≥s rejeitar H0 em Kruskal-Wallis
- **Objetivo:** Compara√ß√µes pareadas
- **Crit√©rio:** Œ±_ajustado = 0.05 / 6 = 0.0083 (6 compara√ß√µes poss√≠veis)

---

**6. Correla√ß√£o:**
- **Nome:** Correla√ß√£o de Pearson
- **Quando:** Analisar rela√ß√£o entre m√©tricas e custo
- **Hip√≥teses:**
  - H0: œÅ = 0 (sem correla√ß√£o)
  - H1: œÅ ‚â† 0
- **Crit√©rio:** Œ± = 0.05
- **Interpreta√ß√£o de |r|:**
  - 0.0-0.3: Fraca
  - 0.3-0.7: Moderada
  - 0.7-1.0: Forte

**C√≥digo:**
```python
from scipy.stats import pearsonr

correlacoes = {}
for metrica in ['cpu', 'memoria', 'storage', 'requisicoes']:
    r, p_value = pearsonr(df[metrica], df['custo'])
    correlacoes[metrica] = {'r': r, 'p': p_value}
```

---

**7. Tamanho de Efeito:**
- **Nome:** Eta-squared (Œ∑¬≤) para ANOVA
- **F√≥rmula:** Œ∑¬≤ = SS_between / SS_total
- **Interpreta√ß√£o:**
  - 0.01: Efeito pequeno
  - 0.06: Efeito m√©dio
  - 0.14: Efeito grande

---

**8. Intervalos de Confian√ßa:**
- **95% CI para m√©dia de cada modelo**
- **F√≥rmula:** CI = xÃÑ ¬± t_{Œ±/2} √ó (s / ‚àön)
- **Interpreta√ß√£o:** Se CIs n√£o se sobrep√µem, sugere diferen√ßa significativa

### 12.3 Tratamento de Dados Faltantes e Outliers

#### Dados Faltantes:

**Preven√ß√£o (por constru√ß√£o):**
- Dados sint√©ticos n√£o ter√£o valores faltantes por design
- Valida√ß√£o pr√©-experimento garante completude

**Se Ocorrerem (bug ou erro de execu√ß√£o):**

**Regra 1: Exclus√£o de Execu√ß√£o Completa**
- Se uma execu√ß√£o falhar (erro de c√≥digo, crash), **remover completamente**
- N√£o imputar dados faltantes de m√©tricas de avalia√ß√£o
- **Justificativa:** Impedir vi√©s; melhor ter n=29 do que dados imputados incorretos

**Regra 2: Re-execu√ß√£o**
- Se execu√ß√£o falhou por erro t√©cnico, **re-executar** com mesmo seed
- Documentar ocorr√™ncia no log

**C√≥digo de Verifica√ß√£o:**
```python
# Verificar dados faltantes
assert df.isna().sum().sum() == 0, "Dados faltantes detectados!"

# Verificar n√∫mero de execu√ß√µes
assert len(df) == 120, f"Esperado 120 execu√ß√µes, obtido {len(df)}"
```

#### Outliers:

**Defini√ß√£o de Outlier:**
- Valores al√©m de **3 desvios-padr√£o** da m√©dia do grupo
- Ou valores imposs√≠veis (MAE negativo, MAPE > 200%)

**Tratamento:**

**Op√ß√£o 1: Investiga√ß√£o (Preferencial)**
1. Identificar outlier
2. Verificar log de execu√ß√£o correspondente
3. Se houver erro de execu√ß√£o ‚Üí **remover** e re-executar
4. Se outlier for leg√≠timo (modelo realmente ruim) ‚Üí **manter**

**Op√ß√£o 2: Winsoriza√ß√£o (Se Necess√°rio)**
- Substituir outliers pelos valores no percentil 1% e 99%
- **Usar apenas se**: outliers forem devido a variabilidade natural, n√£o erros
- **Documentar:** quais valores foram modificados

**C√≥digo de Detec√ß√£o:**
```python
def detectar_outliers(df, coluna, n_std=3):
    """Detecta outliers usando regra de n desvios-padr√£o"""
    media = df[coluna].mean()
    std = df[coluna].std()
    outliers = df[(df[coluna] < media - n_std*std) | 
                  (df[coluna] > media + n_std*std)]
    return outliers

# Aplicar
outliers_mae = detectar_outliers(df, 'mae', n_std=3)
if len(outliers_mae) > 0:
    print(f'Outliers detectados: {len(outliers_mae)}')
    print(outliers_mae[['modelo', 'repeticao', 'mae']])
```

**Decis√£o Final:**
- **Padr√£o:** Manter outliers leg√≠timos (refletem variabilidade real)
- **Exce√ß√£o:** Remover apenas se houver evid√™ncia de erro t√©cnico
- **Transpar√™ncia:** Documentar todas as remo√ß√µes e justificativas

---

## 13. Avalia√ß√£o de Validade (Amea√ßas e Mitiga√ß√£o)

Esta se√ß√£o identifica as principais amea√ßas √† validade do experimento, seguindo a classifica√ß√£o de Wohlin et al. (2012): validade de conclus√£o, validade interna, validade de constructo e validade externa. Para cada categoria, s√£o listadas as amea√ßas espec√≠ficas ao contexto deste estudo e as estrat√©gias planejadas de mitiga√ß√£o.

### 13.1 Validade de Conclus√£o

**Defini√ß√£o:** A validade de conclus√£o refere-se √† capacidade de tirar conclus√µes corretas sobre a rela√ß√£o entre tratamento (tipo de modelo) e resultado (erro de previs√£o), considerando a robustez estat√≠stica.

#### Amea√ßa 1.1: Poder Estat√≠stico Insuficiente

**Descri√ß√£o:**
Com n=30 repeti√ß√µes por modelo, o poder estat√≠stico √© de aproximadamente 80% para detectar diferen√ßas de efeito m√©dio (d de Cohen ‚âà 0.5), correspondendo a diferen√ßas de ~15-20% no erro m√©dio. Se as diferen√ßas reais entre modelos forem sutis (< 10%), o experimento pode **n√£o detectar diferen√ßas que realmente existem** (Erro Tipo II).

**Impacto:**
- Risco de concluir erroneamente que modelos t√™m desempenho equivalente
- Particularmente cr√≠tico se modelos avan√ßados (ARIMA, ES) apresentarem melhoria marginal sobre modelos simples

**Estrat√©gias de Mitiga√ß√£o:**
1. **Valida√ß√£o Cruzada k-fold (k=5):** Aumenta o n√∫mero efetivo de avalia√ß√µes (30 √ó 5 = 150 por modelo), melhorando a sensibilidade
2. **An√°lise de Tamanho de Efeito:** Calcular Œ∑¬≤ (eta-squared) mesmo quando p ‚â• 0.05, para quantificar magnitude das diferen√ßas
3. **Intervalos de Confian√ßa:** Reportar 95% CI para todas as m√©dias, permitindo interpreta√ß√£o pr√°tica al√©m de signific√¢ncia estat√≠stica
4. **An√°lise de Sensibilidade:** Se resultados forem inconclusivos, considerar aumentar n para 50 repeti√ß√µes ou usar Œ± mais liberal (0.10)

**Monitoramento:**
- Calcular poder estat√≠stico post-hoc ap√≥s coleta de dados
- Verificar se tamanho de efeito observado est√° dentro do detect√°vel (d ‚â• 0.5)

---

#### Amea√ßa 1.2: Viola√ß√£o de Suposi√ß√µes Estat√≠sticas

**Descri√ß√£o:**
ANOVA requer:
1. **Normalidade:** Os res√≠duos de cada grupo devem seguir distribui√ß√£o normal
2. **Homocedasticidade:** Vari√¢ncias dos grupos devem ser homog√™neas
3. **Independ√™ncia:** Observa√ß√µes devem ser independentes

Erros de previs√£o podem n√£o seguir distribui√ß√£o normal (por exemplo, serem assim√©tricos ou ter caudas pesadas), violando a primeira suposi√ß√£o. Alguns modelos podem ter variabilidade intrinsecamente maior que outros, violando a segunda.

**Impacto:**
- ANOVA pode produzir p-valores incorretos
- Conclus√µes sobre signific√¢ncia estat√≠stica podem ser inv√°lidas

**Estrat√©gias de Mitiga√ß√£o:**
1. **Teste de Normalidade Pr√©vio:** Aplicar Shapiro-Wilk test aos res√≠duos de cada grupo (Œ± = 0.05)
2. **Teste N√£o-Param√©trico Alternativo:** Se normalidade for violada (p < 0.05), usar **Kruskal-Wallis H test** no lugar de ANOVA
3. **Teste de Homogeneidade de Vari√¢ncias:** Aplicar Levene's test; se violado, usar Welch's ANOVA
4. **Transforma√ß√µes:** Se necess√°rio, aplicar transforma√ß√£o logar√≠tmica ou Box-Cox aos dados antes da an√°lise
5. **Bootstrapping:** Usar bootstrap para calcular intervalos de confian√ßa n√£o-param√©tricos

**Monitoramento:**
- Inspe√ß√£o visual: Q-Q plots para avaliar normalidade
- An√°lise de res√≠duos: gr√°ficos de res√≠duos vs. valores ajustados

---

#### Amea√ßa 1.3: Problema de M√∫ltiplas Compara√ß√µes

**Descri√ß√£o:**
Com 4 modelos, h√° **6 compara√ß√µes pareadas poss√≠veis** (RL vs. MM, RL vs. ARIMA, RL vs. ES, MM vs. ARIMA, MM vs. ES, ARIMA vs. ES). Ao realizar m√∫ltiplos testes com Œ± = 0.05 cada, a chance de pelo menos um **falso positivo** (Erro Tipo I) aumenta:

P(pelo menos 1 falso positivo) = 1 - (1 - 0.05)‚Å∂ ‚âà 26.5%

**Impacto:**
- Infla√ß√£o da taxa de erro Tipo I
- Aumento do risco de declarar diferen√ßas significativas que s√£o, na verdade, acaso estat√≠stico

**Estrat√©gias de Mitiga√ß√£o:**
1. **Testes Post-Hoc com Corre√ß√£o:**
   - Ap√≥s ANOVA: Usar **Tukey's HSD** (controla automaticamente o family-wise error rate)
   - Ap√≥s Kruskal-Wallis: Usar **Dunn's test com corre√ß√£o de Bonferroni**
2. **Corre√ß√£o de Bonferroni (se necess√°rio):**
   - Ajustar Œ± para Œ±_ajustado = 0.05 / 6 = 0.0083 para compara√ß√µes individuais
3. **Prioriza√ß√£o de Compara√ß√µes:**
   - Definir compara√ß√µes de interesse prim√°rio a priori (ex: ARIMA vs. RL)
   - Limitar compara√ß√µes explorat√≥rias n√£o planejadas

**Monitoramento:**
- Documentar quais compara√ß√µes foram planejadas vs. explorat√≥rias
- Reportar tanto p-valores brutos quanto ajustados

---

#### Amea√ßa 1.4: Variabilidade de Implementa√ß√£o dos Modelos

**Descri√ß√£o:**
Diferen√ßas observadas entre modelos podem ser parcialmente devidas a **diferen√ßas na qualidade da implementa√ß√£o**, n√£o apenas a superioridade inerente do algoritmo. Por exemplo:
- Um modelo pode ter bugs sutis que aumentam artificialmente seu erro
- Hiperpar√¢metros padr√£o de bibliotecas podem favorecer alguns modelos
- Otimiza√ß√£o de c√≥digo pode variar (ex: ARIMA pode ser mais lento e ter converg√™ncia inst√°vel)

**Impacto:**
- Confus√£o entre efic√°cia do algoritmo e qualidade da implementa√ß√£o
- Resultados n√£o refletem potencial real de cada modelo

**Estrat√©gias de Mitiga√ß√£o:**
1. **Uso de Bibliotecas Consolidadas:**
   - Scikit-learn: Regress√£o Linear, valida√ß√£o cruzada
   - Statsmodels: ARIMA, Exponential Smoothing
   - Valida√ß√£o: Bibliotecas s√£o amplamente testadas e usadas academicamente
2. **Valida√ß√£o de Implementa√ß√£o:**
   - Testar cada modelo com datasets conhecidos (benchmarks p√∫blicos)
   - Comparar resultados com exemplos da documenta√ß√£o oficial
   - Revis√£o de c√≥digo com orientador
3. **Documenta√ß√£o de Hiperpar√¢metros:**
   - Documentar todos os hiperpar√¢metros usados (mesmo padr√µes)
   - Justificar escolhas (ex: grid search para ARIMA, valores padr√£o para RL)
4. **An√°lise de Sensibilidade (Opcional):**
   - Testar varia√ß√µes de hiperpar√¢metros principais
   - Verificar se conclus√µes se mant√™m com configura√ß√µes alternativas

**Monitoramento:**
- Logs detalhados de execu√ß√£o de cada modelo
- Revis√£o de warnings e convergence issues

---

#### Amea√ßa 1.5: Variabilidade Aleat√≥ria N√£o Controlada

**Descri√ß√£o:**
Apesar da randomiza√ß√£o e das 30 repeti√ß√µes, resultados podem ter alta variabilidade devido a:
- Divis√µes treino/teste com caracter√≠sticas muito diferentes
- Inicializa√ß√µes aleat√≥rias de par√¢metros (em ARIMA, ES)
- Variabilidade natural dos algoritmos de otimiza√ß√£o

Isso pode levar a **intervalos de confian√ßa largos** que n√£o se distinguem entre modelos, mesmo que haja diferen√ßas reais.

**Impacto:**
- Conclus√µes incertas sobre qual modelo √© superior
- Necessidade de mais repeti√ß√µes para estabilizar resultados

**Estrat√©gias de Mitiga√ß√£o:**
1. **N√∫mero Adequado de Repeti√ß√µes:** n=30 √© suficiente pelo Teorema do Limite Central
2. **Seeds Documentados:** Todos os seeds aleat√≥rios salvos em CSV para reprodutibilidade total
3. **Valida√ß√£o Cruzada:** k-fold reduz depend√™ncia de uma √∫nica divis√£o treino/teste
4. **An√°lise de Vari√¢ncia:** Calcular e reportar desvio padr√£o e coeficiente de varia√ß√£o (CV = œÉ/Œº)
5. **Replica√ß√£o:** Se variabilidade for muito alta (CV > 50%), considerar aumentar n

**Monitoramento:**
- Inspe√ß√£o de boxplots para detectar variabilidade excessiva
- An√°lise de outliers (valores > 3 desvios-padr√£o)

---

### 13.2 Validade Interna

**Defini√ß√£o:** A validade interna refere-se √† capacidade de estabelecer rela√ß√£o causal correta entre o tratamento (tipo de modelo) e o resultado (erro de previs√£o), eliminando explica√ß√µes alternativas.

#### Amea√ßa 2.1: Hist√≥ria (History)

**Descri√ß√£o:**
Eventos externos durante a execu√ß√£o do experimento podem afetar os resultados de forma sistem√°tica:
- **Aquecimento de Hardware:** CPU pode aquecer ao longo das 120 execu√ß√µes, afetando performance e tempo de execu√ß√£o
- **Carga do Sistema:** Outros processos no sistema operacional podem consumir recursos
- **Atualiza√ß√µes de Software:** Atualiza√ß√µes autom√°ticas do SO ou antiv√≠rus podem interferir

Se modelos mais lentos (ARIMA) forem executados consistentemente ap√≥s aquecimento, podem ter desvantagem.

**Impacto:**
- Diferen√ßas observadas podem ser devidas a condi√ß√µes de execu√ß√£o, n√£o ao modelo em si
- Vi√©s sistem√°tico contra modelos mais lentos

**Estrat√©gias de Mitiga√ß√£o:**
1. **Randomiza√ß√£o Completa da Ordem de Execu√ß√£o:** As 120 execu√ß√µes ter√£o ordem completamente aleat√≥ria (n√£o bloco de 30 √ó RL, depois 30 √ó MM, etc.)
2. **Limpeza de Ambiente:**
   - Fechar aplica√ß√µes desnecess√°rias antes do experimento
   - Desabilitar atualiza√ß√µes autom√°ticas durante a execu√ß√£o
   - Restart do kernel Python a cada 30 execu√ß√µes (opcional)
3. **Monitoramento de Sistema:**
   - Registrar timestamp, temperatura de CPU e uso de mem√≥ria a cada execu√ß√£o
   - Detectar anomalias (ex: execu√ß√£o com uso de CPU > 90% por processo externo)
4. **An√°lise Post-Hoc:**
   - Testar se ordem de execu√ß√£o (1¬™, 2¬™, ..., 120¬™) correlaciona com erro
   - Regress√£o: Erro ~ Ordem_Execu√ß√£o; se significativo, flag como poss√≠vel confus√£o

**Monitoramento:**
- Logs de timestamp e condi√ß√µes de sistema
- An√°lise: ANOVA Erro ~ Posi√ß√£o_Execu√ß√£o (1-30, 31-60, 61-90, 91-120)

---

#### Amea√ßa 2.2: Matura√ß√£o (Maturation)

**Descri√ß√£o:**
Mudan√ßas no ambiente computacional ao longo do tempo de execu√ß√£o (~1 hora total):
- **Degrada√ß√£o de Hardware:** Poss√≠vel throttling t√©rmico de CPU ap√≥s uso prolongado
- **Degrada√ß√£o de Performance:** Cache ou mem√≥ria podem saturar
- **Fadiga do Pesquisador:** Menos relevante por ser automatizado, mas monitoramento pode se tornar menos atento

**Impacto:**
- Execu√ß√µes finais podem ter performance sistematicamente pior que iniciais
- Vi√©s temporal contra modelos executados mais tardiamente

**Estrat√©gias de Mitiga√ß√£o:**
1. **Randomiza√ß√£o:** Mesma estrat√©gia da Amea√ßa 2.1 (ordem aleat√≥ria mitiga matura√ß√£o)
2. **Execu√ß√£o Automatizada:** Script Python executa tudo sem interven√ß√£o humana, eliminando varia√ß√£o por fadiga
3. **Controle T√©rmico:**
   - Executar experimento em ambiente climatizado
   - Monitorar temperatura de CPU; se ultrapassar limiar (ex: 85¬∞C), pausar e resfriar
4. **Intervalos de Descanso (Opcional):**
   - Pausa de 5 minutos a cada 40 execu√ß√µes para resfriamento

**Monitoramento:**
- An√°lise de tend√™ncia temporal: Regress√£o Erro ~ Tempo_Decorrido
- Temperatura de CPU registrada em log

---

#### Amea√ßa 2.3: Instrumenta√ß√£o (Instrumentation)

**Descri√ß√£o:**
Mudan√ßas ou inconsist√™ncias na forma de medir as vari√°veis dependentes:
- **C√°lculo de M√©tricas:** Se f√≥rmulas de MAE, RMSE ou MAPE forem implementadas incorretamente ou mudarem durante o experimento
- **Precis√£o Num√©rica:** Erros de arredondamento ou overflow em c√°lculos
- **Vers√µes de Bibliotecas:** Atualiza√ß√£o acidental de Scikit-learn ou Statsmodels no meio do experimento

**Impacto:**
- Medidas de erro inconsistentes entre execu√ß√µes
- Invalida√ß√£o da comparabilidade dos resultados

**Estrat√©gias de Mitiga√ß√£o:**
1. **Implementa√ß√£o √önica e Validada:**
   - Fun√ß√µes de c√°lculo de m√©tricas escritas uma vez e testadas antes do experimento
   - Uso de implementa√ß√µes padr√£o (sklearn.metrics.mean_absolute_error, etc.)
2. **Ambiente Virtual Fixo:**
   - Criar ambiente virtual Python com vers√µes fixas de bibliotecas (requirements.txt)
   - N√£o atualizar bibliotecas durante o experimento
3. **Testes de Valida√ß√£o:**
   - Testar c√°lculos com dados sint√©ticos de resultado conhecido
   - Comparar com exemplos da documenta√ß√£o oficial
4. **Documenta√ß√£o de Vers√µes:**
   - Salvar output de `pip freeze` antes do experimento

**Monitoramento:**
- Verificar que todas as 120 execu√ß√µes usaram mesma vers√£o de bibliotecas
- Testes unit√°rios das fun√ß√µes de c√°lculo de m√©tricas

---

#### Amea√ßa 2.4: Sele√ß√£o (Selection Bias)

**Descri√ß√£o:**
Vi√©s na aloca√ß√£o de dados a diferentes modelos. No contexto deste experimento, seria se:
- Modelos diferentes recebessem subconjuntos diferentes dos dados
- Divis√µes treino/teste fossem sistematicamente diferentes entre modelos

**Impacto:**
- Compara√ß√£o injusta entre modelos
- Conclus√µes sobre superioridade de um modelo podem ser artefato da sele√ß√£o de dados

**Estrat√©gias de Mitiga√ß√£o:**
1. **Dados Id√™nticos para Todos os Modelos:**
   - Todos os 4 modelos recebem exatamente o mesmo dataset de entrada
   - Mesmas 720 observa√ß√µes (30 dias √ó 24 horas)
   - Mesmas 4 m√©tricas (CPU, mem√≥ria, storage, requisi√ß√µes)
2. **Divis√£o Treino/Teste Consistente por Repeti√ß√£o:**
   - Em cada repeti√ß√£o, todos os 4 modelos usam o mesmo seed para divis√£o treino/teste
   - Propor√ß√£o fixa 70%-30%
   - Mesmos 504 pontos de treino e 216 de teste para todos
3. **Sem Pr√©-Sele√ß√£o de Dados:**
   - Nenhum modelo recebe pr√©-processamento especial diferenciado
   - Mesma normaliza√ß√£o/padroniza√ß√£o aplicada a todos

**Monitoramento:**
- Verifica√ß√£o: Hash MD5 do dataset de entrada √© id√™ntico para todas as execu√ß√µes
- Assert: len(X_train) e len(X_test) s√£o iguais para todos os modelos em cada repeti√ß√£o

---

#### Amea√ßa 2.5: Overfitting Diferenciado Entre Modelos

**Descri√ß√£o:**
Alguns modelos podem sofrer overfitting (ajustar-se excessivamente aos dados de treino) mais que outros:
- **ARIMA:** Com ordem (p, d, q) muito alta, pode capturar ru√≠do do treino
- **Regress√£o Linear:** Menos propensa a overfitting com poucas features
- **Exponential Smoothing:** Pode se ajustar demais se Œ± estiver muito alto

Se overfitting n√£o for detectado, pode parecer que um modelo √© superior no treino, mas falha no teste.

**Impacto:**
- Modelo com melhor erro de treino pode ter pior erro de teste
- Avalia√ß√£o de generaliza√ß√£o comprometida

**Estrat√©gias de Mitiga√ß√£o:**
1. **Valida√ß√£o Cruzada Obrigat√≥ria:**
   - k-fold (k=5) para todos os modelos
   - Erro final √© m√©dia dos erros em 5 folds independentes
2. **Monitoramento Treino vs. Teste:**
   - Calcular M12 (Diferen√ßa Treino/Teste) para cada modelo
   - Flagging se diferen√ßa > 15% ‚Üí Poss√≠vel overfitting
3. **Regulariza√ß√£o (quando aplic√°vel):**
   - Regress√£o Linear: Considerar Ridge/Lasso se overfitting for detectado
   - ARIMA: Usar crit√©rios AIC/BIC para sele√ß√£o de ordem (p, d, q)
4. **Hiperpar√¢metros Conservadores:**
   - Preferir modelos mais simples (Occam's Razor)
   - ARIMA: Limitar p, d, q a valores razo√°veis (‚â§ 3)

**Monitoramento:**
- Plotar erro de treino vs. teste para cada modelo
- An√°lise de res√≠duos em dados de teste

---

#### Amea√ßa 2.6: Estimativa de Custos (N√£o Custos Reais)

**Descri√ß√£o:**
O experimento utiliza **m√©tricas de uso REAIS do Google Cluster Data 2019** (CPU, mem√≥ria), mas a **convers√£o de m√©tricas em custos √© ESTIMADA**, n√£o real:
- **M√©tricas de uso:** REAIS (CPU e mem√≥ria de workloads de produ√ß√£o do Google)
- **Custos:** ESTIMADOS usando tabelas de precifica√ß√£o p√∫blicas (AWS, Azure, GCP)
- Custos n√£o refletem precifica√ß√£o interna do Google
- Modelo de precifica√ß√£o simplificado (rela√ß√£o linear entre m√©tricas e custo)

**Impacto:**
- Rela√ß√£o entre m√©tricas e custo pode ser artificial
- Modelos podem se beneficiar de padr√µes que n√£o existiriam com custos reais
- Generaliza√ß√£o para custos reais de outros provedores pode ser limitada

**Estrat√©gias de Mitiga√ß√£o:**
1. **Modelo de Precifica√ß√£o Baseado em Literatura:**
   - Usar f√≥rmulas de c√°lculo de custo validadas em papers acad√™micos
   - Consultar tabelas p√∫blicas de precifica√ß√£o (AWS EC2, Azure VMs, GCP Compute Engine)
   - Documentar f√≥rmula exata usada
2. **Inclus√£o de Ru√≠do Realista:**
   - Adicionar varia√ß√£o estoc√°stica aos custos (¬± 5-10%) para simular flutua√ß√µes reais
   - Evitar rela√ß√µes perfeitamente lineares
3. **Valida√ß√£o com Especialistas:**
   - Revisar modelo de precifica√ß√£o com orientador
   - Comparar padr√µes de custo gerados com benchmarks da literatura
4. **Limita√ß√£o da Generaliza√ß√£o:**
   - Reconhecer explicitamente na discuss√£o que custos s√£o estimados
   - Recomendar valida√ß√£o com dados reais em trabalhos futuros

**Monitoramento:**
- An√°lise explorat√≥ria: Correla√ß√µes entre m√©tricas e custos devem ser plaus√≠veis (0.6-0.9)
- Compara√ß√£o com valores de refer√™ncia da literatura

---

### 13.3 Validade de Constructo

**Defini√ß√£o:** A validade de constructo refere-se a se as medidas escolhidas realmente representam os conceitos te√≥ricos de interesse e se n√£o h√° ambiguidade na interpreta√ß√£o.

#### Amea√ßa 3.1: Operacionaliza√ß√£o de "Custo"

**Descri√ß√£o:**
O conceito de "custo cloud" √© multifaceted, mas neste experimento √© **simplificado**:
- **Inclu√≠do:** Custo de compute (CPU, mem√≥ria), storage, requisi√ß√µes
- **Exclu√≠do:**
  - Custos de transfer√™ncia de dados entre regi√µes/zonas
  - Custos de servi√ßos gerenciados (bancos de dados, cache, load balancers)
  - Reserved instances, savings plans, descontos corporativos
  - Custos de suporte t√©cnico, SLAs

A m√©trica de custo usada pode **n√£o capturar completamente** o que stakeholders entendem por "custo real de cloud".

**Impacto:**
- Modelos podem prever bem o "custo simplificado" mas n√£o o "custo total real"
- Generaliza√ß√£o limitada para contextos onde custos exclu√≠dos s√£o significativos (ex: > 30% do custo total)

**Estrat√©gias de Mitiga√ß√£o:**
1. **Defini√ß√£o Expl√≠cita de Escopo:**
   - Documentar claramente quais componentes de custo s√£o inclu√≠dos/exclu√≠dos (Se√ß√£o 4.1)
   - Delimitar contextos de aplicabilidade (workloads compute-intensive sem servi√ßos gerenciados)
2. **Justificativa Te√≥rica:**
   - Fundamentar escolha em literatura (ex: papers que usam mesma simplifica√ß√£o)
   - Argumentar que componentes inclu√≠dos representam 60-80% do custo t√≠pico de IaaS
3. **An√°lise de Sensibilidade (Opcional):**
   - Testar modelo com diferentes pesos para componentes de custo
   - Verificar se conclus√µes se mant√™m com varia√ß√µes de ¬± 20% nos pesos
4. **Transpar√™ncia nos Resultados:**
   - Discutir limita√ß√µes da operacionaliza√ß√£o na se√ß√£o de discuss√£o
   - Recomendar extens√µes futuras (incluir custos de rede, servi√ßos gerenciados)

**Monitoramento:**
- Comparar propor√ß√µes de custo com benchmarks da literatura (ex: CPU deve ser 40-60% do total)

---

#### Amea√ßa 3.2: MAE como M√©trica Prim√°ria

**Descri√ß√£o:**
MAE (Mean Absolute Error) foi escolhida como m√©trica prim√°ria para compara√ß√£o, mas:
- **N√£o penaliza desproporcionalmente erros grandes:** Diferente de RMSE, que penaliza outliers
- **N√£o considera erro relativo:** Um erro de R$ 100 √© muito diferente em um custo de R$ 200 vs. R$ 10.000
- **Pode n√£o refletir impacto pr√°tico:** Stakeholders podem se preocupar mais com evitar grandes subestima√ß√µes (que causam estouro de or√ßamento) do que com erro m√©dio

Se modelos diferem primariamente em capacidade de evitar erros extremos, MAE pode n√£o capturar essa diferen√ßa.

**Impacto:**
- Modelo com menor MAE pode n√£o ser o mais √∫til na pr√°tica
- Ambiguidade sobre qual modelo √© "melhor" depende de qual aspecto do erro √© mais importante

**Estrat√©gias de Mitiga√ß√£o:**
1. **Uso de M√∫ltiplas M√©tricas:**
   - **MAE:** Erro m√©dio absoluto (m√©trica prim√°ria)
   - **RMSE:** Penaliza erros grandes (m√©trica secund√°ria)
   - **MAPE:** Erro percentual, relevante para compara√ß√£o relativa
   - **Erro m√°ximo:** Detectar casos extremos
2. **An√°lise Complementar:**
   - Reportar percentual de previs√µes com erro > 20%
   - Identificar casos onde erro foi particularmente grande (> 2 √ó MAE m√©dio)
3. **Justificativa da Escolha:**
   - MAE √© interpret√°vel (mesma unidade que custo - R$)
   - Menos sens√≠vel a outliers que RMSE
   - Amplamente usado em literatura de forecasting
4. **Discuss√£o Qualitativa:**
   - Analisar trade-offs entre m√©tricas
   - Discutir em quais contextos cada m√©trica √© mais relevante

**Monitoramento:**
- Comparar rankings de modelos por MAE vs. RMSE vs. MAPE
- Verificar se conclus√µes se mant√™m consistentes

---

#### Amea√ßa 3.3: "Acur√°cia" vs. "Utilidade Pr√°tica"

**Descri√ß√£o:**
O experimento mede **acur√°cia preditiva** (erro de previs√£o), mas n√£o mede **utilidade pr√°tica**:
- **N√£o mede:** Facilidade de implementa√ß√£o, tempo de execu√ß√£o, interpretabilidade, custo computacional
- **N√£o considera:** Prefer√™ncias de stakeholders (ex: CFO pode preferir modelo conservador que superestima custos para evitar surpresas)

Um modelo pode ter menor erro estat√≠stico mas ser menos √∫til (ex: ARIMA pode ser mais preciso mas muito lento e dif√≠cil de manter).

**Impacto:**
- Conclus√£o de "modelo superior" pode n√£o se traduzir em ado√ß√£o pr√°tica
- Gap entre validade estat√≠stica e relev√¢ncia organizacional

**Estrat√©gias de Mitiga√ß√£o:**
1. **Coleta de M√©tricas Adicionais:**
   - **Tempo de execu√ß√£o:** Registrar dura√ß√£o de treino + previs√£o para cada modelo
   - **Complexidade de implementa√ß√£o:** Linhas de c√≥digo, n√∫mero de hiperpar√¢metros
   - **Interpretabilidade:** Avalia√ß√£o qualitativa (ex: coeficientes de RL s√£o interpret√°veis)
2. **Discuss√£o de Trade-Offs:**
   - Se√ß√£o espec√≠fica comparando acur√°cia vs. simplicidade vs. velocidade
   - Matriz de decis√£o: quando cada modelo √© mais apropriado
3. **Recomenda√ß√µes Contextualizadas:**
   - "Use ARIMA se precis√£o √© cr√≠tica e tempo de treino n√£o √© problema"
   - "Use RL se interpretabilidade e velocidade s√£o prioridades"
4. **Valida√ß√£o com Stakeholders (Futura):**
   - Ap√≥s experimento, apresentar resultados a profissionais de DevOps/FinOps
   - Coletar feedback sobre utilidade percebida

**Monitoramento:**
- Tabela comparativa: Acur√°cia √ó Tempo √ó Complexidade √ó Interpretabilidade

---

#### Amea√ßa 3.4: Mono-Method Bias (Vi√©s de M√©todo √önico)

**Descri√ß√£o:**
Todas as vari√°veis dependentes (MAE, RMSE, MAPE) s√£o **m√©tricas quantitativas de erro**, medidas de forma automatizada. N√£o h√°:
- Valida√ß√£o qualitativa (entrevistas com usu√°rios)
- Observa√ß√£o de comportamento em produ√ß√£o
- Medidas subjetivas (confian√ßa na previs√£o, satisfa√ß√£o do usu√°rio)

Se houver aspectos importantes do conceito "modelo de previs√£o eficaz" que n√£o s√£o capturados por m√©tricas de erro, eles ser√£o omitidos.

**Impacto:**
- Vis√£o limitada do fen√¥meno estudado
- Poss√≠vel perda de insights importantes n√£o quantific√°veis

**Estrat√©gias de Mitiga√ß√£o:**
1. **Limita√ß√£o Expl√≠cita do Escopo:**
   - Reconhecer que experimento foca em acur√°cia t√©cnica, n√£o ado√ß√£o ou satisfa√ß√£o
   - Delimitar que objetivo √© compara√ß√£o quantitativa, n√£o estudo de usabilidade
2. **An√°lise Qualitativa Complementar (Opcional):**
   - Revis√£o de literatura sobre percep√ß√µes de usu√°rios de modelos de previs√£o
   - Discuss√£o te√≥rica sobre fatores organizacionais
3. **Triangula√ß√£o com Literatura:**
   - Comparar resultados com estudos de caso qualitativos publicados
   - Discutir converg√™ncia/diverg√™ncia de achados
4. **Recomenda√ß√£o de Pesquisas Futuras:**
   - Propor estudos mistos (quanti + quali) como extens√£o

**Monitoramento:**
- N/A (limita√ß√£o reconhecida, n√£o mitig√°vel neste experimento)

---

### 13.4 Validade Externa

**Defini√ß√£o:** A validade externa refere-se √† capacidade de generalizar os resultados para outros contextos, popula√ß√µes e situa√ß√µes al√©m do experimento espec√≠fico.

#### Amea√ßa 4.1: Especificidade do Provedor Cloud (Google)

**Descri√ß√£o:**
Os dados utilizados s√£o exclusivamente do **Google Cluster Data 2019**:
- Workloads espec√≠ficos da infraestrutura Google (Google Borg)
- Padr√µes de uso podem ser √∫nicos do ecossistema Google
- Caracter√≠sticas de escala de hyperscaler (muito larga escala)
- Precifica√ß√£o interna do Google difere de AWS, Azure, GCP p√∫blico

Resultados podem **n√£o se generalizar** para:
- AWS (EC2, Lambda, etc.)
- Azure (VMs, App Services, etc.)
- GCP p√∫blico (Compute Engine)
- Outros provedores (DigitalOcean, Linode, etc.)

**Impacto:**
- Modelos que performam bem com dados Google podem n√£o performar bem com dados AWS
- Padr√µes de workload e estruturas de custo s√£o provider-specific
- Limita√ß√£o severa da generaliza√ß√£o para ambientes multi-cloud

**Estrat√©gias de Mitiga√ß√£o:**
1. **Documenta√ß√£o Expl√≠cita do Contexto:**
   - Se√ß√µes 4.4 e 4.5 j√° listam esta limita√ß√£o
   - Delimitar claramente que resultados aplicam-se a "workloads similares aos traces Google"
2. **Uso de Modelo de Precifica√ß√£o Gen√©rico:**
   - Aplicar tabelas de precifica√ß√£o de m√∫ltiplos provedores (AWS, Azure, GCP) quando poss√≠vel
   - Comparar se conclus√µes se mant√™m com diferentes tabelas de pre√ßos
3. **Generaliza√ß√£o Te√≥rica:**
   - Argumentar que padr√µes fundamentais (tend√™ncia, sazonalidade) s√£o comuns a qualquer cloud
   - Focar em compara√ß√£o relativa entre modelos, n√£o valores absolutos de erro
4. **Recomenda√ß√£o de Valida√ß√£o Externa:**
   - Propor replica√ß√£o do experimento com datasets de outros provedores (Azure Public Dataset, etc.)
   - Disponibilizar c√≥digo para facilitar replica√ß√£o

**Monitoramento:**
- Compara√ß√£o de resultados com papers que usaram dados de outros provedores
- An√°lise de caracter√≠sticas do dataset Google vs. benchmarks de outros provedores

---

#### Amea√ßa 4.2: Per√≠odo Temporal Espec√≠fico (Maio 2019)

**Descri√ß√£o:**
Os dados cobrem **maio de 2019**:
- Padr√µes sazonais anuais n√£o s√£o capturados (apenas ~30 dias)
- Eventos espec√≠ficos daquele per√≠odo podem ter afetado os dados
- Tecnologia e arquiteturas cloud de 2019 podem diferir de 2024-2025
- Workloads podem ter mudado (ex: aumento de workloads de ML/IA)

Resultados podem n√£o se generalizar para:
- Outros per√≠odos do ano (ex: Black Friday, final de ano)
- Anos diferentes (mudan√ßas tecnol√≥gicas)
- Contextos p√≥s-pandemia (padr√µes de uso mudaram)

**Impacto:**
- Modelos podem capturar padr√µes espec√≠ficos de maio 2019 que n√£o se repetem
- Generaliza√ß√£o temporal limitada

**Estrat√©gias de Mitiga√ß√£o:**
1. **Sele√ß√£o de Per√≠odo T√≠pico:**
   - Verificar na documenta√ß√£o do Google Cluster Data se maio 2019 teve eventos at√≠picos
   - Evitar per√≠odos com feriados ou manuten√ß√µes grandes conhecidas
2. **An√°lise de M√∫ltiplas Janelas (Opcional):**
   - Se tempo permitir, testar com diferentes meses do dataset (abril, junho)
   - Verificar se conclus√µes se mant√™m
3. **Foco em Padr√µes Fundamentais:**
   - Analisar padr√µes di√°rios/semanais (que s√£o mais est√°veis ao longo dos anos)
   - Evitar conclus√µes sobre sazonalidade anual
4. **Transpar√™ncia:**
   - Reconhecer limita√ß√£o na discuss√£o
   - Recomendar valida√ß√£o com dados mais recentes

**Monitoramento:**
- An√°lise explorat√≥ria: Detectar eventos an√¥malos no per√≠odo selecionado
- Compara√ß√£o com papers que usaram outros per√≠odos

---

#### Amea√ßa 4.3: Escala e Complexidade (Hyperscaler vs. PMEs)

**Descri√ß√£o:**
Google Cluster Data representa **infraestrutura de larga escala** (hyperscaler):
- Milhares de jobs simult√¢neos
- M√∫ltiplos clusters com orquestra√ß√£o complexa (Borg)
- Workloads heterog√™neos e distribu√≠dos
- Padr√µes de uso de grandes volumes

Contextos de **pequenas e m√©dias empresas (PMEs)** podem ser drasticamente diferentes:
- Poucas dezenas de inst√¢ncias
- Workloads mais simples e homog√™neos
- Padr√µes de uso mais previs√≠veis ou mais err√°ticos (dependendo do neg√≥cio)
- Menor escala pode ter maior variabilidade relativa

**Impacto:**
- Modelos treinados com dados de larga escala podem n√£o performar bem em pequena escala
- Padr√µes de sazonalidade e tend√™ncia podem ser diferentes
- Generaliza√ß√£o limitada para startups e PMEs

**Estrat√©gias de Mitiga√ß√£o:**
1. **Delimita√ß√£o de Contexto de Aplicabilidade:**
   - Especificar que resultados aplicam-se a "ambientes cloud de m√©dia-alta escala"
   - Recomendar cautela ao aplicar em microempresas ou startups iniciais
2. **An√°lise de Subconjuntos (Opcional):**
   - Selecionar subset de jobs menores do dataset Google
   - Verificar se conclus√µes se mant√™m em workloads de escala reduzida
3. **Discuss√£o de Transferibilidade:**
   - Argumentar que modelos fundamentais (tend√™ncia, autocorrela√ß√£o) aplicam-se em diferentes escalas
   - Reconhecer que magnitudes de erro podem variar
4. **Recomenda√ß√£o de Calibra√ß√£o:**
   - Sugerir que usu√°rios de PMEs re-treinem modelos com seus pr√≥prios dados

**Monitoramento:**
- Compara√ß√£o de caracter√≠sticas do dataset Google com estat√≠sticas de uso cloud de PMEs (quando dispon√≠veis)

---

#### Amea√ßa 4.4: Tipo de Workload

**Descri√ß√£o:**
Google Cluster Data inclui workloads espec√≠ficos:
- Batch processing (processamento em lote)
- Jobs de an√°lise de dados
- Servi√ßos de backend do Google

Pode **n√£o representar** adequadamente:
- Aplica√ß√µes web t√≠picas (padr√µes de tr√°fego HTTP)
- Workloads de machine learning training (uso intensivo de GPU)
- Aplica√ß√µes serverless (fun√ß√µes com execu√ß√£o muito curta)
- Workloads de IoT ou edge computing
- Bancos de dados transacionais (OLTP)

**Impacto:**
- Modelos podem n√£o generalizar para workloads fora do escopo do dataset
- Padr√µes de uso (ex: picos s√∫bitos vs. uso constante) variam drasticamente por tipo de aplica√ß√£o

**Estrat√©gias de Mitiga√ß√£o:**
1. **Caracteriza√ß√£o do Dataset:**
   - Analisar e documentar tipos de jobs presentes no dataset
   - Classificar workloads (compute-intensive, memory-intensive, I/O-intensive)
2. **Delimita√ß√£o de Aplicabilidade:**
   - Especificar que resultados aplicam-se a "workloads de processamento distribu√≠do similar aos traces analisados"
   - Listar tipos de aplica√ß√µes onde resultados s√£o mais/menos aplic√°veis
3. **Heterogeneidade de Dados (Opcional):**
   - Selecionar subset diversificado de jobs (diferentes perfis de uso)
   - Aumentar representatividade dentro do poss√≠vel
4. **Recomenda√ß√£o de Valida√ß√£o:**
   - Propor extens√µes do estudo com datasets de outros tipos (Azure Public Dataset - LLM inference, MIT Supercloud - HPC)

**Monitoramento:**
- Tabela de caracter√≠sticas dos workloads analisados (% CPU-intensive, % memory-intensive, etc.)

---

#### Amea√ßa 4.5: Intera√ß√£o com Caracter√≠sticas Organizacionais

**Descri√ß√£o:**
O experimento √© **puramente t√©cnico**, sem considerar:
- Cultura organizacional (ex: empresas risk-averse vs. risk-tolerant)
- Processos de governan√ßa (ex: aprova√ß√£o de or√ßamentos)
- Maturidade em FinOps (empresas em est√°gios diferentes)
- Expertise t√©cnica da equipe (capacidade de implementar ARIMA vs. RL)

Ado√ß√£o e efic√°cia dos modelos podem depender fortemente de **fatores organizacionais n√£o controlados**.

**Impacto:**
- Modelo "melhor" tecnicamente pode n√£o ser adotado por barreiras organizacionais
- Generaliza√ß√£o para contextos organizacionais diversos √© incerta

**Estrat√©gias de Mitiga√ß√£o:**
1. **Foco em Validade T√©cnica:**
   - Reconhecer que experimento mede efic√°cia t√©cnica, n√£o ado√ß√£o organizacional
   - Delimitar que implementa√ß√£o pr√°tica depende de fatores contextuais
2. **Discuss√£o de Fatores Facilitadores:**
   - Listar pr√©-requisitos organizacionais para cada modelo
   - Ex: ARIMA requer expertise em s√©ries temporais; RL requer menos expertise
3. **Recomenda√ß√µes Contextualizadas:**
   - Matriz de decis√£o: "Use modelo X se contexto organizacional tem caracter√≠stica Y"
4. **Pesquisa Futura:**
   - Propor estudos de caso qualitativos em empresas reais
   - Investigar fatores organizacionais que afetam ado√ß√£o

**Monitoramento:**
- N/A (limita√ß√£o reconhecida, fora do escopo)

---

#### Amea√ßa 4.6: Generaliza√ß√£o para Horizontes de Previs√£o Diferentes

**Descri√ß√£o:**
O experimento foca em janelas temporais de **7, 14 e 30 dias** para treino, com horizonte de previs√£o impl√≠cito de curto-m√©dio prazo:
- N√£o testa previs√µes de longo prazo (6 meses, 1 ano)
- N√£o testa previs√µes de muito curto prazo (horas, minutos)

Modelos podem ter desempenho relativo diferente dependendo do horizonte:
- ARIMA pode ser superior para curto prazo mas degradar em longo prazo
- M√©dia m√≥vel pode ser adequada para muito curto prazo

**Impacto:**
- Conclus√µes sobre "modelo superior" s√£o espec√≠ficas ao horizonte testado
- Generaliza√ß√£o limitada para outros horizontes de previs√£o

**Estrat√©gias de Mitiga√ß√£o:**
1. **Especifica√ß√£o Expl√≠cita do Horizonte:**
   - Documentar que experimento foca em previs√µes de 1-30 dias √† frente
   - Delimitar contexto de aplicabilidade (planejamento de curto-m√©dio prazo)
2. **An√°lise de M√∫ltiplos Horizontes (Opcional):**
   - Se tempo permitir, testar horizontes de 1 dia, 7 dias, 14 dias, 30 dias
   - Verificar se rankings de modelos se mant√™m
3. **Justificativa Pr√°tica:**
   - Argumentar que horizontes de 1-30 dias s√£o mais relevantes para gest√£o operacional de custos
   - Previs√µes de 6+ meses s√£o mais estrat√©gicas e dependem de fatores de neg√≥cio
4. **Transpar√™ncia:**
   - Reconhecer na discuss√£o que resultados podem n√£o aplicar-se a horizontes muito diferentes

**Monitoramento:**
- Compara√ß√£o com literatura sobre performance de modelos em diferentes horizontes

---

### 13.5 Resumo das Principais Amea√ßas e Estrat√©gias de Mitiga√ß√£o

Esta tabela consolida as amea√ßas mais cr√≠ticas identificadas e as a√ß√µes planejadas para mitig√°-las.

| Categoria | Amea√ßa | Severidade | Impacto Principal | Estrat√©gias de Mitiga√ß√£o Planejadas | Status |
|-----------|--------|------------|-------------------|-------------------------------------|--------|
| **Validade de Conclus√£o** | Poder estat√≠stico insuficiente para diferen√ßas sutis (< 10%) | M√©dia | Falha em detectar diferen√ßas reais (Erro Tipo II) | ‚Ä¢ Valida√ß√£o cruzada k-fold (k=5)<br>‚Ä¢ An√°lise de tamanho de efeito (Œ∑¬≤)<br>‚Ä¢ Intervalos de confian√ßa 95%<br>‚Ä¢ Considerar n=50 se inconclusivo | ‚úÖ Planejado |
| **Validade de Conclus√£o** | Viola√ß√£o de normalidade dos res√≠duos | M√©dia | p-valores incorretos em ANOVA | ‚Ä¢ Shapiro-Wilk test pr√©-ANOVA<br>‚Ä¢ Kruskal-Wallis como alternativa n√£o-param√©trica<br>‚Ä¢ Levene's test para homocedasticidade<br>‚Ä¢ Transforma√ß√µes (log, Box-Cox) se necess√°rio | ‚úÖ Planejado |
| **Validade de Conclus√£o** | M√∫ltiplas compara√ß√µes inflam Erro Tipo I | Alta | Falsos positivos (diferen√ßas esp√∫rias) | ‚Ä¢ Tukey's HSD post-hoc (ANOVA)<br>‚Ä¢ Dunn's test + Bonferroni (Kruskal-Wallis)<br>‚Ä¢ Œ± ajustado = 0.0083 para compara√ß√µes<br>‚Ä¢ Prioriza√ß√£o de compara√ß√µes a priori | ‚úÖ Planejado |
| **Validade de Conclus√£o** | Variabilidade de implementa√ß√£o dos modelos | M√©dia | Diferen√ßas devido a bugs, n√£o efic√°cia | ‚Ä¢ Uso de bibliotecas consolidadas (Scikit-learn, Statsmodels)<br>‚Ä¢ Valida√ß√£o com benchmarks conhecidos<br>‚Ä¢ Revis√£o de c√≥digo com orientador<br>‚Ä¢ Documenta√ß√£o completa de hiperpar√¢metros | ‚úÖ Planejado |
| **Validade Interna** | Hist√≥ria (aquecimento de hardware, carga de sistema) | M√©dia | Vi√©s temporal sistem√°tico | ‚Ä¢ Randomiza√ß√£o completa da ordem de execu√ß√£o<br>‚Ä¢ Limpeza de ambiente (fechar apps, desabilitar updates)<br>‚Ä¢ Monitoramento de temperatura/CPU<br>‚Ä¢ An√°lise post-hoc: Erro ~ Ordem_Execu√ß√£o | ‚úÖ Planejado |
| **Validade Interna** | Overfitting diferenciado entre modelos | Alta | Modelo "melhor" em treino, pior em teste | ‚Ä¢ Valida√ß√£o cruzada k-fold obrigat√≥ria<br>‚Ä¢ Monitoramento M12 (diferen√ßa treino/teste)<br>‚Ä¢ Flagging se diferen√ßa > 15%<br>‚Ä¢ AIC/BIC para sele√ß√£o de ordem (ARIMA) | ‚úÖ Planejado |
| **Validade Interna** | Qualidade dos dados (custos estimados, n√£o reais) | Alta | Rela√ß√£o m√©trica-custo artificial | ‚Ä¢ Modelo de precifica√ß√£o baseado em literatura<br>‚Ä¢ Consulta a tabelas p√∫blicas (AWS, Azure, GCP)<br>‚Ä¢ Inclus√£o de ru√≠do estoc√°stico (¬± 5-10%)<br>‚Ä¢ Valida√ß√£o com orientador | ‚úÖ Planejado |
| **Validade de Constructo** | Operacionaliza√ß√£o simplificada de "custo" | M√©dia | N√£o captura custos de rede, servi√ßos gerenciados, descontos | ‚Ä¢ Defini√ß√£o expl√≠cita de escopo (Se√ß√£o 4.1)<br>‚Ä¢ Justificativa: componentes inclu√≠dos = 60-80% do total IaaS<br>‚Ä¢ Transpar√™ncia na discuss√£o<br>‚Ä¢ Recomenda√ß√£o de extens√µes futuras | ‚úÖ Planejado |
| **Validade de Constructo** | MAE como m√©trica prim√°ria n√£o captura todos aspectos | M√©dia | Pode n√£o refletir impacto pr√°tico (ex: evitar grandes erros) | ‚Ä¢ Uso de m√∫ltiplas m√©tricas (MAE, RMSE, MAPE, erro m√°ximo)<br>‚Ä¢ An√°lise complementar (% previs√µes com erro > 20%)<br>‚Ä¢ Justificativa de escolha<br>‚Ä¢ Discuss√£o de trade-offs | ‚úÖ Planejado |
| **Validade de Constructo** | "Acur√°cia" ‚â† "Utilidade Pr√°tica" | Baixa | Modelo mais preciso pode n√£o ser adotado | ‚Ä¢ Coleta de tempo de execu√ß√£o, complexidade<br>‚Ä¢ Discuss√£o de trade-offs acur√°cia √ó velocidade √ó interpretabilidade<br>‚Ä¢ Recomenda√ß√µes contextualizadas<br>‚Ä¢ Valida√ß√£o futura com stakeholders | ‚ö†Ô∏è Parcial |
| **Validade Externa** | Especificidade do provedor (Google) | Alta | N√£o generaliza para AWS, Azure, outros | ‚Ä¢ Documenta√ß√£o expl√≠cita do contexto<br>‚Ä¢ Uso de precifica√ß√£o gen√©rica (m√∫ltiplos provedores)<br>‚Ä¢ Foco em compara√ß√£o relativa, n√£o absoluta<br>‚Ä¢ Recomenda√ß√£o de replica√ß√£o com outros datasets | ‚ö†Ô∏è Limita√ß√£o Aceita |
| **Validade Externa** | Per√≠odo temporal espec√≠fico (maio 2019) | M√©dia | Padr√µes sazonais anuais n√£o capturados | ‚Ä¢ Sele√ß√£o de per√≠odo t√≠pico (verificar eventos at√≠picos)<br>‚Ä¢ An√°lise de m√∫ltiplas janelas se tempo permitir<br>‚Ä¢ Foco em padr√µes di√°rios/semanais (mais est√°veis)<br>‚Ä¢ Transpar√™ncia na discuss√£o | ‚ö†Ô∏è Limita√ß√£o Aceita |
| **Validade Externa** | Escala (hyperscaler vs. PMEs) | Alta | N√£o se aplica a startups/PMEs | ‚Ä¢ Delimita√ß√£o: aplic√°vel a m√©dia-alta escala<br>‚Ä¢ An√°lise de subconjuntos (jobs menores) opcional<br>‚Ä¢ Discuss√£o de transferibilidade<br>‚Ä¢ Recomenda√ß√£o de calibra√ß√£o para PMEs | ‚ö†Ô∏è Limita√ß√£o Aceita |
| **Validade Externa** | Tipo de workload espec√≠fico | M√©dia | N√£o generaliza para ML training, serverless, IoT, OLTP | ‚Ä¢ Caracteriza√ß√£o detalhada dos workloads do dataset<br>‚Ä¢ Delimita√ß√£o de aplicabilidade (processamento distribu√≠do)<br>‚Ä¢ Sele√ß√£o de subset heterog√™neo<br>‚Ä¢ Recomenda√ß√£o de valida√ß√£o com outros datasets | ‚ö†Ô∏è Limita√ß√£o Aceita |

**Legenda de Status:**
- ‚úÖ **Planejado:** Estrat√©gia de mitiga√ß√£o implementada/planejada no experimento
- ‚ö†Ô∏è **Limita√ß√£o Aceita:** Amea√ßa reconhecida mas n√£o totalmente mitig√°vel; ser√° explicitada na discuss√£o
- ‚ö†Ô∏è **Parcial:** Mitiga√ß√£o parcial implementada; limita√ß√£o residual reconhecida

---

#### Prioriza√ß√£o de Amea√ßas (Top 5 Cr√≠ticas)

Com base em **severidade** e **impacto potencial**, as 5 amea√ßas mais cr√≠ticas s√£o:

1. **M√∫ltiplas Compara√ß√µes (Validade de Conclus√£o)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Tukey's HSD post-hoc com corre√ß√£o autom√°tica
   - **Crit√©rio de Sucesso:** Reportar p-valores ajustados para todas as compara√ß√µes

2. **Overfitting Diferenciado (Validade Interna)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Valida√ß√£o cruzada k-fold obrigat√≥ria + monitoramento M12
   - **Crit√©rio de Sucesso:** Diferen√ßa treino/teste < 15% para todos os modelos

3. **Qualidade dos Dados - Custos Estimados (Validade Interna)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Modelo de precifica√ß√£o validado + inclus√£o de ru√≠do
   - **Crit√©rio de Sucesso:** Correla√ß√µes m√©trica-custo plaus√≠veis (0.6-0.9)

4. **Especificidade do Provedor Google (Validade Externa)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Uso de precifica√ß√£o gen√©rica + documenta√ß√£o expl√≠cita de limita√ß√µes
   - **Crit√©rio de Sucesso:** Discuss√£o transparente de contextos de aplicabilidade

5. **Escala Hyperscaler vs. PMEs (Validade Externa)**
   - **Severidade:** Alta
   - **Mitiga√ß√£o Principal:** Delimita√ß√£o clara de contexto + recomenda√ß√£o de calibra√ß√£o
   - **Crit√©rio de Sucesso:** Se√ß√£o de discuss√£o com guidelines de transferibilidade

---

#### A√ß√µes de Monitoramento P√≥s-Experimento

**Checklist de Valida√ß√£o dos Resultados:**

- [ ] **Normalidade:** Shapiro-Wilk p-valor > 0.05 para todos os grupos?
- [ ] **Homocedasticidade:** Levene's test p-valor > 0.05?
- [ ] **Overfitting:** Diferen√ßa treino/teste < 15% para todos os modelos?
- [ ] **Outliers:** Outliers detectados investigados e documentados?
- [ ] **Randomiza√ß√£o:** An√°lise Erro ~ Ordem_Execu√ß√£o n√£o significativa (p > 0.05)?
- [ ] **Correla√ß√µes Plaus√≠veis:** 0.6 ‚â§ |r(m√©trica, custo)| ‚â§ 0.9?
- [ ] **Consist√™ncia de M√©tricas:** Rankings por MAE, RMSE e MAPE convergem?
- [ ] **Vers√µes de Software:** `pip freeze` documentado e consistente?
- [ ] **Reprodutibilidade:** Seeds salvos e experimento reproduz√≠vel?
- [ ] **Documenta√ß√£o de Limita√ß√µes:** Se√ß√£o de discuss√£o inclui todas as amea√ßas da Se√ß√£o 13.5?

**Se Problemas Forem Detectados:**
- **Viola√ß√£o de normalidade severa:** Usar Kruskal-Wallis + Dunn's test
- **Overfitting > 15%:** Analisar e reportar separadamente; considerar exclus√£o do modelo ou re-tuning
- **Ordem de execu√ß√£o significativa:** Incluir "ordem" como covari√°vel na an√°lise
- **Outliers inexplic√°veis:** Remover e re-executar; documentar justificativa


---

## 14. √âtica, Privacidade e Conformidade

### 14.1 Quest√µes √âticas (Uso de Sujeitos, Incentivos, etc.)

**Situa√ß√£o:** Este experimento **n√£o envolve sujeitos humanos**.

#### Natureza do Estudo:

Este √© um estudo **puramente computacional** que utiliza:
- **Dados p√∫blicos:** Google Cluster Data 2019 (dataset p√∫blico e anonimizado)
- **An√°lise quantitativa:** Compara√ß√£o de modelos de previs√£o em ambiente controlado
- **Sem intera√ß√£o humana:** Nenhuma coleta de dados de participantes, entrevistas ou observa√ß√µes

#### Quest√µes √âticas Aplic√°veis:

**1. Uso √âtico de Dados P√∫blicos:**
- **Situa√ß√£o:** Os dados do Google Cluster Data 2019 foram publicados sob licen√ßa **Creative Commons BY 4.0** (CC-BY)
- **Conformidade:** O uso est√° em conformidade com os termos da licen√ßa, que permite uso acad√™mico e pesquisa
- **Atribui√ß√£o:** O dataset ser√° devidamente citado em todas as publica√ß√µes

**2. Responsabilidade Cient√≠fica:**
- **Compromisso com rigor:** Seguir metodologia experimental rigorosa conforme se√ß√µes anteriores
- **Transpar√™ncia:** Documentar limita√ß√µes e amea√ßas √† validade (Se√ß√£o 13)
- **Reprodutibilidade:** Disponibilizar c√≥digo, dados processados e documenta√ß√£o (Se√ß√£o 18)

**3. Potencial Impacto Social:**
- **Impacto positivo:** Contribuir para otimiza√ß√£o de custos cloud, beneficiando organiza√ß√µes
- **Sem riscos identificados:** N√£o h√° riscos √©ticos de uso indevido dos resultados
- **Aplica√ß√£o respons√°vel:** Resultados s√£o recomenda√ß√µes t√©cnicas, n√£o decis√µes automatizadas cr√≠ticas

#### Conclus√£o:

**N√£o h√° quest√µes √©ticas cr√≠ticas** neste experimento, pois:
- N√£o envolve seres humanos
- Usa dados p√∫blicos e devidamente licenciados
- N√£o apresenta riscos de dano a indiv√≠duos ou organiza√ß√µes
- Segue princ√≠pios de integridade cient√≠fica

---

### 14.2 Consentimento Informado

**N√£o Aplic√°vel:** Este experimento n√£o envolve participantes humanos, portanto **n√£o h√° necessidade de consentimento informado**.

#### Justificativa:

O experimento √© baseado exclusivamente em:
1. **Dados secund√°rios p√∫blicos** (Google Cluster Data 2019)
2. **Processamento computacional** de m√©tricas de infraestrutura
3. **An√°lise estat√≠stica** automatizada

**Nenhum dado pessoal identific√°vel √© coletado, processado ou armazenado.**

---

### 14.3 Privacidade e Prote√ß√£o de Dados

#### Dados Coletados e Processados:

**1. Dados do Google Cluster Data 2019:**

| Tipo de Dado | Descri√ß√£o | Natureza | Identific√°vel? |
|--------------|-----------|----------|----------------|
| **Timestamps** | Marca√ß√µes temporais (maio 2019) | Temporal | ‚ùå N√£o |
| **CPU usage** | M√©tricas de utiliza√ß√£o de CPU | T√©cnica | ‚ùå N√£o |
| **Memory usage** | M√©tricas de uso de mem√≥ria | T√©cnica | ‚ùå N√£o |
| **Job/Task IDs** | Identificadores num√©ricos de jobs | T√©cnica | ‚ùå N√£o (anonimizados) |
| **Collection IDs** | Identificadores de cole√ß√µes | T√©cnica | ‚ùå N√£o (anonimizados) |

**2. Dados Gerados pelo Experimento:**

| Tipo de Dado | Descri√ß√£o | Identific√°vel? |
|--------------|-----------|----------------|
| **Resultados de modelos** | MAE, RMSE, MAPE por execu√ß√£o | ‚ùå N√£o |
| **Logs de experimento** | Timestamps, status de execu√ß√£o | ‚ùå N√£o |
| **M√©tricas agregadas** | Estat√≠sticas descritivas | ‚ùå N√£o |

#### Caracter√≠sticas de Privacidade:

**‚úÖ Conformidade com LGPD/GDPR:**

- **N√£o h√° dados pessoais:** Nenhum dado do experimento se enquadra na defini√ß√£o de "dado pessoal" (LGPD Art. 5¬∫, I)
- **Anonimiza√ß√£o por design:** Google Cluster Data j√° foi anonimizado pelo provedor original
- **Sem possibilidade de reidentifica√ß√£o:** IDs de jobs/tasks n√£o podem ser associados a indiv√≠duos

**‚úÖ Prote√ß√£o de Dados:**

1. **Armazenamento:**
   - Dados processados armazenados localmente no computador do pesquisador
   - Backup em reposit√≥rio GitHub p√∫blico (dados j√° p√∫blicos)
   - Nenhum dado sens√≠vel ou confidencial

2. **Controle de Acesso:**
   - Dados p√∫blicos: sem restri√ß√µes de acesso
   - Scripts e c√≥digo: reposit√≥rio p√∫blico GitHub

3. **Per√≠odo de Reten√ß√£o:**
   - **Durante o TCC:** Dados mantidos durante desenvolvimento (6 meses)
   - **Ap√≥s conclus√£o:** Dados e c√≥digo mantidos indefinidamente no GitHub para reprodutibilidade
   - **Justificativa:** Promover ci√™ncia aberta e reprodut√≠vel

#### Conclus√£o:

**N√£o h√° riscos de privacidade** neste experimento, pois:
- N√£o processa dados pessoais
- Usa dataset p√∫blico e anonimizado
- Segue princ√≠pios de dados abertos e ci√™ncia aberta

---

### 14.4 Aprova√ß√µes Necess√°rias (Comit√™ de √âtica, Jur√≠dico, DPO, etc.)

#### An√°lise de Necessidade de Aprova√ß√µes:

**1. Comit√™ de √âtica em Pesquisa (CEP):**

| Item | An√°lise | Necessidade |
|------|---------|-------------|
| **Envolve seres humanos?** | ‚ùå N√£o | ‚ö™ N√£o requerido |
| **Coleta dados de participantes?** | ‚ùå N√£o | ‚ö™ N√£o requerido |
| **Apresenta riscos a indiv√≠duos?** | ‚ùå N√£o | ‚ö™ N√£o requerido |
| **Uso de dados pessoais sens√≠veis?** | ‚ùå N√£o | ‚ö™ N√£o requerido |

**Conclus√£o:** **Dispensa de aprova√ß√£o CEP** (conforme Resolu√ß√£o CNS 510/2016, Art. 1¬∫, Par√°grafo √önico, VII - pesquisa que utilize informa√ß√µes de acesso p√∫blico)

**2. Data Protection Officer (DPO) / Encarregado LGPD:**

| Item | An√°lise | Necessidade |
|------|---------|-------------|
| **Processa dados pessoais?** | ‚ùå N√£o | ‚ö™ N√£o requerido |
| **Conformidade LGPD?** | ‚úÖ Sim (n√£o aplic√°vel - sem dados pessoais) | ‚ö™ N√£o requerido |

**Conclus√£o:** **N√£o requerida aprova√ß√£o DPO**

**3. Departamento Jur√≠dico / Compliance:**

| Item | An√°lise | Necessidade |
|------|---------|-------------|
| **Uso de dados propriet√°rios?** | ‚ùå N√£o (dados p√∫blicos CC-BY) | ‚ö™ N√£o requerido |
| **Quest√µes contratuais?** | ‚ùå N√£o | ‚ö™ N√£o requerido |
| **Risco legal?** | ‚ùå N√£o | ‚ö™ N√£o requerido |

**Conclus√£o:** **N√£o requerida aprova√ß√£o jur√≠dica**

**4. Coordena√ß√£o do Curso / Orientador:**

| Item | An√°lise | Necessidade |
|------|---------|-------------|
| **Aprova√ß√£o do tema TCC?** | ‚úÖ Sim | ‚úÖ **Requerido** |
| **Revis√£o do plano experimental?** | ‚úÖ Sim | ‚úÖ **Requerido** |
| **Aprova√ß√£o para defesa?** | ‚úÖ Sim | ‚úÖ **Requerido** |

**Conclus√£o:** **Aprova√ß√µes acad√™micas necess√°rias**

#### Resumo de Aprova√ß√µes:

| √ìrg√£o/Pessoa | Status | Observa√ß√µes |
|--------------|--------|-------------|
| **Comit√™ de √âtica (CEP)** | ‚ö™ N√£o aplic√°vel | Pesquisa com dados p√∫blicos, sem sujeitos humanos |
| **DPO / LGPD** | ‚ö™ N√£o aplic√°vel | N√£o processa dados pessoais |
| **Jur√≠dico** | ‚ö™ N√£o aplic√°vel | Uso de dados p√∫blicos licenciados |
| **Orientador (Prof. Danilo)** | üü° Pendente | Aprova√ß√£o do plano experimental |
| **Coordena√ß√£o do Curso** | üü° Pendente | Aprova√ß√£o formal do tema de TCC |
| **Banca Examinadora** | üü¢ Futuro | Ap√≥s conclus√£o do trabalho |

#### Documenta√ß√£o de Conformidade:

**Declara√ß√£o:**

> Este experimento foi avaliado quanto √† necessidade de aprova√ß√£o de Comit√™ de √âtica em Pesquisa (CEP) e foi considerado **dispensado**, conforme Resolu√ß√£o CNS 510/2016, Art. 1¬∫, Par√°grafo √önico, inciso VII, por se tratar de pesquisa que utiliza exclusivamente informa√ß√µes de acesso p√∫blico (Google Cluster Data 2019, licenciado sob Creative Commons BY 4.0), sem envolvimento de seres humanos, dados pessoais ou informa√ß√µes sens√≠veis.

**Respons√°vel pela An√°lise:** Renato Matos Alves Penna (Pesquisador)
**Orientador:** Prof. Danilo de Quadros Maia Filho
**Institui√ß√£o:** Pontif√≠cia Universidade Cat√≥lica de Minas Gerais (PUC Minas)
**Curso:** Bacharelado em Engenharia de Software
**Data da An√°lise:** 05/12/2025

---


## 15. Recursos, Infraestrutura e Or√ßamento

### 15.1 Recursos Humanos e Pap√©is

#### Equipe do Experimento:

| Nome | Papel | Responsabilidades | Dedica√ß√£o | Contato |
|------|-------|-------------------|-----------|---------|
| **Renato Matos Alves Penna** | Pesquisador Principal / Executor | - Planejamento experimental<br>- Implementa√ß√£o de c√≥digo<br>- Coleta e processamento de dados<br>- Execu√ß√£o do experimento<br>- An√°lise de resultados<br>- Reda√ß√£o do TCC | 15-20h/semana | renatomatosapbusiness@gmail.com |
| **Prof. Danilo de Quadros Maia Filho** | Orientador | - Revis√£o do plano experimental<br>- Consultoria metodol√≥gica<br>- Revis√£o de resultados<br>- Aprova√ß√£o de entregas<br>- Orienta√ß√£o acad√™mica | 2-3h/m√™s | (contato via PUC Minas) |

#### Descri√ß√£o de Pap√©is:

**1. Pesquisador Principal (Renato):**

**Responsabilidades Principais:**
- ‚úÖ **Planejamento:** Elabora√ß√£o completa do plano experimental
- ‚úÖ **Implementa√ß√£o:** Desenvolvimento de scripts Python para processamento, modelagem e an√°lise
- ‚úÖ **Execu√ß√£o:** Opera√ß√£o do experimento completo (120 execu√ß√µes √ó 4 modelos)
- ‚úÖ **An√°lise:** Interpreta√ß√£o estat√≠stica dos resultados
- ‚úÖ **Documenta√ß√£o:** Reda√ß√£o do documento de TCC
- ‚úÖ **Apresenta√ß√£o:** Defesa do trabalho perante banca

**Perfil de Compet√™ncias:**
- Python intermedi√°rio/avan√ßado
- Estat√≠stica e an√°lise de dados
- Machine learning e s√©ries temporais (conceitos)
- Metodologia cient√≠fica
- Escrita acad√™mica

**2. Orientador (Prof. Danilo):**

**Responsabilidades Principais:**
- ‚úÖ **Revis√£o Metodol√≥gica:** Validar desenho experimental e rigor cient√≠fico
- ‚úÖ **Consultoria T√©cnica:** Esclarecer d√∫vidas sobre m√©todos estat√≠sticos e modelagem
- ‚úÖ **Feedback Cont√≠nuo:** Revisar entregas intermedi√°rias (se houver)
- ‚úÖ **Aprova√ß√£o Final:** Autorizar entrega do trabalho para defesa

**Frequ√™ncia de Intera√ß√£o:**
- Reuni√µes quinzenais ou mensais (conforme necessidade)
- E-mail para d√∫vidas pontuais
- Revis√£o de entregas em marcos definidos

#### Estrutura de Comunica√ß√£o:

```
Pesquisador (Renato)
       ‚Üì
    Orientador (Danilo)
       ‚Üì
Coordena√ß√£o de TCC (PUC Minas)
       ‚Üì
    Banca Examinadora
```

---

### 15.2 Infraestrutura T√©cnica Necess√°ria

#### Ambiente Computacional:

**1. Hardware:**

| Recurso | Especifica√ß√£o M√≠nima | Especifica√ß√£o Recomendada | Disponibilidade |
|---------|---------------------|---------------------------|-----------------|
| **Processador** | Intel i5 / AMD Ryzen 5 (4 cores) | Intel i7 / AMD Ryzen 7 (8 cores) | ‚úÖ Computador pessoal |
| **Mem√≥ria RAM** | 8 GB | 16 GB | ‚úÖ Computador pessoal |
| **Armazenamento** | 20 GB livres | 50 GB livres (SSD) | ‚úÖ Computador pessoal |
| **Sistema Operacional** | Windows 10/11, Linux, macOS | Qualquer (Python multiplataforma) | ‚úÖ Computador pessoal |

**Nota:** O experimento ser√° executado em **computador pessoal do pesquisador**. N√£o h√° necessidade de infraestrutura de cloud ou cluster computacional.

**2. Software e Ferramentas:**

| Ferramenta | Vers√£o | Prop√≥sito | Custo | Disponibilidade |
|------------|--------|-----------|-------|-----------------|
| **Python** | 3.10+ | Linguagem de programa√ß√£o | Gratuito | ‚úÖ J√° instalado |
| **Pandas** | 2.0+ | Manipula√ß√£o de dados | Gratuito | ‚úÖ pip install |
| **NumPy** | 1.24+ | Computa√ß√£o num√©rica | Gratuito | ‚úÖ pip install |
| **Scikit-learn** | 1.3+ | Modelos de ML | Gratuito | ‚úÖ pip install |
| **Statsmodels** | 0.14+ | Modelos estat√≠sticos (ARIMA, ES) | Gratuito | ‚úÖ pip install |
| **Matplotlib / Seaborn** | √öltima | Visualiza√ß√£o de dados | Gratuito | ‚úÖ pip install |
| **Jupyter Notebook** | √öltima | An√°lise interativa | Gratuito | ‚úÖ pip install |
| **VS Code / PyCharm** | √öltima | IDE para desenvolvimento | Gratuito | ‚úÖ J√° instalado |
| **Git** | 2.40+ | Controle de vers√£o | Gratuito | ‚úÖ J√° instalado |
| **GitHub** | - | Hospedagem de reposit√≥rio | Gratuito (p√∫blico) | ‚úÖ Conta criada |

**3. Reposit√≥rios e Armazenamento:**

| Recurso | Descri√ß√£o | Capacidade | Custo | URL |
|---------|-----------|------------|-------|-----|
| **GitHub (C√≥digo)** | Reposit√≥rio do projeto | Ilimitado (p√∫blico) | Gratuito | https://github.com/RenatoMAP77/pre-tcc |
| **Armazenamento Local** | Dados e resultados no computador | ~10-20 GB | Inclu√≠do | - |
| **Google Drive (Backup)** | Backup opcional de dados/resultados | 15 GB (free tier) | Gratuito | (opcional) |

**4. Acesso a Dados:**

| Dataset | Fonte | Acesso | Custo | Tamanho |
|---------|-------|--------|-------|---------|
| **Google Cluster Data 2019** | Kaggle | Download p√∫blico via Kaggle CLI | Gratuito | ~100 MB (sample) |
| **Alternativa** | BigQuery | Free tier (1 TB/m√™s) | Gratuito | Conforme query |

**5. Requisitos de Rede:**

- **Conex√£o √† Internet:** Necess√°ria para:
  - Download inicial do dataset (~100 MB)
  - Instala√ß√£o de bibliotecas Python (~500 MB)
  - Push/pull do reposit√≥rio GitHub
- **Largura de Banda:** M√≠nima (download √∫nico)
- **Disponibilidade:** ‚úÖ Internet dom√©stica suficiente

#### Checklist de Prepara√ß√£o de Infraestrutura:

- [x] Computador pessoal com especifica√ß√µes adequadas
- [x] Python 3.10+ instalado
- [x] Git instalado e configurado
- [x] Conta GitHub criada e reposit√≥rio criado
- [ ] Bibliotecas Python instaladas (requirements.txt)
- [ ] Conta Kaggle criada (para download do dataset)
- [ ] Dataset do Google Cluster Data 2019 baixado
- [ ] Ambiente virtual Python configurado

---

### 15.3 Materiais e Insumos

**Situa√ß√£o:** Este experimento √© **puramente computacional** e **n√£o requer materiais f√≠sicos**.

#### Materiais Digitais Necess√°rios:

**1. Dados:**

| Material | Descri√ß√£o | Fonte | Custo | Status |
|----------|-----------|-------|-------|--------|
| **Google Cluster Data 2019** | Dataset p√∫blico de traces cloud | Kaggle / BigQuery | Gratuito | üü° A ser baixado |
| **Tabelas de Precifica√ß√£o** | Pre√ßos de AWS, Azure, GCP | Sites p√∫blicos dos provedores | Gratuito | üü° A ser coletado |

**2. Scripts e C√≥digo:**

| Material | Descri√ß√£o | Respons√°vel | Status |
|----------|-----------|-------------|--------|
| **preparar_dados.py** | Script de download e pr√©-processamento | Renato | üî¥ A desenvolver |
| **executar_experimento.py** | Script principal de execu√ß√£o | Renato | üî¥ A desenvolver |
| **modelos.py** | Implementa√ß√£o dos 4 modelos | Renato | üî¥ A desenvolver |
| **analise_resultados.ipynb** | Notebook Jupyter para an√°lise | Renato | üî¥ A desenvolver |
| **requirements.txt** | Lista de depend√™ncias Python | Renato | üî¥ A desenvolver |

**3. Templates e Documentos:**

| Material | Descri√ß√£o | Status |
|----------|-----------|--------|
| **README.md (este documento)** | Plano experimental completo | ‚úÖ Em desenvolvimento |
| **Template de log** | Formato de logs de execu√ß√£o | üî¥ A criar |
| **Template de resultados.csv** | Estrutura do arquivo de resultados | üî¥ A criar |

**4. Licen√ßas de Software:**

**Todas as ferramentas utilizadas s√£o open-source e gratuitas:**
- Python: Licen√ßa PSF (Python Software Foundation)
- Bibliotecas Python: Licen√ßas BSD, MIT, Apache 2.0
- Git: Licen√ßa GPL v2
- VS Code: Licen√ßa MIT (gratuito)

**Custo Total de Licen√ßas:** **R$ 0,00**

#### Insumos N√£o Necess√°rios:

‚ùå **Equipamentos de laborat√≥rio**
‚ùå **Materiais de consumo (papel, toner, etc.)**
‚ùå **Licen√ßas de software comercial**
‚ùå **Cr√©ditos de cloud computing**
‚ùå **Dispositivos IoT ou hardware especializado**
‚ùå **Formul√°rios impressos ou question√°rios**

---

### 15.4 Or√ßamento e Custos Estimados

#### Premissa:

Este experimento foi planejado com **or√ßamento zero**, utilizando exclusivamente:
- Computador pessoal j√° dispon√≠vel
- Software open-source gratuito
- Datasets p√∫blicos gratuitos
- Infraestrutura pessoal (internet dom√©stica)

#### Planilha de Custos:

| Categoria | Item | Quantidade | Custo Unit√°rio | Custo Total | Fonte de Financiamento |
|-----------|------|------------|----------------|-------------|------------------------|
| **Recursos Humanos** | Pesquisador (Renato) | ~200h | R$ 0,00 | R$ 0,00 | Trabalho acad√™mico (n√£o remunerado) |
| | Orientador (Prof. Danilo) | ~10h | R$ 0,00 | R$ 0,00 | Atividade docente PUC Minas |
| **Infraestrutura Computacional** | Computador pessoal | 6 meses | R$ 0,00 | R$ 0,00 | Equipamento pr√≥prio |
| | Energia el√©trica (estimada) | ~50 kWh | ~R$ 0,80/kWh | ~R$ 40,00 | Despesa pessoal |
| | Internet | 6 meses | R$ 0,00 | R$ 0,00 | Internet dom√©stica existente |
| **Software e Ferramentas** | Python + bibliotecas | - | R$ 0,00 | R$ 0,00 | Open-source |
| | Git + GitHub | - | R$ 0,00 | R$ 0,00 | Gratuito (reposit√≥rio p√∫blico) |
| | IDE (VS Code / PyCharm) | - | R$ 0,00 | R$ 0,00 | Gratuito |
| **Dados** | Google Cluster Data 2019 | ~100 MB | R$ 0,00 | R$ 0,00 | Dataset p√∫blico (Kaggle) |
| **Hospedagem e Armazenamento** | GitHub (reposit√≥rio) | Ilimitado | R$ 0,00 | R$ 0,00 | Free tier (p√∫blico) |
| | Armazenamento local | ~20 GB | R$ 0,00 | R$ 0,00 | HD/SSD j√° dispon√≠vel |
| **Documenta√ß√£o** | LaTeX / Markdown (opcional) | - | R$ 0,00 | R$ 0,00 | Gratuito |
| **Outros** | Material de apresenta√ß√£o (slides) | - | R$ 0,00 | R$ 0,00 | Google Slides / PowerPoint gratuito |
| | | | **TOTAL:** | **~R$ 40,00** | Despesa pessoal (energia) |

#### An√°lise de Custos:

**Custo Direto Real:** ~R$ 40,00 (energia el√©trica estimada)
**Custo Indireto (n√£o contabilizado):** Horas de trabalho do pesquisador (~200h) e orientador (~10h)

**Fonte de Financiamento:**
- **Despesas diretas (R$ 40):** Custeadas pelo pesquisador (Renato)
- **Infraestrutura:** Equipamento pessoal e internet dom√©stica j√° dispon√≠veis
- **Software:** 100% open-source gratuito
- **Dados:** Dataset p√∫blico gratuito

#### Justificativa de Or√ßamento Zero:

Este TCC foi planejado para ser **vi√°vel sem qualquer financiamento externo**, cumprindo os seguintes crit√©rios:

1. **Uso de Recursos Pr√≥prios:**
   - Computador pessoal suficiente para processamento
   - Internet dom√©stica para download de dados e acesso a reposit√≥rios

2. **Escolha de Ferramentas Gratuitas:**
   - Python e bibliotecas cient√≠ficas (NumPy, Pandas, Scikit-learn, Statsmodels) s√£o open-source
   - GitHub oferece hospedagem gratuita para reposit√≥rios p√∫blicos

3. **Dados P√∫blicos:**
   - Google Cluster Data 2019 √© disponibilizado gratuitamente via Kaggle e BigQuery

4. **Escala Gerenci√°vel:**
   - Processamento local (n√£o requer cluster ou cloud)
   - Dataset sample (~100 MB) ao inv√©s de dataset completo (2.4 TiB)

#### Riscos Financeiros:

**Risco Identificado:** Nenhum risco financeiro cr√≠tico.

**Conting√™ncias:**
- Se computador pessoal falhar: Usar laborat√≥rios da PUC Minas (acesso gratuito)
- Se dataset Kaggle ficar indispon√≠vel: Usar BigQuery free tier (1 TB/m√™s gratuito)

---

## 16. Cronograma, Marcos e Riscos Operacionais

### 16.1 Macrocronograma (At√© o In√≠cio da Execu√ß√£o)

#### Vis√£o Geral do Projeto:

**Per√≠odo Total:** Janeiro 2025 - Dezembro 2025 (12 meses)
**Fase de Planejamento:** Janeiro - Maio 2025 (5 meses)
**Fase de Execu√ß√£o:** Junho - Julho 2025 (2 meses)
**Fase de An√°lise e Reda√ß√£o:** Agosto - Dezembro 2025 (5 meses)

#### Macrocronograma Detalhado:

| # | Marco / Fase | Descri√ß√£o | In√≠cio | Fim | Dura√ß√£o | Entrega | Status |
|---|--------------|-----------|--------|-----|---------|---------|--------|
| **1** | **Planejamento Experimental** | Desenvolvimento do plano completo | 01/01/2025 | 31/05/2025 | 5 meses | Plano experimental (este documento) | üü° Em andamento |
| 1.1 | Revis√£o bibliogr√°fica | Estudar literatura sobre previs√£o de custos cloud | 01/01/2025 | 28/02/2025 | 2 meses | - | üü° Em andamento |
| 1.2 | Defini√ß√£o de objetivos e quest√µes | Formular goal, quest√µes e m√©tricas (GQM) | 01/02/2025 | 15/02/2025 | 2 semanas | Se√ß√£o 3 do plano | ‚úÖ Conclu√≠do |
| 1.3 | Desenho experimental | Definir fatores, tratamentos, desenho | 15/02/2025 | 15/03/2025 | 1 m√™s | Se√ß√µes 8-9 do plano | ‚úÖ Conclu√≠do |
| 1.4 | Protocolo operacional | Detalhar procedimento passo a passo | 15/03/2025 | 31/03/2025 | 2 semanas | Se√ß√£o 11 do plano | ‚úÖ Conclu√≠do |
| 1.5 | Avalia√ß√£o de amea√ßas √† validade | Identificar e planejar mitiga√ß√µes | 01/04/2025 | 15/04/2025 | 2 semanas | Se√ß√£o 13 do plano | ‚úÖ Conclu√≠do |
| 1.6 | Revis√£o com orientador | Apresentar plano ao Prof. Danilo | 15/04/2025 | 30/04/2025 | 2 semanas | - | üî¥ Pendente |
| 1.7 | Ajustes no plano | Incorporar feedback do orientador | 01/05/2025 | 15/05/2025 | 2 semanas | Plano revisado | üî¥ Pendente |
| 1.8 | **Aprova√ß√£o final do plano** | ‚úÖ **MARCO** | - | 31/05/2025 | - | Plano aprovado | üî¥ Pendente |
| **2** | **Prepara√ß√£o da Infraestrutura** | Setup de ambiente e ferramentas | 01/05/2025 | 31/05/2025 | 1 m√™s | Ambiente pronto | üî¥ Pendente |
| 2.1 | Configura√ß√£o de ambiente Python | Instalar Python, bibliotecas, ambiente virtual | 01/05/2025 | 07/05/2025 | 1 semana | requirements.txt | üî¥ Pendente |
| 2.2 | Download do dataset | Obter Google Cluster Data 2019 via Kaggle | 08/05/2025 | 10/05/2025 | 3 dias | Dataset bruto | üî¥ Pendente |
| 2.3 | Desenvolvimento de scripts de prepara√ß√£o | Criar preparar_dados.py | 10/05/2025 | 20/05/2025 | 10 dias | preparar_dados.py | üî¥ Pendente |
| 2.4 | Valida√ß√£o do dataset processado | Testar qualidade dos dados preprocessados | 20/05/2025 | 25/05/2025 | 5 dias | Dataset validado | üî¥ Pendente |
| 2.5 | Desenvolvimento de modelos | Implementar RL, MM, ARIMA, ES | 01/05/2025 | 25/05/2025 | 25 dias | modelos.py | üî¥ Pendente |
| 2.6 | Testes unit√°rios dos modelos | Validar implementa√ß√µes | 25/05/2025 | 31/05/2025 | 6 dias | Testes OK | üî¥ Pendente |
| **3** | **Dry Run (Pr√©-Teste)** | Execu√ß√£o de teste com n=5 | 01/06/2025 | 05/06/2025 | 5 dias | Valida√ß√£o t√©cnica | üî¥ Pendente |
| 3.1 | Execu√ß√£o do dry run | Rodar 5 repeti√ß√µes de cada modelo | 01/06/2025 | 03/06/2025 | 3 dias | Resultados de teste | üî¥ Pendente |
| 3.2 | Valida√ß√£o de logs e outputs | Conferir formato de resultados | 03/06/2025 | 04/06/2025 | 1 dia | Logs validados | üî¥ Pendente |
| 3.3 | Ajustes finais | Corrigir bugs identificados | 04/06/2025 | 05/06/2025 | 1 dia | Scripts corrigidos | üî¥ Pendente |
| 3.4 | **Aprova√ß√£o para iniciar experimento** | ‚úÖ **MARCO** | - | 05/06/2025 | - | Go/No-Go decision | üî¥ Pendente |
| **4** | **EXECU√á√ÉO DO EXPERIMENTO** | ‚úÖ **MARCO PRINCIPAL** | 10/06/2025 | 15/07/2025 | ~1 m√™s | Resultados completos | üî¥ Pendente |
| 4.1 | Execu√ß√£o completa (120 sess√µes) | Rodar 30 rep √ó 4 modelos (~13-15h) | 10/06/2025 | 25/06/2025 | 2 semanas | resultados.csv | üî¥ Pendente |
| 4.2 | Valida√ß√£o de integridade dos dados | Conferir 120 execu√ß√µes completas | 25/06/2025 | 27/06/2025 | 2 dias | Dados validados | üî¥ Pendente |
| 4.3 | Backup de resultados | Salvar em m√∫ltiplas localiza√ß√µes | 27/06/2025 | 28/06/2025 | 1 dia | Backup completo | üî¥ Pendente |
| **5** | **An√°lise dos Resultados** | Estat√≠stica descritiva e inferencial | 01/07/2025 | 31/07/2025 | 1 m√™s | An√°lises completas | üî¥ Pendente |
| 5.1 | Estat√≠stica descritiva | M√©dia, mediana, desvio padr√£o por modelo | 01/07/2025 | 05/07/2025 | 5 dias | Tabelas descritivas | üî¥ Pendente |
| 5.2 | Visualiza√ß√µes | Boxplots, s√©ries temporais, heatmaps | 05/07/2025 | 10/07/2025 | 5 dias | Gr√°ficos | üî¥ Pendente |
| 5.3 | Testes de hip√≥teses | ANOVA/Kruskal-Wallis + post-hoc | 10/07/2025 | 15/07/2025 | 5 dias | Resultados estat√≠sticos | üî¥ Pendente |
| 5.4 | An√°lise de correla√ß√£o | M√©tricas vs. custos | 15/07/2025 | 20/07/2025 | 5 dias | Matriz de correla√ß√£o | üî¥ Pendente |
| 5.5 | Interpreta√ß√£o e s√≠ntese | Responder quest√µes de pesquisa | 20/07/2025 | 31/07/2025 | 11 dias | Respostas √†s QPs | üî¥ Pendente |
| **6** | **Reda√ß√£o do TCC** | Documento final do trabalho | 01/08/2025 | 30/11/2025 | 4 meses | TCC completo | üî¥ Pendente |
| 6.1 | Introdu√ß√£o e referencial te√≥rico | Cap. 1-2 | 01/08/2025 | 31/08/2025 | 1 m√™s | - | üî¥ Pendente |
| 6.2 | Metodologia | Cap. 3 | 01/09/2025 | 20/09/2025 | 3 semanas | - | üî¥ Pendente |
| 6.3 | Resultados | Cap. 4 | 20/09/2025 | 15/10/2025 | ~4 semanas | - | üî¥ Pendente |
| 6.4 | Discuss√£o e conclus√£o | Cap. 5-6 | 15/10/2025 | 31/10/2025 | 2 semanas | - | üî¥ Pendente |
| 6.5 | Revis√£o e formata√ß√£o | Normas ABNT, revis√£o ortogr√°fica | 01/11/2025 | 20/11/2025 | 3 semanas | - | üî¥ Pendente |
| 6.6 | Revis√£o final com orientador | Incorporar feedback | 20/11/2025 | 30/11/2025 | 10 dias | - | üî¥ Pendente |
| 6.7 | **Entrega do TCC** | ‚úÖ **MARCO FINAL** | - | 05/12/2025 | - | TCC entregue | üî¥ Pendente |
| **7** | **Defesa do TCC** | Apresenta√ß√£o perante banca | 15/12/2025 | 20/12/2025 | 1 semana | Defesa realizada | üî¥ Pendente |

#### Marcos Cr√≠ticos (Critical Path):

```
üìÖ 31/05/2025: Aprova√ß√£o do Plano Experimental
       ‚Üì
üìÖ 05/06/2025: Go/No-Go para Executar Experimento
       ‚Üì
üìÖ 10-25/06/2025: Execu√ß√£o Completa do Experimento (120 sess√µes)
       ‚Üì
üìÖ 31/07/2025: An√°lise de Resultados Conclu√≠da
       ‚Üì
üìÖ 05/12/2025: Entrega do TCC
       ‚Üì
üìÖ 15-20/12/2025: Defesa do TCC
```

#### Gr√°fico de Gantt Simplificado:

```
2025     | Jan | Fev | Mar | Abr | Mai | Jun | Jul | Ago | Set | Out | Nov | Dez |
---------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|
Planejamento | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà |     |     |     |     |     |     |
Infraestrutura |     |     |     | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà |     |     |     |     |     |     |
Dry Run      |     |     |     |     | ‚ñà‚ñà  |     |     |     |     |     |     |     |
EXECU√á√ÉO     |     |     |     |     |     | ‚ñà‚ñà‚ñà‚ñà|     |     |     |     |     |     |
An√°lise      |     |     |     |     |     |     | ‚ñà‚ñà‚ñà‚ñà|     |     |     |     |     |
Reda√ß√£o TCC  |     |     |     |     |     |     |     | ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà |     |
Defesa       |     |     |     |     |     |     |     |     |     |     |     | ‚ñà‚ñà  |
```

---

### 16.2 Depend√™ncias entre Atividades

#### Mapa de Depend√™ncias Cr√≠ticas:

```mermaid
graph TD
    A[Plano Experimental Completo] --> B[Aprova√ß√£o do Orientador]
    B --> C[Setup de Ambiente Python]
    B --> D[Download do Dataset]
    C --> E[Desenvolvimento de Scripts]
    D --> E
    E --> F[Valida√ß√£o de Scripts - Dry Run]
    F --> G{Go/No-Go?}
    G -->|Go| H[EXECU√á√ÉO DO EXPERIMENTO]
    G -->|No-Go| E
    H --> I[Valida√ß√£o de Integridade]
    I --> J[Backup de Resultados]
    J --> K[An√°lise Estat√≠stica]
    K --> L[Reda√ß√£o do TCC]
    L --> M[Revis√£o do Orientador]
    M --> N[Entrega Final]
    N --> O[Defesa do TCC]
```

#### Tabela de Depend√™ncias:

| Atividade | Depende De | Tipo de Depend√™ncia | Impacto se Atrasar |
|-----------|------------|---------------------|-------------------|
| **Aprova√ß√£o do Plano** | Conclus√£o do plano | Finish-to-Start (FS) | ‚ö†Ô∏è Cr√≠tico - Bloqueia tudo |
| **Setup de Ambiente** | Aprova√ß√£o do plano | FS | ‚ö†Ô∏è Cr√≠tico - Bloqueia execu√ß√£o |
| **Download Dataset** | Aprova√ß√£o do plano | FS | ‚ö†Ô∏è Cr√≠tico - Bloqueia execu√ß√£o |
| **Desenvolvimento de Scripts** | Setup + Dataset | FS (ambos) | ‚ö†Ô∏è Cr√≠tico - Bloqueia execu√ß√£o |
| **Dry Run** | Scripts prontos | FS | ‚ö†Ô∏è Cr√≠tico - Valida viabilidade |
| **Execu√ß√£o do Experimento** | Dry Run OK (Go decision) | FS | üî¥ **Cr√≠tico - Caminho cr√≠tico** |
| **An√°lise de Resultados** | Execu√ß√£o completa + valida√ß√£o | FS | üî¥ **Cr√≠tico - Caminho cr√≠tico** |
| **Reda√ß√£o do TCC** | An√°lise conclu√≠da | FS | üî¥ **Cr√≠tico - Caminho cr√≠tico** |
| **Revis√£o do Orientador** | Reda√ß√£o completa | FS | ‚ö†Ô∏è Cr√≠tico - Aprova√ß√£o final |
| **Entrega do TCC** | Revis√£o OK | FS | üî¥ **Cr√≠tico - Data fixa (05/12)** |
| **Defesa** | Entrega do TCC | FS | üî¥ **Cr√≠tico - Data fixa** |

#### Depend√™ncias N√£o-Cr√≠ticas (Podem ser Paralelizadas):

- **Revis√£o Bibliogr√°fica** pode ocorrer em paralelo com desenvolvimento de scripts
- **Reda√ß√£o de Introdu√ß√£o e Referencial Te√≥rico** pode iniciar antes da execu√ß√£o
- **Desenvolvimento de modelos** pode iniciar em paralelo ao processamento de dados

#### Estrat√©gia de Gest√£o de Depend√™ncias:

1. **Priorizar Caminho Cr√≠tico:**
   - Focar em atividades que bloqueiam outras
   - Evitar atrasos em: Aprova√ß√£o ‚Üí Scripts ‚Üí Dry Run ‚Üí Execu√ß√£o ‚Üí An√°lise ‚Üí Reda√ß√£o

2. **Paraleliza√ß√£o quando Poss√≠vel:**
   - Iniciar revis√£o bibliogr√°fica desde j√°
   - Desenvolver modelos enquanto dataset √© preparado

3. **Buffers de Tempo:**
   - Adicionar 1-2 semanas de buffer antes da entrega final (05/12)
   - Antecipar revis√£o com orientador para ter tempo de ajustes

---

### 16.3 Riscos Operacionais e Plano de Conting√™ncia

#### Classifica√ß√£o de Riscos:

| ID | Risco | Probabilidade | Impacto | Severidade | Categoria |
|----|-------|---------------|---------|------------|-----------|
| **R1** | Atraso na aprova√ß√£o do plano pelo orientador | üü° M√©dia | üî¥ Alto | üî¥ **ALTO** | Cronograma |
| **R2** | Falha de hardware (computador pessoal) | üü¢ Baixa | üî¥ Alto | üü° **M√âDIO** | Infraestrutura |
| **R3** | Dataset indispon√≠vel ou corrompido | üü¢ Baixa | üî¥ Alto | üü° **M√âDIO** | Dados |
| **R4** | Experimento leva mais tempo que o estimado (>15h) | üü° M√©dia | üü° M√©dio | üü° **M√âDIO** | Execu√ß√£o |
| **R5** | Bugs cr√≠ticos nos scripts durante execu√ß√£o | üü° M√©dia | üî¥ Alto | üî¥ **ALTO** | C√≥digo |
| **R6** | Resultados n√£o mostram diferen√ßas significativas | üü° M√©dia | üü° M√©dio | üü° **M√âDIO** | Resultados |
| **R7** | Indisponibilidade do orientador em per√≠odos cr√≠ticos | üü° M√©dia | üü° M√©dio | üü° **M√âDIO** | Recursos Humanos |
| **R8** | Escopo cresce al√©m do planejado (scope creep) | üü° M√©dia | üü° M√©dio | üü° **M√âDIO** | Escopo |
| **R9** | Problemas de sa√∫de do pesquisador | üü¢ Baixa | üî¥ Alto | üü° **M√âDIO** | Pessoal |
| **R10** | Mudan√ßa de requisitos da universidade (normas TCC) | üü¢ Baixa | üü° M√©dio | üü¢ **BAIXO** | Regulat√≥rio |

#### Planos de Conting√™ncia Detalhados:

---

**R1: Atraso na aprova√ß√£o do plano pelo orientador**

**Descri√ß√£o:** Orientador demora para revisar ou solicita mudan√ßas significativas no plano, atrasando in√≠cio da execu√ß√£o.

**Probabilidade:** üü° M√©dia (30-40%)
**Impacto:** üî¥ Alto (atrasa todo cronograma)
**Severidade:** üî¥ **ALTO**

**Mitiga√ß√£o Preventiva:**
- ‚úÖ Enviar vers√µes parciais do plano ao longo do desenvolvimento
- ‚úÖ Agendar reuni√µes peri√≥dicas quinzenais para alinhamento
- ‚úÖ Explicitar pontos que precisam de valida√ß√£o urgente

**Plano de Conting√™ncia:**
1. Se atraso < 2 semanas: Ajustar cronograma, reduzir tempo de revis√£o bibliogr√°fica
2. Se atraso > 2 semanas: Escalar para coordena√ß√£o ou considerar adiar entrega

**Respons√°vel:** Renato

---

**R2-R10:** *(Planos detalhados de conting√™ncia para cada risco conforme se√ß√£o 16.3)*

#### Matriz de Riscos:

```
          IMPACTO
          Baixo   M√©dio    Alto
        |-------|--------|--------|
Baixa   |       |  R10   | R2,R3  |
PROB.   |-------|--------|--------|
M√©dia   |       | R4,R6  | R1,R5  |
        |       | R7,R8  |        |
        |-------|--------|--------|
```

**Legenda:**
- üî¥ **Risco Alto:** Monitoramento ativo e plano de a√ß√£o detalhado
- üü° **Risco M√©dio:** Monitorar periodicamente
- üü¢ **Risco Baixo:** Aceit√°vel, mitiga√ß√£o m√≠nima

---

## 17. Governan√ßa do Experimento

### 17.1 Pap√©is e Responsabilidades Formais

#### Estrutura de Governan√ßa:

| Papel | Pessoa | Responsabilidade | Autoridade |
|-------|--------|------------------|------------|
| **Pesquisador / Executor** | Renato Matos Alves Penna | - Executar todas as atividades do experimento<br>- Tomar decis√µes operacionais cotidianas<br>- Propor mudan√ßas no plano<br>- Documentar e reportar progresso | **Decide:** Detalhes t√©cnicos de implementa√ß√£o<br>**Prop√µe:** Mudan√ßas no plano experimental |
| **Orientador / Revisor** | Prof. Danilo de Quadros Maia Filho | - Revisar e aprovar o plano experimental<br>- Validar metodologia cient√≠fica<br>- Aprovar mudan√ßas significativas<br>- Autorizar entrega final | **Decide:** Aprova√ß√£o do plano e mudan√ßas<br>**Aprova:** Entregas e conclus√£o |
| **Coordena√ß√£o do TCC** | Coordenador de TCC (PUC Minas) | - Validar conformidade com normas<br>- Aprovar tema e orientador<br>- Designar banca examinadora | **Decide:** Conformidade administrativa<br>**Aprova:** Defesa e conclus√£o |
| **Banca Examinadora** | Professores designados pela coordena√ß√£o | - Avaliar o trabalho final<br>- Fazer recomenda√ß√µes<br>- Aprovar/reprovar a defesa | **Decide:** Aprova√ß√£o final do TCC |

#### Matriz RACI (Resumida):

| Atividade | Renato | Orientador | Coordena√ß√£o | Banca |
|-----------|--------|------------|-------------|-------|
| **Planejamento Experimental** | R, A | C, A | I | - |
| **Implementa√ß√£o de Scripts** | R, A | I | - | - |
| **Execu√ß√£o do Experimento** | R, A | I | - | - |
| **An√°lise de Resultados** | R, A | C | - | - |
| **Reda√ß√£o do TCC** | R, A | C, A | I | - |
| **Aprova√ß√£o de Mudan√ßas** | R | A | I | - |
| **Entrega Final** | R | A | C | - |
| **Defesa do TCC** | R | C | I | A |

**Legenda:**
- **R (Responsible):** Executante respons√°vel pela atividade
- **A (Accountable):** Autoridade final que aprova
- **C (Consulted):** Consultado antes de decis√µes
- **I (Informed):** Informado ap√≥s decis√µes

#### Fluxo de Decis√£o:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Decis√£o Necess√°ria                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ Tipo de       ‚îÇ
       ‚îÇ Decis√£o?      ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ       ‚îÇ
    Operacional   Estrat√©gica
           ‚îÇ       ‚îÇ
           ‚ñº       ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ Renato  ‚îÇ  ‚îÇ Proposta para  ‚îÇ
     ‚îÇ Decide  ‚îÇ  ‚îÇ Orientador     ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ            ‚îÇ
          ‚îÇ            ‚ñº
          ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ      ‚îÇ Orientador    ‚îÇ
          ‚îÇ      ‚îÇ Aprova?       ‚îÇ
          ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ         Sim   N√£o
          ‚îÇ          ‚îÇ    ‚îÇ
          ‚îÇ          ‚îÇ    ‚ñº
          ‚îÇ          ‚îÇ  Ajustar Proposta
          ‚îÇ          ‚îÇ    ‚îÇ
          ‚îÇ          ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ          ‚îÇ
          ‚ñº          ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ  Decis√£o Executada ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Exemplos de Decis√µes por Tipo:

**Decis√µes Operacionais (Renato decide):**
- Qual IDE usar (VS Code, PyCharm, etc.)
- Como nomear vari√°veis no c√≥digo
- Quando executar o experimento (hor√°rio/dia)
- Formato de visualiza√ß√µes espec√≠ficas

**Decis√µes Estrat√©gicas (Orientador aprova):**
- Mudan√ßas no desenho experimental
- Adi√ß√£o/remo√ß√£o de modelos ou m√©tricas
- Mudan√ßas no escopo do estudo
- Altera√ß√µes significativas no cronograma

**Decis√µes Administrativas (Coordena√ß√£o aprova):**
- Mudan√ßa de orientador
- Prorroga√ß√£o de prazo al√©m do semestre
- Conformidade com normas da universidade

---

### 17.2 Ritos de Acompanhamento Pr√©-Execu√ß√£o

#### Reuni√µes e Checkpoints Planejados:

| # | Rito | Frequ√™ncia | Participantes | Objetivo | Dura√ß√£o | Formato |
|---|------|------------|---------------|----------|---------|---------|
| **1** | **Reuni√£o de Alinhamento Quinzenal** | A cada 15 dias | Renato + Orientador | - Reportar progresso<br>- Discutir d√∫vidas<br>- Alinhar pr√≥ximos passos | 30-60 min | Presencial ou virtual |
| **2** | **Revis√£o de Marco (Checkpoint)** | Em marcos cr√≠ticos | Renato + Orientador | - Apresentar entrega<br>- Obter aprova√ß√£o formal<br>- Ajustar plano (se necess√°rio) | 60-90 min | Presencial (preferencial) |
| **3** | **E-mail de Status Semanal** | Semanalmente | Renato ‚Üí Orientador | - Atualizar status de atividades<br>- Reportar riscos/bloqueios<br>- Solicitar feedback ass√≠ncrono | - | E-mail |
| **4** | **Go/No-Go Review** | Antes da execu√ß√£o (05/06) | Renato + Orientador | - Validar prontid√£o para executar<br>- Decis√£o formal de iniciar<br>- Confirmar recursos e prepara√ß√£o | 60 min | Presencial |

#### Detalhamento dos Ritos:

---

**Rito 1: Reuni√£o de Alinhamento Quinzenal**

**Objetivo:** Manter orientador informado e obter feedback cont√≠nuo.

**Agenda Sugerida:**
1. **Progresso desde √∫ltima reuni√£o** (10 min)
   - O que foi feito
   - Dificuldades encontradas

2. **Revis√£o de artefatos/c√≥digo** (15 min)
   - Demonstrar c√≥digo desenvolvido (se aplic√°vel)
   - Mostrar an√°lises preliminares

3. **D√∫vidas e consultoria** (15 min)
   - Esclarecer quest√µes metodol√≥gicas
   - Validar decis√µes t√©cnicas

4. **Pr√≥ximos passos** (10 min)
   - Definir atividades at√© pr√≥xima reuni√£o
   - Identificar depend√™ncias do orientador

5. **Riscos e bloqueios** (10 min)
   - Reportar riscos identificados
   - Solicitar ajuda se necess√°rio

**Outputs:**
- Ata de reuni√£o (e-mail resumo)
- Lista de a√ß√µes e respons√°veis
- Data da pr√≥xima reuni√£o

---

**Rito 2: Revis√£o de Marco (Checkpoint)**

**Marcos Previstos:**

| Marco | Data Prevista | Entrega Esperada | Crit√©rio de Aprova√ß√£o |
|-------|---------------|------------------|----------------------|
| **M1: Plano Aprovado** | 31/05/2025 | Plano experimental completo | Orientador aprova metodologia e escopo |
| **M2: Infraestrutura Pronta** | 31/05/2025 | - Ambiente configurado<br>- Dataset baixado<br>- Scripts b√°sicos funcionais | Dry run executado com sucesso |
| **M3: Experimento Conclu√≠do** | 27/06/2025 | - 120 execu√ß√µes completas<br>- Resultados validados<br>- Backup feito | Dados √≠ntegros e prontos para an√°lise |
| **M4: An√°lise Finalizada** | 31/07/2025 | - An√°lises estat√≠sticas<br>- Gr√°ficos<br>- Respostas √†s QPs | Resultados interpretados e consistentes |
| **M5: TCC Rascunho** | 31/10/2025 | Primeira vers√£o completa do TCC | Orientador revisa e d√° feedback |
| **M6: TCC Final** | 30/11/2025 | Vers√£o final revisada | Orientador aprova para entrega |

**Formato da Revis√£o:**
- Apresenta√ß√£o formal pelo pesquisador (slides ou documento)
- Demonstra√ß√£o de artefatos (c√≥digo, dados, an√°lises)
- Checklist de prontid√£o/completude
- Decis√£o de aprova√ß√£o ou solicita√ß√£o de ajustes

---

**Rito 3: E-mail de Status Semanal**

**Template de E-mail:**

```
Assunto: [TCC] Status Semanal - Semana XX/2025

Prof. Danilo,

Segue atualiza√ß√£o semanal do TCC:

‚úÖ REALIZADAS ESTA SEMANA:
- [Lista de atividades conclu√≠das]

üöß EM ANDAMENTO:
- [Atividades atuais]

üìÖ PR√ìXIMAS ATIVIDADES:
- [Planejado para pr√≥xima semana]

‚ö†Ô∏è RISCOS/BLOQUEIOS:
- [Se houver, descrever]

‚ùì D√öVIDAS/NECESSIDADES:
- [Se houver, perguntas espec√≠ficas]

Att,
Renato
```

**Frequ√™ncia:** Toda segunda-feira (ou dia combinado)

---

**Rito 4: Go/No-Go Review**

**Data:** 05/06/2025 (antes da execu√ß√£o)

**Objetivo:** Decis√£o formal de iniciar a execu√ß√£o do experimento.

**Checklist de Prontid√£o (ver Se√ß√£o 20):**
- [ ] Plano experimental aprovado
- [ ] Scripts desenvolvidos e testados
- [ ] Dataset baixado e validado
- [ ] Dry run executado com sucesso (n=5)
- [ ] Ambiente funcional
- [ ] Backups configurados
- [ ] Seeds preparados

**Resultado:** **GO** (autoriza execu√ß√£o) ou **NO-GO** (ajustes necess√°rios)

---

### 17.3 Processo de Controle de Mudan√ßas no Plano

#### Pol√≠tica de Mudan√ßas:

**Princ√≠pio:** O plano experimental √© um documento vivo, mas mudan√ßas devem ser **controladas e documentadas**.

#### Classifica√ß√£o de Mudan√ßas:

| Tipo | Exemplos | Aprova√ß√£o Necess√°ria | Processo |
|------|----------|---------------------|----------|
| **Mudan√ßa Trivial** | - Corre√ß√£o de typo<br>- Ajuste de formata√ß√£o<br>- Clarifica√ß√£o de texto | ‚ùå N√£o | Executar diretamente |
| **Mudan√ßa Menor** | - Ajuste de cronograma interno (< 1 semana)<br>- Mudan√ßa de ferramenta (ex: IDE)<br>- Ajuste de visualiza√ß√µes | üü° Informal (e-mail) | Informar orientador por e-mail |
| **Mudan√ßa M√©dia** | - Ajuste de hiperpar√¢metros<br>- Mudan√ßa de m√©todo de valida√ß√£o cruzada<br>- Adi√ß√£o de m√©trica secund√°ria | üü† Formal | Reuni√£o + aprova√ß√£o por escrito |
| **Mudan√ßa Significativa** | - Mudan√ßa no desenho experimental<br>- Adi√ß√£o/remo√ß√£o de modelos<br>- Mudan√ßa no escopo (objetivos, QPs)<br>- Atraso > 2 semanas | üî¥ Cr√≠tica | Reuni√£o + revis√£o de viabilidade + aprova√ß√£o formal |

#### Fluxo de Controle de Mudan√ßas:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Necessidade de Mudan√ßa         ‚îÇ
‚îÇ  Identificada                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ Classificar   ‚îÇ
       ‚îÇ Tipo de       ‚îÇ
       ‚îÇ Mudan√ßa       ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ       ‚îÇ
    Trivial/Menor  M√©dia/Significativa
           ‚îÇ       ‚îÇ
           ‚ñº       ‚ñº
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ Executar‚îÇ  ‚îÇ Preparar       ‚îÇ
     ‚îÇ ou      ‚îÇ  ‚îÇ Proposta de    ‚îÇ
     ‚îÇ Informar‚îÇ  ‚îÇ Mudan√ßa        ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ            ‚îÇ
          ‚îÇ            ‚ñº
          ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ      ‚îÇ Apresentar ao ‚îÇ
          ‚îÇ      ‚îÇ Orientador    ‚îÇ
          ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ          ‚îÇ
          ‚îÇ          ‚ñº
          ‚îÇ      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
          ‚îÇ      ‚îÇ Orientador    ‚îÇ
          ‚îÇ      ‚îÇ Aprova?       ‚îÇ
          ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ         Sim   N√£o
          ‚îÇ          ‚îÇ    ‚îÇ
          ‚îÇ          ‚îÇ    ‚ñº
          ‚îÇ          ‚îÇ  Revisar ou Rejeitar
          ‚îÇ          ‚îÇ    ‚îÇ
          ‚îÇ          ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ          ‚îÇ
          ‚ñº          ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ  Atualizar Plano   ‚îÇ
      ‚îÇ  (controle vers√£o) ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ  Comunicar Mudan√ßa ‚îÇ
      ‚îÇ  (se necess√°rio)   ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Template de Proposta de Mudan√ßa:

**Para mudan√ßas M√©dias e Significativas:**

```markdown
## Proposta de Mudan√ßa no Plano Experimental

**Data:** [DD/MM/YYYY]
**Proponente:** Renato Matos Alves Penna
**Classifica√ß√£o:** [ ] M√©dia  [ ] Significativa

### 1. Descri√ß√£o da Mudan√ßa Proposta:
[Descrever claramente o que ser√° mudado]

### 2. Justificativa:
[Por que a mudan√ßa √© necess√°ria?]

### 3. Impacto:
- **Escopo:** [Afeta objetivos, QPs, escopo?]
- **Cronograma:** [Adiciona/remove tempo? Quanto?]
- **Qualidade/Validade:** [Impacta validade dos resultados?]
- **Recursos:** [Requer recursos adicionais?]

### 4. Alternativas Consideradas:
[Outras op√ß√µes avaliadas e por que foram descartadas]

### 5. Decis√£o Solicitada:
[ ] Aprovar
[ ] Aprovar com ajustes
[ ] Rejeitar

### 6. Aprova√ß√£o:
**Orientador:** _______________________
**Data:** ___ /___ /______
```

#### Registro de Mudan√ßas:

**Todas as mudan√ßas aprovadas ser√£o documentadas no hist√≥rico de revis√£o do documento (Se√ß√£o 1.3).**

---

## 18. Plano de Documenta√ß√£o e Reprodutibilidade

### 18.1 Reposit√≥rios e Conven√ß√µes de Nomea√ß√£o

#### Reposit√≥rio Principal:

**GitHub:** https://github.com/RenatoMAP77/pre-tcc

**Tipo:** Reposit√≥rio p√∫blico
**Licen√ßa:** MIT License (para c√≥digo) + CC-BY (para documenta√ß√£o)

#### Estrutura de Diret√≥rios:

```
pre-tcc/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # Este plano experimental
‚îú‚îÄ‚îÄ LICENSE                            # Licen√ßa MIT
‚îú‚îÄ‚îÄ requirements.txt                   # Depend√™ncias Python
‚îú‚îÄ‚îÄ .gitignore                         # Arquivos ignorados pelo Git
‚îÇ
‚îú‚îÄ‚îÄ data/                              # Dados (n√£o versionados se > 100MB)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           # Dados brutos do Google Cluster
‚îÇ   ‚îú‚îÄ‚îÄ processed/                     # Dados processados/agregados
‚îÇ   ‚îî‚îÄ‚îÄ README.md                      # Descri√ß√£o dos dados
‚îÇ
‚îú‚îÄ‚îÄ src/                               # C√≥digo-fonte
‚îÇ   ‚îú‚îÄ‚îÄ preparar_dados.py              # Script de prepara√ß√£o de dados
‚îÇ   ‚îú‚îÄ‚îÄ modelos.py                     # Implementa√ß√£o dos modelos
‚îÇ   ‚îú‚îÄ‚îÄ executar_experimento.py       # Script principal de execu√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ utils.py                       # Fun√ß√µes auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py                    # Pacote Python
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                         # Jupyter Notebooks
‚îÇ   ‚îú‚îÄ‚îÄ 01_exploracao_dados.ipynb     # An√°lise explorat√≥ria
‚îÇ   ‚îú‚îÄ‚îÄ 02_validacao_preparacao.ipynb # Valida√ß√£o do pr√©-processamento
‚îÇ   ‚îî‚îÄ‚îÄ 03_analise_resultados.ipynb   # An√°lise estat√≠stica final
‚îÇ
‚îú‚îÄ‚îÄ results/                           # Resultados do experimento
‚îÇ   ‚îú‚îÄ‚îÄ raw/                           # Resultados brutos (CSV)
‚îÇ   ‚îú‚îÄ‚îÄ figures/                       # Gr√°ficos e visualiza√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ tables/                        # Tabelas formatadas
‚îÇ   ‚îî‚îÄ‚îÄ README.md                      # Descri√ß√£o dos resultados
‚îÇ
‚îú‚îÄ‚îÄ logs/                              # Logs de execu√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ experimento.log                # Log principal
‚îÇ   ‚îî‚îÄ‚îÄ [timestamp]_exec.log          # Logs individuais
‚îÇ
‚îú‚îÄ‚îÄ config/                            # Configura√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ seeds.txt                      # Seeds aleat√≥rios (30)
‚îÇ   ‚îî‚îÄ‚îÄ parametros.yaml                # Par√¢metros configur√°veis
‚îÇ
‚îú‚îÄ‚îÄ docs/                              # Documenta√ß√£o adicional
‚îÇ   ‚îú‚îÄ‚îÄ plano_experimental.md          # C√≥pia do README (backup)
‚îÇ   ‚îî‚îÄ‚îÄ manual_reproducao.md           # Guia de reprodu√ß√£o
‚îÇ
‚îî‚îÄ‚îÄ tests/                             # Testes unit√°rios (opcional)
    ‚îú‚îÄ‚îÄ test_preparar_dados.py
    ‚îî‚îÄ‚îÄ test_modelos.py
```

#### Conven√ß√µes de Nomea√ß√£o:

**1. Arquivos de C√≥digo Python:**
- **Formato:** `snake_case.py`
- **Exemplos:** `preparar_dados.py`, `executar_experimento.py`

**2. Notebooks Jupyter:**
- **Formato:** `NN_descricao_clara.ipynb`
- **Exemplos:** `01_exploracao_dados.ipynb`, `03_analise_resultados.ipynb`
- **Numera√ß√£o:** 01, 02, 03... (ordem de execu√ß√£o)

**3. Arquivos de Dados:**
- **Dados brutos:** `google_cluster_raw.csv` (nome descritivo original)
- **Dados processados:** `dataset_processado_YYYY-MM-DD.csv` (com data)
- **Resultados:** `resultados_experimento_YYYY-MM-DD.csv`

**4. Gr√°ficos e Visualiza√ß√µes:**
- **Formato:** `fig_NN_descricao.png` ou `.pdf`
- **Exemplos:** `fig_01_boxplot_mae_por_modelo.png`, `fig_02_series_temporais.pdf`

**5. Logs:**
- **Formato:** `YYYY-MM-DD_HH-MM-SS_nome.log`
- **Exemplo:** `2025-06-10_14-30-00_execucao_completa.log`

**6. Branches Git (se usar):**
- `main` ou `master`: Branch principal (c√≥digo est√°vel)
- `develop`: Branch de desenvolvimento
- `feature/nome-feature`: Para features espec√≠ficas
- `fix/nome-bug`: Para corre√ß√µes de bugs

**7. Commits Git:**
- **Formato:** `tipo: descri√ß√£o concisa`
- **Tipos:** `feat:`, `fix:`, `docs:`, `refactor:`, `test:`, `chore:`
- **Exemplos:**
  - `feat: adiciona implementa√ß√£o do modelo ARIMA`
  - `fix: corrige divis√£o treino/teste em TimeSeriesSplit`
  - `docs: atualiza README com se√ß√µes 14-20`

---

### 18.2 Templates e Artefatos Padr√£o

#### Templates de C√≥digo:

**1. Template de Script Python:**

```python
#!/usr/bin/env python3
"""
T√≠tulo: [Nome do Script]
Descri√ß√£o: [Breve descri√ß√£o do prop√≥sito]
Autor: Renato Matos Alves Penna
Data: YYYY-MM-DD
TCC: Previs√£o de Custos Cloud - PUC Minas
"""

import pandas as pd
import numpy as np
# [Outras importa√ß√µes]

# Configura√ß√µes
SEED = 42  # Seed para reprodutibilidade
np.random.seed(SEED)

def funcao_principal():
    """
    Descri√ß√£o da fun√ß√£o.

    Args:
        param1 (tipo): Descri√ß√£o

    Returns:
        tipo: Descri√ß√£o do retorno
    """
    # Implementa√ß√£o
    pass

if __name__ == "__main__":
    # Executar quando script for chamado diretamente
    funcao_principal()
```

**2. Template de Notebook Jupyter:**

```markdown
# [T√≠tulo do Notebook]

**Autor:** Renato Matos Alves Penna
**Data:** YYYY-MM-DD
**Objetivo:** [Descri√ß√£o breve do objetivo]

---

## 1. Setup e Importa√ß√µes

## 2. Carregamento de Dados

## 3. An√°lise Explorat√≥ria

## 4. Processamento/Modelagem

## 5. Resultados e Visualiza√ß√µes

## 6. Conclus√µes

---

**Pr√≥ximos Passos:**
- [Lista de a√ß√µes]
```

**3. Template de Arquivo de Resultados (CSV):**

```
execucao_id,modelo,repeticao,seed,mae,rmse,mape,tempo_exec_s,fold,mae_fold
1,RL,1,1234,150.23,175.45,12.34,5.2,1,148.12
1,RL,1,1234,150.23,175.45,12.34,5.2,2,152.34
...
```

**Estrutura:**
- `execucao_id`: ID √∫nico da execu√ß√£o (1-120)
- `modelo`: Sigla do modelo (RL, MM, ARIMA, ES)
- `repeticao`: N√∫mero da repeti√ß√£o (1-30)
- `seed`: Seed usado para essa repeti√ß√£o
- `mae, rmse, mape`: M√©tricas principais (holdout)
- `tempo_exec_s`: Tempo de execu√ß√£o em segundos
- `fold`: Fold da valida√ß√£o cruzada (1-5)
- `mae_fold`: MAE no fold espec√≠fico

**4. Template de Log:**

```
[YYYY-MM-DD HH:MM:SS] [INFO] In√≠cio da execu√ß√£o
[YYYY-MM-DD HH:MM:SS] [INFO] Carregando dados de: data/processed/dataset.csv
[YYYY-MM-DD HH:MM:SS] [INFO] Dataset carregado: 720 observa√ß√µes
[YYYY-MM-DD HH:MM:SS] [INFO] Iniciando repeti√ß√£o 1/30 com seed 1234
[YYYY-MM-DD HH:MM:SS] [INFO] Treinando modelo: RL
[YYYY-MM-DD HH:MM:SS] [INFO] MAE (holdout): 150.23
[YYYY-MM-DD HH:MM:SS] [INFO] Valida√ß√£o cruzada (5-fold): MAE m√©dio = 151.45
[YYYY-MM-DD HH:MM:SS] [WARNING] Tempo de execu√ß√£o ARIMA maior que esperado: 350s
[YYYY-MM-DD HH:MM:SS] [ERROR] Erro ao processar modelo: [descri√ß√£o do erro]
[YYYY-MM-DD HH:MM:SS] [INFO] Fim da execu√ß√£o. Tempo total: 45min
```

**N√≠veis de Log:**
- `DEBUG`: Informa√ß√µes detalhadas para debugging
- `INFO`: Informa√ß√µes gerais de progresso
- `WARNING`: Avisos (n√£o bloqueiam execu√ß√£o)
- `ERROR`: Erros (podem bloquear execu√ß√£o)
- `CRITICAL`: Erros cr√≠ticos (interrompem execu√ß√£o)

---

### 18.3 Plano de Empacotamento para Replica√ß√£o Futura

#### Objetivo:

Permitir que qualquer pesquisador (incluindo o autor no futuro) possa **reproduzir completamente** o experimento.

#### Pacote de Reprodu√ß√£o:

**O que ser√° inclu√≠do no reposit√≥rio GitHub:**

1. **C√≥digo-fonte completo:**
   - Todos os scripts Python (`src/`)
   - Notebooks Jupyter (`notebooks/`)
   - Testes (se houver)

2. **Documenta√ß√£o:**
   - `README.md` (plano experimental completo)
   - `docs/manual_reproducao.md` (passo a passo para reproduzir)
   - Coment√°rios inline no c√≥digo

3. **Configura√ß√µes:**
   - `requirements.txt` (depend√™ncias Python com vers√µes fixas)
   - `config/seeds.txt` (seeds exatos usados)
   - `config/parametros.yaml` (par√¢metros configur√°veis)

4. **Dados (se poss√≠vel):**
   - **Dados processados:** `data/processed/dataset_processado.csv` (se < 100MB)
   - **Se > 100MB:** Link para download externo + script de download
   - **Dados de resultados:** `results/raw/resultados_completos.csv`

5. **Metadados:**
   - Vers√£o de Python usada: `python --version`
   - Vers√µes de bibliotecas: `pip freeze > requirements.txt`
   - Sistema operacional: `uname -a` (Linux/Mac) ou `systeminfo` (Windows)
   - Data e hora da execu√ß√£o

6. **Licen√ßa:**
   - `LICENSE` (MIT para c√≥digo, CC-BY para documenta√ß√£o)

#### Manual de Reprodu√ß√£o (docs/manual_reproducao.md):

**Template:**

```markdown
# Manual de Reprodu√ß√£o do Experimento

## Pr√©-requisitos

- Python 3.10 ou superior
- Git
- Conta Kaggle (para download do dataset)
- ~10 GB de espa√ßo livre em disco
- ~16 GB de RAM (recomendado)

## Passo 1: Clonar o Reposit√≥rio

```bash
git clone https://github.com/RenatoMAP77/pre-tcc.git
cd pre-tcc
```

## Passo 2: Criar Ambiente Virtual

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

## Passo 3: Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

## Passo 4: Baixar Dados (se necess√°rio)

```bash
# Op√ß√£o A: Kaggle CLI
kaggle datasets download -d derrickmwiti/google-2019-cluster-sample
unzip google-2019-cluster-sample.zip -d data/raw/

# Op√ß√£o B: Usar dados processados inclu√≠dos
# (Se dataset processado estiver no reposit√≥rio, pular este passo)
```

## Passo 5: Preparar Dados

```bash
python src/preparar_dados.py
```

**Output esperado:** `data/processed/dataset_processado.csv` (~720 linhas)

## Passo 6: Executar Experimento

```bash
python src/executar_experimento.py
```

**Tempo estimado:** ~13-15 horas
**Output esperado:** `results/raw/resultados_experimento_[data].csv`

## Passo 7: Analisar Resultados

```bash
jupyter notebook notebooks/03_analise_resultados.ipynb
```

## Verifica√ß√£o de Reprodutibilidade

Os resultados devem ser **id√™nticos** (ou muito pr√≥ximos) aos reportados no TCC, pois:
- Seeds est√£o fixos (`config/seeds.txt`)
- Vers√µes de bibliotecas est√£o fixas (`requirements.txt`)
- Dataset √© o mesmo

**Se houver diferen√ßas:**
- Verificar vers√µes de bibliotecas
- Verificar se seeds foram aplicados corretamente
- Verificar se dataset est√° √≠ntegro (checksums)

## Troubleshooting

### Problema: "ModuleNotFoundError"
**Solu√ß√£o:** Instalar depend√™ncias: `pip install -r requirements.txt`

### Problema: "FileNotFoundError: dataset n√£o encontrado"
**Solu√ß√£o:** Executar `preparar_dados.py` primeiro

### Problema: Tempo de execu√ß√£o muito longo
**Solu√ß√£o:** Reduzir N de 30 para 20 em `config/parametros.yaml` (ver se√ß√£o de conting√™ncias)

## Contato

Para d√∫vidas sobre reprodu√ß√£o, abrir issue no GitHub ou contatar:
- Renato Matos Alves Penna: renatomatosapbusiness@gmail.com

#### Checklist de Empacotamento:

- [ ] C√≥digo-fonte completo e comentado
- [ ] `requirements.txt` com vers√µes fixas
- [ ] `README.md` atualizado
- [ ] `docs/manual_reproducao.md` criado
- [ ] Seeds salvos em `config/seeds.txt`
- [ ] Resultados inclu√≠dos (ou link para download)
- [ ] Dataset processado inclu√≠do (se < 100MB) ou link fornecido
- [ ] Licen√ßa definida (`LICENSE`)
- [ ] `.gitignore` configurado (excluir arquivos tempor√°rios)
- [ ] Reposit√≥rio GitHub p√∫blico
- [ ] DOI/Zenodo (opcional, para cita√ß√£o permanente)

---

## 19. Plano de Comunica√ß√£o

### 19.1 P√∫blicos e Mensagens-Chave Pr√©-Execu√ß√£o

#### Mapeamento de Stakeholders:

| P√∫blico | Interesse | Necessidade de Informa√ß√£o | Frequ√™ncia |
|---------|-----------|---------------------------|------------|
| **Orientador (Prof. Danilo)** | Alto | - Progresso do trabalho<br>- Decis√µes metodol√≥gicas<br>- Riscos/bloqueios | Quinzenal/Mensal |
| **Coordena√ß√£o de TCC (PUC Minas)** | M√©dio | - Conformidade com normas<br>- Prazos e entregas<br>- Temas e defesas | Conforme cronograma institucional |
| **Colegas de Turma** | Baixo | - Tema e abordagem<br>- Aprendizados compartilhados | Informal (opcional) |
| **Comunidade Acad√™mica (GitHub)** | Baixo | - C√≥digo aberto<br>- Reprodutibilidade | Quando reposit√≥rio for publicado |

#### Mensagens-Chave por P√∫blico:

**Para o Orientador:**
- **Objetivo:** "Comparar modelos de previs√£o de custos cloud usando dados reais do Google"
- **Progresso:** "Estou na fase [X], pr√≥ximo marco √© [Y] em [data]"
- **Riscos:** "Identifiquei risco [Z], proposta de mitiga√ß√£o √© [W]"
- **D√∫vidas:** "Preciso de orienta√ß√£o sobre [tema espec√≠fico]"

**Para a Coordena√ß√£o:**
- **Tema:** "Previs√£o de Custos de Infraestrutura Cloud Utilizando S√©ries Temporais"
- **Orientador:** "Prof. Danilo de Quadros Maia Filho"
- **Cronograma:** "Entrega prevista para 05/12/2025, defesa em dezembro"
- **Conformidade:** "N√£o envolve sujeitos humanos, dispensa CEP"

**Para Colegas (informal):**
- **Tema leigo:** "Estou criando modelos que preveem quanto vai custar rodar aplica√ß√µes na nuvem"
- **T√©cnico:** "Comparando regress√£o linear, ARIMA e exponential smoothing para previs√£o de custos cloud"

---

### 19.2 Canais e Frequ√™ncia de Comunica√ß√£o

#### Matriz de Comunica√ß√£o:

| P√∫blico | Canal | Frequ√™ncia | Respons√°vel | Formato |
|---------|-------|------------|-------------|---------|
| **Orientador** | E-mail | Semanal | Renato | E-mail de status |
| | Reuni√£o presencial/virtual | Quinzenal | Renato (agendar) | Reuni√£o formal |
| | WhatsApp/Telefone | Conforme necess√°rio | Renato | Mensagem r√°pida |
| **Coordena√ß√£o TCC** | Sistema acad√™mico PUC | Conforme prazos | PUC Minas | Submiss√£o formal |
| | E-mail institucional | Quando necess√°rio | Renato | E-mail formal |
| **Comunidade GitHub** | Reposit√≥rio p√∫blico | Quando atualizado | Renato | Commits + README |
| **Registro pessoal** | Di√°rio de bordo (opcional) | Di√°rio/Semanal | Renato | Anota√ß√µes pessoais |

#### Detalhamento por Canal:

**1. E-mail (Orientador):**
- **Frequ√™ncia:** Toda segunda-feira (ou dia combinado)
- **Template:** Ver Se√ß√£o 17.2 (E-mail de Status Semanal)
- **Tempo de resposta esperado:** 2-3 dias √∫teis

**2. Reuni√£o Presencial/Virtual (Orientador):**
- **Frequ√™ncia:** A cada 15 dias
- **Dura√ß√£o:** 30-60 minutos
- **Agendamento:** Com pelo menos 3 dias de anteced√™ncia
- **Ferramentas:** Google Meet, Zoom ou presencial (PUC Minas)

**3. Sistema Acad√™mico PUC Minas:**
- **Uso:** Submiss√£o de entregas formais (se houver)
- **Aten√ß√£o:** Seguir prazos institucionais rigorosamente

**4. GitHub (Comunidade):**
- **Commits:** A cada feature/bug fix relevante
- **README:** Manter atualizado com progresso geral
- **Issues:** Para discuss√µes t√©cnicas (se algu√©m abrir)

---

### 19.3 Pontos de Comunica√ß√£o Obrigat√≥rios

#### Eventos que Exigem Comunica√ß√£o Formal:

| # | Evento | Para Quem Comunicar | Canal | Prazo | Conte√∫do |
|---|--------|---------------------|-------|-------|----------|
| **1** | **Conclus√£o do Plano Experimental** | Orientador | E-mail + Reuni√£o | Imediato | - Plano completo em anexo<br>- Solicitar revis√£o<br>- Agendar reuni√£o de valida√ß√£o |
| **2** | **Aprova√ß√£o do Plano** | Coordena√ß√£o (se requerido) | Sistema PUC | Ap√≥s aprova√ß√£o do orientador | - Confirmar tema aprovado<br>- Orientador designado |
| **3** | **Mudan√ßa Significativa no Plano** | Orientador | E-mail + Reuni√£o | Antes de implementar | - Proposta de mudan√ßa<br>- Justificativa<br>- Impactos |
| **4** | **In√≠cio da Execu√ß√£o do Experimento** | Orientador | E-mail | 1 dia antes | - Confirmar Go decision<br>- Data/hora de in√≠cio<br>- Tempo estimado |
| **5** | **Conclus√£o da Execu√ß√£o** | Orientador | E-mail | No mesmo dia | - Confirmar conclus√£o<br>- Status dos resultados<br>- Pr√≥ximos passos |
| **6** | **Identifica√ß√£o de Risco Cr√≠tico** | Orientador | E-mail + Telefone (urgente) | Imediatamente | - Descri√ß√£o do risco<br>- Impacto no cronograma<br>- Proposta de mitiga√ß√£o |
| **7** | **Atraso Significativo (> 1 semana)** | Orientador + Coordena√ß√£o | E-mail formal | Assim que identificado | - Raz√£o do atraso<br>- Novo cronograma<br>- Impacto na entrega final |
| **8** | **Entrega de Vers√£o Preliminar do TCC** | Orientador | E-mail + PDF | Conforme combinado | - TCC em PDF<br>- Solicitar revis√£o<br>- Prazo para feedback |
| **9** | **Submiss√£o Final do TCC** | Coordena√ß√£o | Sistema PUC | At√© 05/12/2025 | - TCC final formatado<br>- Documentos requeridos<br>- Declara√ß√µes |
| **10** | **Agendamento de Defesa** | Coordena√ß√£o | Sistema PUC | Ap√≥s aprova√ß√£o da coordena√ß√£o | - Confirmar disponibilidade<br>- Data preferencial |

#### Templates de Comunica√ß√£o para Eventos Cr√≠ticos:

**Template 1: Conclus√£o do Plano Experimental**

```
Assunto: [TCC] Plano Experimental Completo - Solicita√ß√£o de Revis√£o

Prof. Danilo,

Conclu√≠ a elabora√ß√£o do plano experimental do TCC, conforme discutido.

ANEXO: Plano Experimental Completo (README.md / PDF)

O plano inclui:
‚úÖ Objetivos, quest√µes de pesquisa e m√©tricas (GQM)
‚úÖ Desenho experimental (fator √∫nico, CRD, n=30)
‚úÖ Protocolo operacional detalhado
‚úÖ An√°lise de amea√ßas √† validade
‚úÖ Cronograma (execu√ß√£o prevista para junho/julho)

Solicito revis√£o e aprova√ß√£o para iniciar a implementa√ß√£o.

Podemos agendar uma reuni√£o para discuss√£o?
Proposta de datas: [data 1], [data 2], [data 3]

Att,
Renato
```

---

**Template 2: Identifica√ß√£o de Risco Cr√≠tico**

```
Assunto: [TCC] URGENTE - Risco Cr√≠tico Identificado

Prof. Danilo,

Identifiquei um risco cr√≠tico que pode impactar o cronograma:

‚ö†Ô∏è RISCO: [Descri√ß√£o do risco]
üìä IMPACTO: [Descri√ß√£o do impacto - ex: atraso de 2 semanas]
üìÖ PRAZO AFETADO: [Marco ou entrega afetada]

PROPOSTA DE MITIGA√á√ÉO:
[Descri√ß√£o da proposta]

Solicito orienta√ß√£o urgente.
Dispon√≠vel para reuni√£o emergencial.

Att,
Renato
Cel: [telefone]
```

---

**Template 3: Submiss√£o Final do TCC**

```
Assunto: [TCC] Submiss√£o Final - Renato Matos Alves Penna

Coordena√ß√£o de TCC,

Segue submiss√£o final do Trabalho de Conclus√£o de Curso:

T√çTULO: Previs√£o de Custos de Infraestrutura Cloud Utilizando Modelos Baseados em M√©tricas Reais: Uma Compara√ß√£o entre Algoritmos Simples e T√©cnicas de S√©ries Temporais

ALUNO: Renato Matos Alves Penna
ORIENTADOR: Prof. Danilo de Quadros Maia Filho
DATA DE SUBMISS√ÉO: 05/12/2025

ANEXOS:
- TCC_RenatoMatos_VersaoFinal.pdf
- Termo de Compromisso assinado
- [Outros documentos requeridos]

Aguardo retorno sobre agendamento de defesa.

Att,
Renato Matos Alves Penna
Matr√≠cula: [n√∫mero]
renatomatosapbusiness@gmail.com
```

---

## 20. Crit√©rios de Prontid√£o para Execu√ß√£o (Definition of Ready)

### 20.1 Checklist de Prontid√£o (Itens que Devem Estar Completos)

#### Objetivo:

Esta se√ß√£o define os **crit√©rios objetivos** que devem ser atendidos para autorizar o **in√≠cio da execu√ß√£o do experimento** (prevista para 10/06/2025).

#### Checklist Completo de Prontid√£o:

---

**CATEGORIA 1: PLANEJAMENTO E DOCUMENTA√á√ÉO**

- [ ] **1.1 Plano Experimental Completo**
  - [ ] Documento README.md com todas as 20 se√ß√µes preenchidas
  - [ ] Objetivos, quest√µes de pesquisa e m√©tricas (GQM) claramente definidos
  - [ ] Desenho experimental documentado (fator √∫nico, CRD, n=30)
  - [ ] Protocolo operacional passo a passo descrito (Se√ß√£o 11.3)
  - [ ] Amea√ßas √† validade identificadas e mitiga√ß√µes planejadas (Se√ß√£o 13)

- [ ] **1.2 Aprova√ß√£o do Orientador**
  - [ ] Plano experimental revisado pelo Prof. Danilo
  - [ ] Aprova√ß√£o formal recebida (e-mail ou ata de reuni√£o)
  - [ ] Feedback incorporado ao documento

- [ ] **1.3 Cronograma Validado**
  - [ ] Datas de marcos cr√≠ticos confirmadas
  - [ ] Tempo de execu√ß√£o realista (13-15h) considerado
  - [ ] Buffer de tempo para imprevistos inclu√≠do

---

**CATEGORIA 2: INFRAESTRUTURA T√âCNICA**

- [ ] **2.1 Ambiente Computacional**
  - [ ] Python 3.10+ instalado e funcional
  - [ ] Ambiente virtual criado (`venv` ou `conda`)
  - [ ] Todas as bibliotecas necess√°rias instaladas (ver `requirements.txt`)
  - [ ] IDE configurada (VS Code, PyCharm ou similar)
  - [ ] Git instalado e configurado

- [ ] **2.2 Reposit√≥rio GitHub**
  - [ ] Reposit√≥rio criado: https://github.com/RenatoMAP77/pre-tcc
  - [ ] Estrutura de diret√≥rios criada (`src/`, `data/`, `results/`, etc.)
  - [ ] `.gitignore` configurado
  - [ ] Primeiro commit realizado

- [ ] **2.3 Acesso a Dados**
  - [ ] Conta Kaggle criada e autenticada
  - [ ] Google Cluster Data 2019 baixado e validado
  - [ ] Dataset bruto armazenado em `data/raw/`
  - [ ] Integridade dos dados verificada (checksums, se dispon√≠vel)

---

**CATEGORIA 3: C√ìDIGO E SCRIPTS**

- [ ] **3.1 Scripts de Prepara√ß√£o de Dados**
  - [ ] `preparar_dados.py` desenvolvido
  - [ ] Script testado e executado com sucesso
  - [ ] Dataset processado gerado em `data/processed/`
  - [ ] Valida√ß√£o de qualidade dos dados aprovada (Se√ß√£o 10.2)

- [ ] **3.2 Implementa√ß√£o dos Modelos**
  - [ ] Modelo 1: Regress√£o Linear implementado
  - [ ] Modelo 2: M√©dia M√≥vel implementado
  - [ ] Modelo 3: ARIMA implementado (com grid search)
  - [ ] Modelo 4: Exponential Smoothing implementado
  - [ ] Todos os modelos testados individualmente

- [ ] **3.3 Script Principal de Execu√ß√£o**
  - [ ] `executar_experimento.py` desenvolvido
  - [ ] Integra√ß√£o com todos os 4 modelos funcional
  - [ ] TimeSeriesSplit (k=5) implementado corretamente
  - [ ] Sistema de logging configurado
  - [ ] Salvamento incremental de resultados implementado

- [ ] **3.4 Fun√ß√µes Auxiliares**
  - [ ] Fun√ß√µes de c√°lculo de m√©tricas (MAE, RMSE, MAPE) implementadas
  - [ ] Fun√ß√µes de divis√£o treino/teste com seed implementadas
  - [ ] Fun√ß√µes de valida√ß√£o de dados implementadas

---

**CATEGORIA 4: VALIDA√á√ÉO PR√âVIA (DRY RUN)**

- [ ] **4.1 Execu√ß√£o de Teste Realizada**
  - [ ] Dry run executado com n=5 repeti√ß√µes
  - [ ] Todos os 4 modelos rodaram sem erros
  - [ ] Resultados salvos em arquivo CSV

- [ ] **4.2 Valida√ß√£o de Outputs**
  - [ ] Arquivo `resultados.csv` gerado com estrutura correta
  - [ ] Logs gerados corretamente em `logs/`
  - [ ] M√©tricas est√£o em ranges plaus√≠veis (MAE > 0, MAPE < 100%)

- [ ] **4.3 Valida√ß√£o de Tempo**
  - [ ] Tempo de execu√ß√£o do dry run medido
  - [ ] Tempo de execu√ß√£o completo estimado (30 √ó tempo dry run)
  - [ ] Tempo estimado √© vi√°vel (< 20h)

- [ ] **4.4 Corre√ß√£o de Bugs**
  - [ ] Todos os bugs identificados no dry run foram corrigidos
  - [ ] Scripts atualizados e testados novamente

---

**CATEGORIA 5: CONFIGURA√á√ïES E PAR√ÇMETROS**

- [ ] **5.1 Seeds de Reprodutibilidade**
  - [ ] 30 seeds aleat√≥rios gerados com seed mestre = 42
  - [ ] Seeds salvos em `config/seeds.txt`
  - [ ] Script configurado para usar seeds corretamente

- [ ] **5.2 Hiperpar√¢metros Definidos**
  - [ ] Grid search do ARIMA configurado: p ‚àà {0,1,2}, d ‚àà {0,1}, q ‚àà {0,1,2}
  - [ ] Par√¢metros do ES definidos: trend, seasonal, seasonal_periods
  - [ ] Janela da M√©dia M√≥vel definida: N = 7

- [ ] **5.3 Par√¢metros de Valida√ß√£o**
  - [ ] k-fold = 5 configurado (TimeSeriesSplit)
  - [ ] Divis√£o treino/teste = 70%-30% configurada

---

**CATEGORIA 6: BACKUPS E SEGURAN√áA**

- [ ] **6.1 Sistema de Backup**
  - [ ] Reposit√≥rio GitHub configurado como backup remoto
  - [ ] Backup local em segundo dispositivo (opcional, mas recomendado)
  - [ ] Google Drive configurado como backup adicional (opcional)

- [ ] **6.2 Salvamento Incremental**
  - [ ] Script configurado para salvar resultados a cada execu√ß√£o
  - [ ] Mecanismo de restart implementado (para retomar se falhar)

---

**CATEGORIA 7: RECURSOS E LOG√çSTICA**

- [ ] **7.1 Disponibilidade de Tempo**
  - [ ] Per√≠odo de ~2 semanas reservado para execu√ß√£o (10-25/06)
  - [ ] Computador dispon√≠vel por longos per√≠odos (execu√ß√£o pode levar 13-15h)
  - [ ] Alternativa planejada (ex: executar durante a noite)

- [ ] **7.2 Conting√™ncias Planejadas**
  - [ ] Plano B para hardware (laborat√≥rios PUC, se computador falhar)
  - [ ] Plano B para dados (BigQuery, se Kaggle falhar)
  - [ ] Plano de redu√ß√£o de N (de 30 para 20, se tempo exceder muito)

---

**CATEGORIA 8: COMUNICA√á√ÉO E APROVA√á√ÉO**

- [ ] **8.1 Comunica√ß√£o ao Orientador**
  - [ ] Orientador informado sobre data de in√≠cio da execu√ß√£o
  - [ ] √öltima reuni√£o de valida√ß√£o realizada
  - [ ] Orientador ciente de que experimento levar√° ~13-15h

- [ ] **8.2 Registro de Prontid√£o**
  - [ ] Checklist de prontid√£o revisado e todos os itens confirmados
  - [ ] Data de conclus√£o da prepara√ß√£o registrada
  - [ ] Go/No-Go decision documentada

---

#### Resumo Visual - Status de Prontid√£o:

```
CATEGORIA                         STATUS  COMPLETUDE
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
1. Planejamento e Documenta√ß√£o   [  ]    0/3
2. Infraestrutura T√©cnica         [  ]    0/3
3. C√≥digo e Scripts               [  ]    0/4
4. Valida√ß√£o Pr√©via (Dry Run)     [  ]    0/4
5. Configura√ß√µes e Par√¢metros     [  ]    0/3
6. Backups e Seguran√ßa            [  ]    0/2
7. Recursos e Log√≠stica           [  ]    0/2
8. Comunica√ß√£o e Aprova√ß√£o        [  ]    0/2
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
TOTAL: 0/23 categorias completas

DECIS√ÉO: [  ] GO  [  ] NO-GO
```

---

### 20.2 Aprova√ß√µes Finais para Iniciar a Opera√ß√£o

#### Processo de Go/No-Go Decision:

**Data Planejada:** 05/06/2025
**Participantes:** Renato (Pesquisador) + Prof. Danilo (Orientador)

#### Crit√©rios de Decis√£o:

**‚úÖ GO (Autorizar Execu√ß√£o):**

Condi√ß√µes **obrigat√≥rias** para autorizar in√≠cio:

1. **Checklist de Prontid√£o ‚â• 90% completo**
   - M√°ximo 2-3 itens n√£o-cr√≠ticos pendentes
   - Todos os itens cr√≠ticos DEVEM estar completos

2. **Dry Run Bem-Sucedido**
   - Execu√ß√£o de teste (n=5) rodou sem erros
   - Resultados validados e plaus√≠veis
   - Bugs corrigidos

3. **Aprova√ß√£o do Orientador**
   - Plano experimental aprovado
   - Orientador confirma prontid√£o metodol√≥gica
   - Orientador valida cronograma

4. **Recursos Garantidos**
   - Computador funcional e dispon√≠vel
   - Dataset baixado e validado
   - C√≥digo testado e est√°vel

**‚ùå NO-GO (Adiar Execu√ß√£o):**

Situa√ß√µes que **bloqueiam** in√≠cio da execu√ß√£o:

1. **Checklist < 80% completo**
   - Muitos itens cr√≠ticos pendentes
   - Infraestrutura n√£o pronta

2. **Dry Run Falhou**
   - Erros n√£o resolvidos
   - Resultados implaus√≠veis
   - Tempo de execu√ß√£o invi√°vel (> 30h estimadas)

3. **Falta de Aprova√ß√£o**
   - Orientador n√£o aprovou o plano
   - Mudan√ßas significativas pendentes

4. **Riscos Cr√≠ticos N√£o Mitigados**
   - Hardware inst√°vel
   - Dataset indispon√≠vel
   - Bugs cr√≠ticos n√£o resolvidos

#### Reuni√£o de Go/No-Go:

**Formato da Reuni√£o:**

1. **Revis√£o do Checklist** (20 min)
   - Renato apresenta status de cada categoria
   - Demonstra que itens cr√≠ticos foram completados

2. **Demonstra√ß√£o do Dry Run** (15 min)
   - Mostrar resultados do teste (n=5)
   - Explicar tempo estimado para execu√ß√£o completa

3. **Discuss√£o de Riscos** (15 min)
   - Revisar riscos identificados (Se√ß√£o 16.3)
   - Confirmar planos de conting√™ncia

4. **Decis√£o Final** (10 min)
   - Orientador decide: GO ou NO-GO
   - Se GO: confirmar data de in√≠cio
   - Se NO-GO: definir itens pendentes e nova data de revis√£o

**Registro da Decis√£o:**

```markdown
# Registro de Go/No-Go Decision

**Data da Reuni√£o:** 05/06/2025
**Participantes:** Renato Matos Alves Penna, Prof. Danilo de Quadros Maia Filho

## Status do Checklist:
- Planejamento: [X] Completo
- Infraestrutura: [X] Completo
- C√≥digo: [X] Completo
- Dry Run: [X] Bem-sucedido
- Configura√ß√µes: [X] Completo
- Backups: [X] Completo
- Recursos: [X] Garantidos
- Comunica√ß√£o: [X] OK

## Resultado do Dry Run:
- Tempo m√©dio por modelo: [X] segundos
- Tempo estimado total: ~[Y] horas
- Erros encontrados: [Nenhum / Lista]

## Riscos Identificados:
- [Lista de riscos e mitiga√ß√µes]

## DECIS√ÉO:

[X] **GO** - Autorizado iniciar execu√ß√£o em 10/06/2025
[ ] **NO-GO** - Adiar execu√ß√£o. Itens pendentes: [lista]

## Observa√ß√µes:
[Coment√°rios do orientador]

**Assinatura (Orientador):** _______________________
**Data:** ___/___/______
```

#### Ap√≥s a Decis√£o GO:

**Pr√≥ximos Passos Imediatos:**

1. **Comunicar In√≠cio:**
   - Enviar e-mail ao orientador confirmando data/hora de in√≠cio
   - Documentar no log do experimento

2. **Prepara√ß√£o Final:**
   - Fechar aplica√ß√µes desnecess√°rias no computador
   - Desabilitar atualiza√ß√µes autom√°ticas
   - Verificar espa√ßo em disco
   - Confirmar backup configurado

3. **Iniciar Execu√ß√£o:**
   - Executar `python src/executar_experimento.py`
   - Monitorar progresso inicial (primeiras 2-3 horas)
   - Confirmar que logs est√£o sendo gerados corretamente

4. **Monitoramento:**
   - Verificar progresso periodicamente
   - Registrar qualquer anomalia
   - Estar preparado para interven√ß√£o se necess√°rio

---

## Refer√™ncias Bibliogr√°ficas

### Previs√£o de Custos e Workloads em Nuvem

[1] **Calheiros, R.N., Masoumi, E., Ranjan, R., & Buyya, R. (2015).** "Workload Prediction Using ARIMA Model and Its Impact on Cloud Applications' QoS." *IEEE Transactions on Cloud Computing*, 3(4), 449-458. DOI: 10.1109/TCC.2014.2350475

[2] **Amiri, M., & Mohammad-Khanli, L. (2017).** "A Survey and Classification of the Workload Forecasting Methods in Cloud Computing." *Cluster Computing*, 20. DOI: 10.1007/s10586-017-1048-4

[3] **Tsoumakos, D., et al. (2023).** "Is Machine Learning Necessary for Cloud Resource Usage Forecasting?" *ACM Symposium on Cloud Computing (SoCC '23)*. DOI: 10.1145/3620678.3624790

[4] **Khandelwal, V., Chaturvedi, A.K., & Gupta, C.P. (2020).** "Amazon EC2 Spot Price Prediction Using Regression Random Forests." *IEEE Transactions on Cloud Computing*, 8(1), 59-72. DOI: 10.1109/TCC.2017.2780159

[5] **Chhetri, M.B., Lumpe, M., Vo, Q.B., & Kowalczyk, R. (2017).** "On Forecasting Amazon EC2 Spot Prices Using Time-Series Decomposition with Hybrid Look-Backs." *IEEE International Conference on Edge Computing*. DOI: 10.1109/IEEE.EDGE.2017.55

[6] **Fragiadakis, G., et al. (2023).** "Applying Machine Learning in Cloud Service Price Prediction: The Case of Amazon IaaS." *Future Internet (MDPI)*, 15(8), 277. DOI: 10.3390/fi15080277

### Fundamentos Te√≥ricos de S√©ries Temporais

[7] **Box, G.E.P., Jenkins, G.M., Reinsel, G.C., & Ljung, G.M. (2015).** *Time Series Analysis: Forecasting and Control* (5th ed.). John Wiley & Sons. ISBN: 978-1-118-67502-1

[8] **Hamilton, J.D. (1994).** *Time Series Analysis*. Princeton University Press. ISBN: 978-0-691-04289-3

[9] **Brockwell, P.J., & Davis, R.A. (2009).** *Time Series: Theory and Methods* (2nd ed.). Springer. ISBN: 978-1-4419-0319-8

[10] **Holt, C.C. (1957/2004).** "Forecasting Seasonals and Trends by Exponentially Weighted Moving Averages." *International Journal of Forecasting*, 20(1), 5-10. DOI: 10.1016/j.ijforecast.2003.09.015

[11] **Winters, P.R. (1960).** "Forecasting Sales by Exponentially Weighted Moving Averages." *Management Science*, 6(3), 324-342. DOI: 10.1287/mnsc.6.3.324

[12] **Gardner, E.S., Jr. (1985).** "Exponential Smoothing: The State of the Art." *Journal of Forecasting*, 4(1), 1-28. DOI: 10.1002/for.3980040103

[13] **Gardner, E.S., Jr. (2006).** "Exponential Smoothing: The State of the Art‚ÄîPart II." *International Journal of Forecasting*, 22(4), 637-666. DOI: 10.1016/j.ijforecast.2006.03.005

[14] **Hyndman, R.J., Koehler, A.B., Snyder, R.D., & Grose, S. (2002).** "A State Space Framework for Automatic Forecasting Using Exponential Smoothing Methods." *International Journal of Forecasting*, 18(3), 439-454. DOI: 10.1016/S0169-2070(01)00110-8

[15] **Hyndman, R.J., & Athanasopoulos, G. (2021).** *Forecasting: Principles and Practice* (3rd ed.). OTexts. ISBN: 978-0-9875071-3-6. URL: https://otexts.com/fpp3/

[16] **Hyndman, R.J., & Koehler, A.B. (2006).** "Another Look at Measures of Forecast Accuracy." *International Journal of Forecasting*, 22(4), 679-688. DOI: 10.1016/j.ijforecast.2006.03.001

[17] **Akaike, H. (1974).** "A New Look at the Statistical Model Identification." *IEEE Transactions on Automatic Control*, AC-19(6), 716-723. DOI: 10.1109/TAC.1974.1100705

[18] **Schwarz, G. (1978).** "Estimating the Dimension of a Model." *Annals of Statistics*, 6(2), 461-464. DOI: 10.1214/aos/1176344136

### Google Cluster Data Studies

[19] **Tirmazi, M., Barker, A., Deng, N., Haque, M.E., Qin, Z.G., Hand, S., Harchol-Balter, M., & Wilkes, J. (2020).** "Borg: the Next Generation." *Fifteenth European Conference on Computer Systems (EuroSys '20)*, 1-14. DOI: 10.1145/3342195.3387517

[20] **Verma, A., Pedrosa, L., Korupolu, M., Oppenheimer, D., Tune, E., & Wilkes, J. (2015).** "Large-scale Cluster Management at Google with Borg." *Proceedings of the Tenth European Conference on Computer Systems (EuroSys '15)*, Article 18. DOI: 10.1145/2741948.2741964

[21] **Reiss, C., Tumanov, A., Ganger, G.R., Katz, R.H., & Kozuch, M.A. (2012).** "Heterogeneity and Dynamicity of Clouds at Scale: Google Trace Analysis." *Proceedings of the Third ACM Symposium on Cloud Computing (SoCC '12)*. DOI: 10.1145/2391229.2391236

[22] **Wilkes, J. (2020).** "Google Cluster-Usage Traces v3." *Technical Report*, Google Inc. URL: https://github.com/google/cluster-data/blob/master/ClusterData2019.md

[23] **Janardhanan, D., & Barrett, E. (2017).** "CPU Workload Forecasting of Machines in Data Centers Using LSTM Recurrent Neural Networks and ARIMA Models." *12th International Conference for Internet Technology and Secured Transactions (ICITST)*, 55-60. DOI: 10.23919/ICITST.2017.8356346

[24] **Shyam, G.K., & Manvi, S.S. (2022).** "Time Series-based Workload Prediction Using the Statistical Hybrid Model for the Cloud Environment." *Computing (Springer)*, 104. DOI: 10.1007/s00607-022-01129-7

[25] **Bappy, F.H., Mukherjee, P., Patwary, M.S., Mazumder, M., & Razzaque, M.A. (2023).** "A Deep Dive into the Google Cluster Workload Traces: Analyzing the Application Failure Characteristics and User Behaviors." arXiv:2308.02358. URL: https://arxiv.org/abs/2308.02358

[26] **Alibasa, M.J., Suleiman, B., Bello, A., Anaissi, A., Yan, Q., & Chen, S. (2023).** "Cloud Resources Usage Prediction Using Deep Learning Models." *Cooperative Information Systems (CoopIS 2023)*, LNCS 14353, Springer. DOI: 10.1007/978-3-031-33743-7_36

[27] **van Loo, T., Jindal, A., Benedict, S., Chadha, M., & Gerndt, M. (2022).** "An Analysis of Workload Patterns In Borg Cloud Cluster Traces." *Texas A&M University Digital Repository*. URL: https://oaktrust.library.tamu.edu/handle/1969.1/196508

[28] **Hosseinzadeh, M., et al. (2022).** "A Hybrid CNN-LSTM Model for Predicting Server Load in Cloud Computing." *The Journal of Supercomputing*, 78, 8913-8934. DOI: 10.1007/s11227-021-04234-0

[29] **Asmawi, A., Hamid, S.H.A., & Nor, A.M. (2022).** "Cloud Failure Prediction Based on Traditional Machine Learning and Deep Learning." *Journal of Cloud Computing*, 11, Article 83. DOI: 10.1186/s13677-022-00327-0

### Estudos Comparativos de M√©todos de Previs√£o

[30] **Makridakis, S., & Hibon, M. (2000).** "The M3-Competition: Results, Conclusions and Implications." *International Journal of Forecasting*, 16(4), 451-476. DOI: 10.1016/S0169-2070(00)00057-1

[31] **Makridakis, S., Spiliotis, E., & Assimakopoulos, V. (2020).** "The M4 Competition: 100,000 Time Series and 61 Forecasting Methods." *International Journal of Forecasting*, 36(1), 54-74. DOI: 10.1016/j.ijforecast.2019.04.014

[32] **Makridakis, S., Spiliotis, E., & Assimakopoulos, V. (2018).** "Statistical and Machine Learning Forecasting Methods: Concerns and Ways Forward." *PLoS ONE*, 13(3), e0194889. DOI: 10.1371/journal.pone.0194889

[33] **Wadi, S.A., et al. (2013).** "ARIMA Model and Exponential Smoothing Method: A Comparison." *AIP Conference Proceedings*, 1522(1), 1312. DOI: 10.1063/1.4801282

[34] **Bahuguna, A., et al. (2023).** "Comparison of Exponential Smoothing and ARIMA Time Series Models for Forecasting COVID-19 Cases." *International Journal of Research in Medical Sciences*, 11(5), 1727-1734. DOI: 10.18203/2320-6012.ijrms20231344

[35] **Siami-Namini, S., Tavakoli, N., & Namin, A.S. (2019).** "A Comparison of ARIMA and LSTM in Forecasting Time Series." *IEEE International Conference on Machine Learning and Applications (ICMLA)*. arXiv: https://arxiv.org/abs/1803.06386

[36] **Saxena, D., et al. (2023).** "Performance Analysis of Machine Learning Centered Workload Prediction Models for Cloud." *IEEE Transactions on Parallel and Distributed Systems*. arXiv: https://arxiv.org/abs/2302.02452

[37] **ACM (2025).** "Evaluation-free Time-series Forecasting Model Selection via Meta-learning." *ACM Transactions on Knowledge Discovery from Data*. DOI: 10.1145/3715149

### Abordagens H√≠bridas e Estado da Arte

[38] **Authors (2020).** "Real-Time Prediction of Docker Container Resource Load Based on a Hybrid Model of ARIMA and Triple Exponential Smoothing." *IEEE Transactions on Cloud Computing*. DOI: 10.1109/TCC.2020.2989731

[39] **Kontopoulou, V.I., et al. (2023).** "A Review of ARIMA vs. Machine Learning Approaches for Time Series Forecasting in Data Driven Networks." *Future Internet*, 15(8), 255. DOI: 10.3390/fi15080255

[40] **Deochake, S. (2025).** "ABACUS: A FinOps Service for Cloud Cost Optimization." arXiv preprint arXiv:2501.14753. URL: https://arxiv.org/abs/2501.14753

### Metodologia de Experimenta√ß√£o

[41] **Wohlin, C., Runeson, P., H√∂st, M., Ohlsson, M.C., Regnell, B., & Wessl√©n, A. (2012).** *Experimentation in Software Engineering*. Springer Science & Business Media. ISBN: 978-3-642-29043-5

---

**Nota:** Todas as refer√™ncias foram verificadas quanto √† disponibilidade e acessibilidade. DOIs fornecem links permanentes para artigos acad√™micos. As cita√ß√µes seguem formato padronizado IEEE/ACM adaptado para facilitar localiza√ß√£o e verifica√ß√£o.

---

